{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8559c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "Pandas version: 2.3.3\n",
      "Numpy version: 2.2.6\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 1: IMPORTS & SETUP\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "What am I doing: Importing libraries\n",
    "Why: These are tools I need for data processing and ML\n",
    "\n",
    "Libraries explained:\n",
    "- pandas: For working with data tables (like Excel)\n",
    "- numpy: For mathematical operations\n",
    "- sklearn: Machine learning algorithms and tools\n",
    "- pickle: For saving/loading trained models\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd49f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä DATASET OVERVIEW\n",
      "==================================================\n",
      "Total rows (resumes): 5000\n",
      "Total columns: 5\n",
      "Column names: ['Company', 'Designation', 'Skills', 'Achievements', 'Status']\n",
      "\n",
      "üìã FIRST 3 RESUMES:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Achievements</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Cloud Architect</td>\n",
       "      <td>Machine Learning, C#, AWS, Scalability, Azure,...</td>\n",
       "      <td>Migrated legacy system to cloud, reducing oper...</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Product Manager</td>\n",
       "      <td>Market Analysis, AWS, Jira, Machine Learning, ...</td>\n",
       "      <td>Defined 1-year product roadmap, securing $1.17...</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>Cloud Architect</td>\n",
       "      <td>Python, Leadership, Java, Scalability, SQL, AW...</td>\n",
       "      <td>Migrated legacy system to cloud, reducing oper...</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company      Designation  \\\n",
       "0  Microsoft  Cloud Architect   \n",
       "1     Amazon  Product Manager   \n",
       "2     Google  Cloud Architect   \n",
       "\n",
       "                                              Skills  \\\n",
       "0  Machine Learning, C#, AWS, Scalability, Azure,...   \n",
       "1  Market Analysis, AWS, Jira, Machine Learning, ...   \n",
       "2  Python, Leadership, Java, Scalability, SQL, AW...   \n",
       "\n",
       "                                        Achievements    Status  \n",
       "0  Migrated legacy system to cloud, reducing oper...  Accepted  \n",
       "1  Defined 1-year product roadmap, securing $1.17...  Accepted  \n",
       "2  Migrated legacy system to cloud, reducing oper...  Rejected  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 2: LOAD DATA\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "What: Load CSV file into pandas DataFrame\n",
    "Why: Need data to train the model\n",
    "\n",
    "DataFrame = Like an Excel spreadsheet in Python\n",
    "- Rows = Individual resumes\n",
    "- Columns = Information about each resume (Company, Skills, etc.)\n",
    "\"\"\"\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('resume_dataset_large.csv')\n",
    "\n",
    "# Let's explore what we loaded\n",
    "print(\"üìä DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total rows (resumes): {len(df)}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"Column names: {list(df.columns)}\")\n",
    "\n",
    "print(\"\\nüìã FIRST 3 RESUMES:\")\n",
    "print(\"=\" * 50)\n",
    "# Display first 3 rows\n",
    "df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: Number of unique companies:\n",
      "\n",
      "Q2: Company names:\n",
      "\n",
      "Q3: Applicants per company:\n",
      "\n",
      "Q4: Status distribution:\n",
      "\n",
      "üìÑ COMPLETE RESUME (Row 0):\n",
      "Company: Microsoft\n",
      "Designation: Cloud Architect\n",
      "Skills: Machine Learning, C#, AWS, Scalability, Azure, Terraform, Network Security, Python\n",
      "Status: Accepted\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 3: DATA EXPLORATION - YOUR TURN!\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "LEARNING EXERCISE: Explore the data by answering these questions\n",
    "\"\"\"\n",
    "\n",
    "# Question 1: How many unique companies are in the dataset?\n",
    "# HINT: Use df['Company'].nunique()\n",
    "print(\"Q1: Number of unique companies:\")\n",
    "# YOUR CODE HERE:\n",
    "\n",
    "\n",
    "\n",
    "# Question 2: What are the names of all companies?\n",
    "# HINT: Use df['Company'].unique()\n",
    "print(\"\\nQ2: Company names:\")\n",
    "# YOUR CODE HERE:\n",
    "\n",
    "\n",
    "\n",
    "# Question 3: How many people applied to each company?\n",
    "# HINT: Use df['Company'].value_counts()\n",
    "print(\"\\nQ3: Applicants per company:\")\n",
    "# YOUR CODE HERE:\n",
    "\n",
    "\n",
    "\n",
    "# Question 4: How many people got 'Accepted' vs 'Rejected'?\n",
    "# HINT: Use df['Status'].value_counts()\n",
    "print(\"\\nQ4: Status distribution:\")\n",
    "# YOUR CODE HERE:\n",
    "\n",
    "\n",
    "\n",
    "# Question 5: Look at one complete resume (row 0)\n",
    "print(\"\\nüìÑ COMPLETE RESUME (Row 0):\")\n",
    "print(f\"Company: {df.loc[0, 'Company']}\")\n",
    "print(f\"Designation: {df.loc[0, 'Designation']}\")\n",
    "print(f\"Skills: {df.loc[0, 'Skills']}\")\n",
    "print(f\"Status: {df.loc[0, 'Status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8629b15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: ['Company', 'Designation', 'Skills', 'Achievements', 'Status']\n",
      "After: ['Company', 'Designation', 'Skills', 'Achievements', 'Status']\n",
      "\n",
      "‚úÖ Data cleaned!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Achievements</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Cloud Architect</td>\n",
       "      <td>Machine Learning, C#, AWS, Scalability, Azure,...</td>\n",
       "      <td>Migrated legacy system to cloud, reducing oper...</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Product Manager</td>\n",
       "      <td>Market Analysis, AWS, Jira, Machine Learning, ...</td>\n",
       "      <td>Defined 1-year product roadmap, securing $1.17...</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>Cloud Architect</td>\n",
       "      <td>Python, Leadership, Java, Scalability, SQL, AW...</td>\n",
       "      <td>Migrated legacy system to cloud, reducing oper...</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>Product Manager</td>\n",
       "      <td>Communication, Python, SQL, Agile, Machine Lea...</td>\n",
       "      <td>Defined 1-year product roadmap, securing $0.18...</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Kubernetes, Monitoring, CI/CD, Machine Learnin...</td>\n",
       "      <td>Implemented CI/CD pipeline, reducing deploymen...</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company      Designation  \\\n",
       "0  Microsoft  Cloud Architect   \n",
       "1     Amazon  Product Manager   \n",
       "2     Google  Cloud Architect   \n",
       "3     Google  Product Manager   \n",
       "4     Google  DevOps Engineer   \n",
       "\n",
       "                                              Skills  \\\n",
       "0  Machine Learning, C#, AWS, Scalability, Azure,...   \n",
       "1  Market Analysis, AWS, Jira, Machine Learning, ...   \n",
       "2  Python, Leadership, Java, Scalability, SQL, AW...   \n",
       "3  Communication, Python, SQL, Agile, Machine Lea...   \n",
       "4  Kubernetes, Monitoring, CI/CD, Machine Learnin...   \n",
       "\n",
       "                                        Achievements    Status  \n",
       "0  Migrated legacy system to cloud, reducing oper...  Accepted  \n",
       "1  Defined 1-year product roadmap, securing $1.17...  Accepted  \n",
       "2  Migrated legacy system to cloud, reducing oper...  Rejected  \n",
       "3  Defined 1-year product roadmap, securing $0.18...  Rejected  \n",
       "4  Implemented CI/CD pipeline, reducing deploymen...  Rejected  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 4: DATA CLEANING\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "What: Clean the data\n",
    "Why: Remove extra spaces, quotes, missing values\n",
    "\"\"\"\n",
    "\n",
    "# TASK 1: Clean column names\n",
    "print(\"Before:\", df.columns.tolist())\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"After:\", df.columns.tolist())\n",
    "\n",
    "# TASK 2: Clean text data\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].str.strip().str.replace('\"', '')\n",
    "\n",
    "# Check the result\n",
    "print(\"\\n‚úÖ Data cleaned!\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1f387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering: 5000 records\n",
      "After filtering: 3010 records\n",
      "Removed: 1990 rejected candidates\n",
      "Input shape: (3010, 2)\n",
      "This means: 3010 rows (people), 2 columns (features)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Designation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Cloud Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Product Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salesforce</td>\n",
       "      <td>Cloud Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Cloud Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>Software Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Cloud Architect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Company        Designation\n",
       "0    Microsoft    Cloud Architect\n",
       "1       Amazon    Product Manager\n",
       "5   Salesforce    Cloud Architect\n",
       "6      Infosys     Data Scientist\n",
       "7    Microsoft    Cloud Architect\n",
       "9      Infosys  Software Engineer\n",
       "10   Microsoft     Data Scientist\n",
       "11      Amazon     Data Scientist\n",
       "12     Infosys    DevOps Engineer\n",
       "14      Amazon    Cloud Architect"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 5: FILTER DATA\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "LEARNING QUESTION: Why filter for 'Accepted' only?\n",
    "ANSWER: [Write your understanding here]\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Before filtering: {len(df)} records\")\n",
    "\n",
    "# Filter for accepted candidates\n",
    "df = df[df['Status'].str.lower() == 'accepted']\n",
    "\n",
    "print(f\"After filtering: {len(df)} records\")\n",
    "print(f\"Removed: {5000 - len(df)} rejected candidates\")\n",
    "\n",
    "# ============================================================\n",
    "# CELL 6: PREPARE INPUT FEATURES (X)\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "CONCEPT: Features = INPUT to the model\n",
    "Features = What we KNOW (Company, Designation)\n",
    "\"\"\"\n",
    "\n",
    "X = df[['Company', 'Designation']].copy()\n",
    "\n",
    "print(f\"Input shape: {X.shape}\")\n",
    "print(f\"This means: {X.shape[0]} rows (people), {X.shape[1]} columns (features)\")\n",
    "\n",
    "# LEARNING TASK: Look at first 10 inputs\n",
    "X.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77feb627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Skills (text):\n",
      "Machine Learning, C#, AWS, Scalability, Azure, Terraform, Network Security, Python\n",
      "\n",
      "Transformed Skills (list):\n",
      "['Machine Learning', 'C#', 'AWS', 'Scalability', 'Azure', 'Terraform', 'Network Security', 'Python']\n",
      "Companies learned:\n",
      "  Amazon ‚Üí 0\n",
      "  Google ‚Üí 1\n",
      "  Infosys ‚Üí 2\n",
      "  Microsoft ‚Üí 3\n",
      "  Salesforce ‚Üí 4\n",
      "\n",
      "üìä Encoding Verification:\n",
      "      Original  Encoded\n",
      "0    Microsoft        3\n",
      "1       Amazon        0\n",
      "5   Salesforce        4\n",
      "6      Infosys        2\n",
      "7    Microsoft        3\n",
      "9      Infosys        2\n",
      "10   Microsoft        3\n",
      "11      Amazon        0\n",
      "12     Infosys        2\n",
      "14      Amazon        0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# CELL 7: PREPARE OUTPUT LABELS (y)\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "CONCEPT: Labels = OUTPUT we want to predict\n",
    "Labels = What we want to LEARN (Skills)\n",
    "\"\"\"\n",
    "\n",
    "# TASK: Split comma-separated skills into lists\n",
    "df['Skills_List'] = df['Skills'].apply(\n",
    "    lambda x: [skill.strip() for skill in str(x).split(',')]\n",
    ")\n",
    "\n",
    "# LEARNING: See the transformation\n",
    "print(\"Original Skills (text):\")\n",
    "print(df.loc[0, 'Skills'])\n",
    "\n",
    "print(\"\\nTransformed Skills (list):\")\n",
    "print(df.loc[0, 'Skills_List'])\n",
    "\n",
    "y = df['Skills_List']\n",
    "\n",
    "# ============================================================\n",
    "# CELL 8: ENCODING - COMPANY\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "CONCEPT: Computers understand numbers, not text\n",
    "'Google' ‚Üí 1, 'Amazon' ‚Üí 0, etc.\n",
    "\n",
    "LEARNING TASK: Understand LabelEncoder\n",
    "\"\"\"\n",
    "\n",
    "company_encoder = LabelEncoder()\n",
    "\n",
    "# Fit: Learn all unique companies\n",
    "company_encoder.fit(X['Company'])\n",
    "\n",
    "# What did it learn?\n",
    "print(\"Companies learned:\")\n",
    "for i, company in enumerate(company_encoder.classes_):\n",
    "    print(f\"  {company} ‚Üí {i}\")\n",
    "\n",
    "# Transform: Convert text to numbers\n",
    "X['Company_Encoded'] = company_encoder.transform(X['Company'])\n",
    "\n",
    "# VERIFY: Check the transformation\n",
    "comparison = pd.DataFrame({\n",
    "    'Original': X['Company'].head(10),\n",
    "    'Encoded': X['Company_Encoded'].head(10)\n",
    "})\n",
    "print(\"\\nüìä Encoding Verification:\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9830f518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (3010, 29)\n",
      "Interpretation: 3010 people, 29 possible skills\n",
      "\n",
      "All possible skills (29):\n",
      "['AWS' 'Agile' 'Algorithms' 'Azure' 'C#' 'CI/CD' 'Communication'\n",
      " 'Data Structures' 'Data Visualization' 'Docker' 'Git' 'Java' 'Jira'\n",
      " 'Kubernetes' 'Leadership' 'Linux' 'Machine Learning' 'Market Analysis'\n",
      " 'Monitoring' 'Network Security' 'Python' 'R' 'Roadmapping' 'SQL'\n",
      " 'Scalability' 'Statistics' 'TensorFlow' 'Terraform' 'UX/UI Principles']\n",
      "\n",
      "üë§ Person 0's skills:\n",
      "Original: ['Machine Learning', 'C#', 'AWS', 'Scalability', 'Azure', 'Terraform', 'Network Security', 'Python']\n",
      "Encoded: [1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0]\n",
      "Interpretation:\n",
      "  ‚úì Has AWS\n",
      "  ‚úì Has Azure\n",
      "  ‚úì Has C#\n",
      "  ‚úì Has Machine Learning\n",
      "  ‚úì Has Network Security\n",
      "  ‚úì Has Python\n",
      "  ‚úì Has Scalability\n",
      "  ‚úì Has Terraform\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# CELL 9: ENCODING - DESIGNATION\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "TASK: Do the same for Designation\n",
    "TRY YOURSELF: Complete this cell\n",
    "\"\"\"\n",
    "\n",
    "designation_encoder = LabelEncoder()\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# 1. Fit the encoder\n",
    "# 2. Print the classes\n",
    "# 3. Transform and add to X\n",
    "# 4. Verify the transformation\n",
    "\n",
    "# ============================================================\n",
    "# CELL 10: ENCODING - SKILLS (Multi-Label)\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "CONCEPT: MultiLabelBinarizer\n",
    "Input: [\"Python\", \"SQL\", \"AWS\"]\n",
    "Output: [0, 0, 1, 0, 1, 0, 1, 0, ...]\n",
    "         ^     ^        ^     ^\n",
    "         |     |        |     |\n",
    "      Not    Not     Has    Has\n",
    "      skill1 skill2  Python  SQL\n",
    "\"\"\"\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_encoded = mlb.fit_transform(y)\n",
    "\n",
    "# LEARNING: Understand the output\n",
    "print(f\"Output shape: {y_encoded.shape}\")\n",
    "print(f\"Interpretation: {y_encoded.shape[0]} people, {y_encoded.shape[1]} possible skills\")\n",
    "\n",
    "print(f\"\\nAll possible skills ({len(mlb.classes_)}):\")\n",
    "print(mlb.classes_)\n",
    "\n",
    "# VISUAL: See one person's encoding\n",
    "person_idx = 0\n",
    "print(f\"\\nüë§ Person 0's skills:\")\n",
    "print(f\"Original: {y.iloc[person_idx]}\")\n",
    "print(f\"Encoded: {y_encoded[person_idx]}\")\n",
    "print(f\"Interpretation:\")\n",
    "for i, skill in enumerate(mlb.classes_):\n",
    "    if y_encoded[person_idx][i] == 1:\n",
    "        print(f\"  ‚úì Has {skill}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã REMINDER: What is 'y'?\n",
      "============================================================\n",
      "Type of y: <class 'pandas.core.series.Series'>\n",
      "Length of y: 3010\n",
      "\n",
      "First 3 people's skills:\n",
      "0    [Machine Learning, C#, AWS, Scalability, Azure...\n",
      "1    [Market Analysis, AWS, Jira, Machine Learning,...\n",
      "5    [Communication, SQL, Machine Learning, Java, AWS]\n",
      "Name: Skills_List, dtype: object\n",
      "\n",
      "Type of one element: <class 'list'>\n",
      "\n",
      "üîÑ ENCODING PROCESS\n",
      "============================================================\n",
      "\n",
      "üìä OUTPUT SHAPE\n",
      "============================================================\n",
      "y_encoded shape: (3010, 29)\n",
      "Interpretation:\n",
      "  - 3010 people (same as our dataset)\n",
      "  - 29 possible skills (learned from data)\n",
      "\n",
      "üìö WHAT ARE 'CLASSES'?\n",
      "============================================================\n",
      "Total unique skills: 29\n",
      "\n",
      "All skills (alphabetically sorted):\n",
      "  Position 0: AWS\n",
      "  Position 1: Agile\n",
      "  Position 2: Algorithms\n",
      "  Position 3: Azure\n",
      "  Position 4: C#\n",
      "  Position 5: CI/CD\n",
      "  Position 6: Communication\n",
      "  Position 7: Data Structures\n",
      "  Position 8: Data Visualization\n",
      "  Position 9: Docker\n",
      "  Position 10: Git\n",
      "  Position 11: Java\n",
      "  Position 12: Jira\n",
      "  Position 13: Kubernetes\n",
      "  Position 14: Leadership\n",
      "  Position 15: Linux\n",
      "  Position 16: Machine Learning\n",
      "  Position 17: Market Analysis\n",
      "  Position 18: Monitoring\n",
      "  Position 19: Network Security\n",
      "  Position 20: Python\n",
      "  Position 21: R\n",
      "  Position 22: Roadmapping\n",
      "  Position 23: SQL\n",
      "  Position 24: Scalability\n",
      "  Position 25: Statistics\n",
      "  Position 26: TensorFlow\n",
      "  Position 27: Terraform\n",
      "  Position 28: UX/UI Principles\n",
      "\n",
      "üîç VISUAL EXAMPLE: Person 0\n",
      "============================================================\n",
      "Original skills (y):\n",
      "  ['Machine Learning', 'C#', 'AWS', 'Scalability', 'Azure', 'Terraform', 'Network Security', 'Python']\n",
      "\n",
      "Encoded version (y_encoded):\n",
      "  [1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0]\n",
      "\n",
      "Decoding (matching 1s to skill names):\n",
      "  ‚úì Position 0: AWS\n",
      "  ‚úì Position 3: Azure\n",
      "  ‚úì Position 4: C#\n",
      "  ‚úì Position 16: Machine Learning\n",
      "  ‚úì Position 19: Network Security\n",
      "  ‚úì Position 20: Python\n",
      "  ‚úì Position 24: Scalability\n",
      "  ‚úì Position 27: Terraform\n",
      "\n",
      "üìä UNDERSTANDING THE BINARY MATRIX\n",
      "============================================================\n",
      "\n",
      "First 5 people √ó First 10 skills:\n",
      "(Rows = People, Columns = Skills)\n",
      "\n",
      "Skill names for columns 0-9:\n",
      "  Col 0: AWS\n",
      "  Col 1: Agile\n",
      "  Col 2: Algorithms\n",
      "  Col 3: Azure\n",
      "  Col 4: C#\n",
      "  Col 5: CI/CD\n",
      "  Col 6: Communication\n",
      "  Col 7: Data Structures\n",
      "  Col 8: Data Visualization\n",
      "  Col 9: Docker\n",
      "\n",
      "Binary matrix (1 = has skill, 0 = doesn't):\n",
      "[[1 0 0 1 1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 1 0]\n",
      " [1 0 0 1 1 0 0 0 0 0]]\n",
      "\n",
      "üìà SUMMARY STATISTICS\n",
      "============================================================\n",
      "Average skills per person: 6.52\n",
      "Minimum skills: 5\n",
      "Maximum skills: 8\n",
      "\n",
      "Most common skills:\n",
      "  Python: 1544 people (51.3%)\n",
      "  Agile: 1463 people (48.6%)\n",
      "  SQL: 1393 people (46.3%)\n",
      "  Communication: 1312 people (43.6%)\n",
      "  Java: 1168 people (38.8%)\n",
      "\n",
      "‚ùì WHY DO WE NEED THIS ENCODING?\n",
      "============================================================\n",
      "\n",
      "Machine Learning models ONLY understand numbers, not text.\n",
      "\n",
      "BEFORE encoding:\n",
      "  Input (X): \"Google\", \"Data Scientist\"  ‚Üê Text\n",
      "  Output (y): [\"Python\", \"SQL\", \"AWS\"]   ‚Üê Text list\n",
      "  ‚ùå Model can't process this!\n",
      "\n",
      "AFTER encoding:\n",
      "  Input (X): [1, 1]                      ‚Üê Numbers\n",
      "  Output (y): [1, 0, 1, 0, 1, 0, ...]   ‚Üê Numbers\n",
      "  ‚úÖ Model CAN process this!\n",
      "\n",
      "The model will learn patterns like:\n",
      "\"When X = [1, 1] (Google + Data Scientist)\n",
      " Then y usually = [1, 0, 1, 0, 1, ...] (Python, AWS, SQL, ...)\"\n",
      "\n",
      "\n",
      "============================================================\n",
      "üì¶ SUMMARY: WHAT WE DID IN THIS CELL\n",
      "============================================================\n",
      "\n",
      "1. Created MultiLabelBinarizer (mlb)\n",
      "   ‚Üí Tool to convert skill lists to binary format\n",
      "\n",
      "2. Fit on y (skill lists)\n",
      "   ‚Üí Learned all 29 unique skills in dataset\n",
      "\n",
      "3. Transformed y to y_encoded\n",
      "   ‚Üí Converted each person's skills to binary array\n",
      "   ‚Üí Shape: (3010 people, 29 skills)\n",
      "\n",
      "4. Each row in y_encoded represents one person\n",
      "   ‚Üí 1 = person has that skill\n",
      "   ‚Üí 0 = person doesn't have that skill\n",
      "\n",
      "5. mlb.classes_ is our \"dictionary\"\n",
      "   ‚Üí Position i in classes_ = column i in y_encoded\n",
      "   ‚Üí We use this to decode predictions back to skill names\n",
      "\n",
      "KEY VARIABLES TO REMEMBER:\n",
      "- y = Original skills (lists of strings)\n",
      "- y_encoded = Encoded skills (binary matrix)\n",
      "- mlb = The encoder (used to decode predictions later)\n",
      "- mlb.classes_ = List of all possible skills\n",
      "\n",
      "\n",
      "============================================================\n",
      "üéì EXERCISE: Test Your Understanding\n",
      "============================================================\n",
      "\n",
      "Try these commands to explore:\n",
      "\n",
      "1. Look at person 5's skills:\n",
      "   print(y.iloc[5])\n",
      "   print(y_encoded[5])\n",
      "\n",
      "2. Find which skill is at position 10:\n",
      "   print(mlb.classes_[10])\n",
      "\n",
      "3. Count how many people have Python:\n",
      "   python_column = list(mlb.classes_).index('Python')\n",
      "   print(y_encoded[:, python_column].sum())\n",
      "\n",
      "4. Find all skills for person 100:\n",
      "   for i, val in enumerate(y_encoded[100]):\n",
      "       if val == 1:\n",
      "           print(mlb.classes_[i])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 10: ENCODING - SKILLS (Multi-Label) - DETAILED VERSION\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ BIG PICTURE: What are we doing in this cell?\n",
    "==============================================\n",
    "\n",
    "We need to convert SKILL NAMES (text) into NUMBERS that the computer understands.\n",
    "\n",
    "BUT! This is different from encoding Company/Designation because:\n",
    "- Company: One person works at ONE company (single-label)\n",
    "- Designation: One person has ONE job title (single-label)\n",
    "- Skills: One person has MULTIPLE skills (multi-label)\n",
    "\n",
    "Example Person:\n",
    "- Company: \"Google\" (just one)\n",
    "- Designation: \"Data Scientist\" (just one)  \n",
    "- Skills: \"Python\", \"SQL\", \"AWS\", \"Machine Learning\" (multiple!)\n",
    "\n",
    "So we need a SPECIAL encoding called MultiLabelBinarizer.\n",
    "\n",
    "ANALOGY: Think of skills like pizza toppings\n",
    "- You can order a pizza with: Pepperoni ‚úì, Mushrooms ‚úì, Olives ‚úó, Cheese ‚úì\n",
    "- Not just ONE topping, but MULTIPLE toppings\n",
    "- We represent this as: [1, 1, 0, 1] (1 = has it, 0 = doesn't have it)\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 1: Import the tool we need\n",
    "# ----------------------------------------------------------\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# What is MultiLabelBinarizer?\n",
    "# - A tool that converts lists of labels into binary (0/1) format\n",
    "# - \"Multi\" = can handle multiple labels per person\n",
    "# - \"Binarizer\" = converts to binary (0 or 1)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 2: Create the encoder object\n",
    "# ----------------------------------------------------------\n",
    "mlb = MultiLabelBinarizer()\n",
    "# mlb = short for \"MultiLabelBinarizer\"\n",
    "# Think of this as creating a \"translator machine\"\n",
    "# Right now it's empty - hasn't learned anything yet\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 3: Remember what 'y' is? Let's review!\n",
    "# ----------------------------------------------------------\n",
    "print(\"üìã REMINDER: What is 'y'?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# y = Our OUTPUT labels (what we want to predict)\n",
    "# y = Skills for each person in our dataset\n",
    "# y is a pandas Series (column) where each row is a LIST of skills\n",
    "\n",
    "print(f\"Type of y: {type(y)}\")  \n",
    "# Result: pandas.core.series.Series\n",
    "\n",
    "print(f\"Length of y: {len(y)}\")  \n",
    "# Result: 3010 (we have 3010 people's skills)\n",
    "\n",
    "print(f\"\\nFirst 3 people's skills:\")\n",
    "print(y.head(3))\n",
    "# Shows something like:\n",
    "# 0    [Python, SQL, AWS, Machine Learning]\n",
    "# 1    [Java, Spring Boot, Kubernetes]\n",
    "# 2    [React, JavaScript, HTML, CSS]\n",
    "\n",
    "# IMPORTANT: Each element is a LIST, not a string!\n",
    "print(f\"\\nType of one element: {type(y.iloc[0])}\")\n",
    "# Result: <class 'list'>\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 4: Fit and Transform - The Magic Happens Here!\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\nüîÑ ENCODING PROCESS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# fit_transform() does TWO things:\n",
    "# 1. FIT: Learn all unique skills across ALL people\n",
    "# 2. TRANSFORM: Convert each person's skills to binary format\n",
    "\n",
    "y_encoded = mlb.fit_transform(y)\n",
    "\n",
    "# Let's break down what happened:\n",
    "# \n",
    "# BEFORE (y - text format):\n",
    "# Person 0: [\"Python\", \"SQL\", \"AWS\"]\n",
    "# Person 1: [\"Java\", \"Python\", \"Docker\"]\n",
    "# Person 2: [\"AWS\", \"Kubernetes\"]\n",
    "#\n",
    "# STEP 1 - FIT: mlb learns ALL unique skills:\n",
    "# [\"Python\", \"SQL\", \"AWS\", \"Java\", \"Docker\", \"Kubernetes\"]\n",
    "#  Position: 0,  1,    2,    3,     4,       5\n",
    "#\n",
    "# STEP 2 - TRANSFORM: Convert each person to binary:\n",
    "# Person 0: [1, 1, 1, 0, 0, 0]  ‚Üê Has Python, SQL, AWS\n",
    "# Person 1: [1, 0, 0, 1, 1, 0]  ‚Üê Has Python, Java, Docker\n",
    "# Person 2: [0, 0, 1, 0, 0, 1]  ‚Üê Has AWS, Kubernetes\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 5: Understand the output shape\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìä OUTPUT SHAPE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"y_encoded shape: {y_encoded.shape}\")\n",
    "# Result: (3010, 29)\n",
    "# What does this mean?\n",
    "# - 3010 = number of people (rows)\n",
    "# - 29 = number of unique skills (columns)\n",
    "# So it's a giant table: 3010 rows √ó 29 columns\n",
    "\n",
    "print(f\"Interpretation:\")\n",
    "print(f\"  - {y_encoded.shape[0]} people (same as our dataset)\")\n",
    "print(f\"  - {y_encoded.shape[1]} possible skills (learned from data)\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 6: What are mlb.classes_?\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìö WHAT ARE 'CLASSES'?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# mlb.classes_ = List of ALL unique skills mlb learned\n",
    "# Think of it as a \"dictionary\" or \"legend\"\n",
    "# Position in this list = column number in y_encoded\n",
    "\n",
    "all_skills = mlb.classes_\n",
    "print(f\"Total unique skills: {len(all_skills)}\")\n",
    "print(f\"\\nAll skills (alphabetically sorted):\")\n",
    "for i, skill in enumerate(all_skills):\n",
    "    print(f\"  Position {i}: {skill}\")\n",
    "\n",
    "# Why is this important?\n",
    "# When y_encoded[0] = [1, 0, 1, 0, ...]\n",
    "# Position 0 in the array corresponds to mlb.classes_[0]\n",
    "# Position 1 corresponds to mlb.classes_[1], etc.\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 7: Visual Example - See the Transformation\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüîç VISUAL EXAMPLE: Person 0\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Pick first person\n",
    "person_index = 0\n",
    "\n",
    "# ORIGINAL (text list)\n",
    "print(f\"Original skills (y):\")\n",
    "print(f\"  {y.iloc[person_index]}\")  \n",
    "# .iloc[0] = get element at position 0\n",
    "# Result: ['Python', 'SQL', 'AWS', 'Machine Learning', ...]\n",
    "\n",
    "# ENCODED (binary array)\n",
    "print(f\"\\nEncoded version (y_encoded):\")\n",
    "print(f\"  {y_encoded[person_index]}\")\n",
    "# Result: [1 0 1 0 1 1 0 0 1 0 ...]\n",
    "# Array of 0s and 1s (29 numbers total)\n",
    "\n",
    "# DECODE: Match 1s to skill names\n",
    "print(f\"\\nDecoding (matching 1s to skill names):\")\n",
    "for i, has_skill in enumerate(y_encoded[person_index]):\n",
    "    # i = position (0, 1, 2, ...)\n",
    "    # has_skill = value at that position (0 or 1)\n",
    "    \n",
    "    if has_skill == 1:  # If person has this skill\n",
    "        skill_name = mlb.classes_[i]  # Get skill name at this position\n",
    "        print(f\"  ‚úì Position {i}: {skill_name}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 8: Understanding the Binary Matrix\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìä UNDERSTANDING THE BINARY MATRIX\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Let's look at first 5 people, first 10 skills\n",
    "print(\"\\nFirst 5 people √ó First 10 skills:\")\n",
    "print(\"(Rows = People, Columns = Skills)\")\n",
    "print(\"\\nSkill names for columns 0-9:\")\n",
    "for i in range(10):\n",
    "    print(f\"  Col {i}: {mlb.classes_[i]}\")\n",
    "\n",
    "print(\"\\nBinary matrix (1 = has skill, 0 = doesn't):\")\n",
    "print(y_encoded[:5, :10])  \n",
    "# [:5, :10] means:\n",
    "# [:5] = first 5 rows (people)\n",
    "# [:10] = first 10 columns (skills)\n",
    "\n",
    "# Example interpretation:\n",
    "# If row 0, column 3 = 1, then Person 0 has the skill at position 3\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 9: Summary Statistics\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìà SUMMARY STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# How many skills does each person have?\n",
    "skills_per_person = y_encoded.sum(axis=1)  \n",
    "# axis=1 means sum across columns (for each row)\n",
    "# Gives us count of 1s in each row = number of skills per person\n",
    "\n",
    "print(f\"Average skills per person: {skills_per_person.mean():.2f}\")\n",
    "print(f\"Minimum skills: {skills_per_person.min()}\")\n",
    "print(f\"Maximum skills: {skills_per_person.max()}\")\n",
    "\n",
    "# How common is each skill?\n",
    "skill_frequency = y_encoded.sum(axis=0)  \n",
    "# axis=0 means sum down rows (for each column)\n",
    "# Gives us count of 1s in each column = how many people have that skill\n",
    "\n",
    "print(f\"\\nMost common skills:\")\n",
    "top_skills_indices = skill_frequency.argsort()[-5:][::-1]  \n",
    "# argsort() = get indices that would sort the array\n",
    "# [-5:] = last 5 (highest values)\n",
    "# [::-1] = reverse order (highest to lowest)\n",
    "\n",
    "for idx in top_skills_indices:\n",
    "    skill_name = mlb.classes_[idx]\n",
    "    count = skill_frequency[idx]\n",
    "    percentage = (count / len(y_encoded)) * 100\n",
    "    print(f\"  {skill_name}: {count} people ({percentage:.1f}%)\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 10: Why do we need this encoding?\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n‚ùì WHY DO WE NEED THIS ENCODING?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "Machine Learning models ONLY understand numbers, not text.\n",
    "\n",
    "BEFORE encoding:\n",
    "  Input (X): \"Google\", \"Data Scientist\"  ‚Üê Text\n",
    "  Output (y): [\"Python\", \"SQL\", \"AWS\"]   ‚Üê Text list\n",
    "  ‚ùå Model can't process this!\n",
    "\n",
    "AFTER encoding:\n",
    "  Input (X): [1, 1]                      ‚Üê Numbers\n",
    "  Output (y): [1, 0, 1, 0, 1, 0, ...]   ‚Üê Numbers\n",
    "  ‚úÖ Model CAN process this!\n",
    "\n",
    "The model will learn patterns like:\n",
    "\"When X = [1, 1] (Google + Data Scientist)\n",
    " Then y usually = [1, 0, 1, 0, 1, ...] (Python, AWS, SQL, ...)\"\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SUMMARY BOX\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"üì¶ SUMMARY: WHAT WE DID IN THIS CELL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "1. Created MultiLabelBinarizer (mlb)\n",
    "   ‚Üí Tool to convert skill lists to binary format\n",
    "\n",
    "2. Fit on y (skill lists)\n",
    "   ‚Üí Learned all {len(mlb.classes_)} unique skills in dataset\n",
    "\n",
    "3. Transformed y to y_encoded\n",
    "   ‚Üí Converted each person's skills to binary array\n",
    "   ‚Üí Shape: ({y_encoded.shape[0]} people, {y_encoded.shape[1]} skills)\n",
    "\n",
    "4. Each row in y_encoded represents one person\n",
    "   ‚Üí 1 = person has that skill\n",
    "   ‚Üí 0 = person doesn't have that skill\n",
    "\n",
    "5. mlb.classes_ is our \"dictionary\"\n",
    "   ‚Üí Position i in classes_ = column i in y_encoded\n",
    "   ‚Üí We use this to decode predictions back to skill names\n",
    "\n",
    "KEY VARIABLES TO REMEMBER:\n",
    "- y = Original skills (lists of strings)\n",
    "- y_encoded = Encoded skills (binary matrix)\n",
    "- mlb = The encoder (used to decode predictions later)\n",
    "- mlb.classes_ = List of all possible skills\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# LEARNING EXERCISE\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"üéì EXERCISE: Test Your Understanding\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "Try these commands to explore:\n",
    "\n",
    "1. Look at person 5's skills:\n",
    "   print(y.iloc[5])\n",
    "   print(y_encoded[5])\n",
    "\n",
    "2. Find which skill is at position 10:\n",
    "   print(mlb.classes_[10])\n",
    "\n",
    "3. Count how many people have Python:\n",
    "   python_column = list(mlb.classes_).index('Python')\n",
    "   print(y_encoded[:, python_column].sum())\n",
    "\n",
    "4. Find all skills for person 100:\n",
    "   for i, val in enumerate(y_encoded[100]):\n",
    "       if val == 1:\n",
    "           print(mlb.classes_[i])\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f70eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù VARIABLE CHEAT SHEET (Copy this to remember!)\n",
      "==================================================\n",
      "\n",
      "X = INPUT FEATURES (what we know)\n",
      "  - Original: df[['Company', 'Designation']]\n",
      "  - Type: pandas DataFrame\n",
      "  - Shape: (3010, 2)\n",
      "  - Contains: Company names and job titles (text)\n",
      "\n",
      "y = OUTPUT LABELS (what we want to predict)\n",
      "  - Original: df['Skills_List']\n",
      "  - Type: pandas Series\n",
      "  - Length: 3010\n",
      "  - Contains: Lists of skills for each person\n",
      "  - Example: y.iloc[0] = ['Python', 'SQL', 'AWS']\n",
      "\n",
      "y_encoded = ENCODED OUTPUT (binary matrix)\n",
      "  - Type: numpy array\n",
      "  - Shape: (3010, 29)\n",
      "  - Contains: 0s and 1s\n",
      "  - Each row = one person's skills in binary\n",
      "  - Example: [1, 0, 1, 0, 1, ...] means has skill 0, 2, 4...\n",
      "\n",
      "mlb = ENCODER OBJECT (MultiLabelBinarizer)\n",
      "  - Tool that converts skill lists ‚Üî binary format\n",
      "  - Has memory of all unique skills\n",
      "\n",
      "mlb.classes_ = SKILL DICTIONARY\n",
      "  - Array of all unique skill names\n",
      "  - Type: numpy array\n",
      "  - Length: 29 (number of unique skills)\n",
      "  - Used to decode: y_encoded ‚Üí skill names\n",
      "\n",
      "IMPORTANT METHODS:\n",
      "==================\n",
      "\n",
      ".iloc[i] - Get element at position i\n",
      "  Example: y.iloc[0] = first person's skills\n",
      "\n",
      ".shape - Get dimensions of array/dataframe\n",
      "  Example: y_encoded.shape = (3010, 29)\n",
      "\n",
      ".classes_ - Get all unique labels learned by encoder\n",
      "  Example: mlb.classes_ = array of 29 skill names\n",
      "\n",
      ".fit() - Learn unique values from data\n",
      ".transform() - Convert data using learned values\n",
      ".fit_transform() - Do both in one step\n",
      "\n",
      ".sum(axis=0) - Sum down columns\n",
      ".sum(axis=1) - Sum across rows\n",
      "\n",
      "QUICK TESTS TO REMEMBER VARIABLES:\n",
      "===================================\n",
      "\n",
      "print(f\"X shape: {X.shape}\")           ‚Üí (3010, 2)\n",
      "print(f\"y length: {len(y)}\")           ‚Üí 3010\n",
      "print(f\"y_encoded shape: {y_encoded.shape}\")  ‚Üí (3010, 29)\n",
      "print(f\"Number of skills: {len(mlb.classes_)}\")  ‚Üí 29\n",
      "\n",
      "print(y.iloc[0])              ‚Üí ['Python', 'SQL', ...]\n",
      "print(y_encoded[0])           ‚Üí [1 0 1 0 1 1 0 ...]\n",
      "print(mlb.classes_[0])        ‚Üí 'Agile' (or whatever skill)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# QUICK REFERENCE CARD - PASTE THIS IN A NEW CELL\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "üìù VARIABLE CHEAT SHEET (Copy this to remember!)\n",
    "==================================================\n",
    "\n",
    "X = INPUT FEATURES (what we know)\n",
    "  - Original: df[['Company', 'Designation']]\n",
    "  - Type: pandas DataFrame\n",
    "  - Shape: (3010, 2)\n",
    "  - Contains: Company names and job titles (text)\n",
    "\n",
    "y = OUTPUT LABELS (what we want to predict)\n",
    "  - Original: df['Skills_List']\n",
    "  - Type: pandas Series\n",
    "  - Length: 3010\n",
    "  - Contains: Lists of skills for each person\n",
    "  - Example: y.iloc[0] = ['Python', 'SQL', 'AWS']\n",
    "\n",
    "y_encoded = ENCODED OUTPUT (binary matrix)\n",
    "  - Type: numpy array\n",
    "  - Shape: (3010, 29)\n",
    "  - Contains: 0s and 1s\n",
    "  - Each row = one person's skills in binary\n",
    "  - Example: [1, 0, 1, 0, 1, ...] means has skill 0, 2, 4...\n",
    "\n",
    "mlb = ENCODER OBJECT (MultiLabelBinarizer)\n",
    "  - Tool that converts skill lists ‚Üî binary format\n",
    "  - Has memory of all unique skills\n",
    "\n",
    "mlb.classes_ = SKILL DICTIONARY\n",
    "  - Array of all unique skill names\n",
    "  - Type: numpy array\n",
    "  - Length: 29 (number of unique skills)\n",
    "  - Used to decode: y_encoded ‚Üí skill names\n",
    "\n",
    "IMPORTANT METHODS:\n",
    "==================\n",
    "\n",
    ".iloc[i] - Get element at position i\n",
    "  Example: y.iloc[0] = first person's skills\n",
    "\n",
    ".shape - Get dimensions of array/dataframe\n",
    "  Example: y_encoded.shape = (3010, 29)\n",
    "\n",
    ".classes_ - Get all unique labels learned by encoder\n",
    "  Example: mlb.classes_ = array of 29 skill names\n",
    "\n",
    ".fit() - Learn unique values from data\n",
    ".transform() - Convert data using learned values\n",
    ".fit_transform() - Do both in one step\n",
    "\n",
    ".sum(axis=0) - Sum down columns\n",
    ".sum(axis=1) - Sum across rows\n",
    "\n",
    "QUICK TESTS TO REMEMBER VARIABLES:\n",
    "===================================\n",
    "\n",
    "print(f\"X shape: {X.shape}\")           ‚Üí (3010, 2)\n",
    "print(f\"y length: {len(y)}\")           ‚Üí 3010\n",
    "print(f\"y_encoded shape: {y_encoded.shape}\")  ‚Üí (3010, 29)\n",
    "print(f\"Number of skills: {len(mlb.classes_)}\")  ‚Üí 29\n",
    "\n",
    "print(y.iloc[0])              ‚Üí ['Python', 'SQL', ...]\n",
    "print(y_encoded[0])           ‚Üí [1 0 1 0 1 1 0 ...]\n",
    "print(mlb.classes_[0])        ‚Üí 'Agile' (or whatever skill)\n",
    "\"\"\"\n",
    "\n",
    "# Print this card\n",
    "print(__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af8102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding complete! Columns now are:\n",
      "   Company_Encoded  Designation_Encoded\n",
      "0                3                    0\n",
      "1                0                    3\n",
      "5                4                    0\n",
      "6                2                    1\n",
      "7                3                    0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ENCODE Company + Designation  (FINAL FIX)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "company_encoder = LabelEncoder()\n",
    "designation_encoder = LabelEncoder()\n",
    "\n",
    "# Encode inside df\n",
    "df['Company_Encoded'] = company_encoder.fit_transform(df['Company'])\n",
    "df['Designation_Encoded'] = designation_encoder.fit_transform(df['Designation'])\n",
    "\n",
    "print(\"Encoding complete! Columns now are:\")\n",
    "print(df[['Company_Encoded', 'Designation_Encoded']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5409a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designation classes found:\n",
      "['Cloud Architect' 'Data Scientist' 'DevOps Engineer' 'Product Manager'\n",
      " 'Software Engineer']\n",
      "\n",
      "Top 5 rows of encoded designation:\n",
      "       Designation  Designation_Encoded\n",
      "0  Cloud Architect                    0\n",
      "1  Product Manager                    3\n",
      "5  Cloud Architect                    0\n",
      "6   Data Scientist                    1\n",
      "7  Cloud Architect                    0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FIX: ENCODE DESIGNATION PROPERLY\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "designation_encoder = LabelEncoder()\n",
    "\n",
    "# Fit encoder\n",
    "designation_encoder.fit(X['Designation'])\n",
    "\n",
    "print(\"Designation classes found:\")\n",
    "print(designation_encoder.classes_)\n",
    "\n",
    "# Transform and ADD column\n",
    "X['Designation_Encoded'] = designation_encoder.transform(X['Designation'])\n",
    "\n",
    "# Verify\n",
    "print(\"\\nTop 5 rows of encoded designation:\")\n",
    "print(X[['Designation', 'Designation_Encoded']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a8401b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã CURRENT STATE OF OUR DATA\n",
      "======================================================================\n",
      "X columns: ['Company', 'Designation', 'Company_Encoded', 'Designation_Encoded']\n",
      "X shape: (3010, 4)\n",
      "\n",
      "First 3 rows of X:\n",
      "      Company      Designation  Company_Encoded  Designation_Encoded\n",
      "0   Microsoft  Cloud Architect                3                    0\n",
      "1      Amazon  Product Manager                0                    3\n",
      "5  Salesforce  Cloud Architect                4                    0\n",
      "\n",
      "üéØ SELECTING ENCODED COLUMNS ONLY\n",
      "======================================================================\n",
      "X_encoded shape: (3010, 2)\n",
      "X_encoded columns: ['Company_Encoded', 'Designation_Encoded']\n",
      "\n",
      "üëÄ BEFORE vs AFTER\n",
      "======================================================================\n",
      "BEFORE (X - has both text and numbers):\n",
      "      Company      Designation  Company_Encoded  Designation_Encoded\n",
      "0   Microsoft  Cloud Architect                3                    0\n",
      "1      Amazon  Product Manager                0                    3\n",
      "5  Salesforce  Cloud Architect                4                    0\n",
      "\n",
      "AFTER (X_encoded - only numbers):\n",
      "   Company_Encoded  Designation_Encoded\n",
      "0                3                    0\n",
      "1                0                    3\n",
      "5                4                    0\n",
      "\n",
      "‚ùì WHY SELECT ONLY ENCODED COLUMNS?\n",
      "======================================================================\n",
      "\n",
      "Reason 1: ML models can't read text\n",
      "  - \"Google\" ‚ùå Model doesn't understand\n",
      "  - 1 ‚úÖ Model understands\n",
      "  \n",
      "Reason 2: Consistency\n",
      "  - We want ONLY numbers as input\n",
      "  - No mixing text and numbers\n",
      "  \n",
      "Reason 3: Model training requirements\n",
      "  - sklearn models expect numeric arrays\n",
      "  - Text columns would cause errors\n",
      "\n",
      "BEFORE:\n",
      "X = ['Google', 'Data Scientist', 1, 1]  ‚Üê Mixed text + numbers ‚ùå\n",
      "\n",
      "AFTER:\n",
      "X_encoded = [1, 1]  ‚Üê Only numbers ‚úÖ\n",
      "\n",
      "\n",
      "‚úÖ SANITY CHECKS\n",
      "======================================================================\n",
      "Number of people in X_encoded: 3010\n",
      "Number of people in y_encoded: 3010\n",
      "Do they match? True\n",
      "\n",
      "Data types in X_encoded:\n",
      "Company_Encoded        int64\n",
      "Designation_Encoded    int64\n",
      "dtype: object\n",
      "\n",
      "Missing values in X_encoded:\n",
      "Company_Encoded        0\n",
      "Designation_Encoded    0\n",
      "dtype: int64\n",
      "\n",
      "üîó THE CONNECTION\n",
      "======================================================================\n",
      "Example: Person at index 0\n",
      "\n",
      "1. ORIGINAL DATA:\n",
      "   Company: 'Microsoft'\n",
      "   Designation: 'Cloud Architect'\n",
      "   Skills: ['Machine Learning', 'C#', 'AWS', 'Scalability', 'Azure', 'Terraform', 'Network Security', 'Python']\n",
      "\n",
      "2. ENCODED INPUT (X_encoded):\n",
      "   [3 0]\n",
      "   Meaning: Company=3, Designation=0\n",
      "\n",
      "3. ENCODED OUTPUT (y_encoded):\n",
      "   [1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0]\n",
      "   (Binary array of 29 values)\n",
      "\n",
      "This is what the model will learn:\n",
      "When INPUT = [3 0]\n",
      "Then OUTPUT should be [1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0]\n",
      "\n",
      "======================================================================\n",
      "üì¶ SUMMARY: CELL 11\n",
      "======================================================================\n",
      "\n",
      "WHAT WE DID:\n",
      "1. Selected ONLY the encoded columns from X\n",
      "2. Created X_encoded with shape (3010, 2)\n",
      "3. Verified it matches y_encoded length\n",
      "\n",
      "KEY VARIABLES NOW:\n",
      "- X_encoded: Input features (numbers only)\n",
      "  ‚Üí Shape: (3010, 2)\n",
      "  ‚Üí Contains: [Company_Encoded, Designation_Encoded]\n",
      "  \n",
      "- y_encoded: Output labels (numbers only)\n",
      "  ‚Üí Shape: (3010, 29)\n",
      "  ‚Üí Contains: Binary matrix of skills\n",
      "\n",
      "READY FOR: Train-test split and model training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 11: PREPARE FINAL INPUTS - SUPER DETAILED\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ BIG PICTURE: What are we doing in this cell?\n",
    "==============================================\n",
    "\n",
    "Remember we encoded THREE things:\n",
    "1. Company names ‚Üí numbers (company_encoder)\n",
    "2. Designation names ‚Üí numbers (designation_encoder)\n",
    "3. Skills lists ‚Üí binary matrix (mlb)\n",
    "\n",
    "Now we need to combine the encoded Company + Designation into ONE input array\n",
    "that our ML model can use.\n",
    "\n",
    "ANALOGY: Packing a suitcase\n",
    "- You have clothes in different drawers (Company_Encoded, Designation_Encoded)\n",
    "- You need to pack them into ONE suitcase (X_encoded)\n",
    "- Model needs everything in one neat package!\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 1: Reminder - What do we have so far?\n",
    "# ----------------------------------------------------------\n",
    "print(\"üìã CURRENT STATE OF OUR DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Let's see what columns X has right now\n",
    "print(f\"X columns: {list(X.columns)}\")\n",
    "# Result: ['Company', 'Designation', 'Company_Encoded', 'Designation_Encoded']\n",
    "# We have BOTH original text AND encoded numbers\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "# Result: (3010, 4) - 3010 people, 4 columns\n",
    "\n",
    "# Let's look at first 3 rows\n",
    "print(f\"\\nFirst 3 rows of X:\")\n",
    "print(X.head(3))\n",
    "# You'll see something like:\n",
    "#   Company    Designation        Company_Encoded  Designation_Encoded\n",
    "# 0 Microsoft  Cloud Architect    3                0\n",
    "# 1 Amazon     Product Manager    0                3\n",
    "# 2 Google     Cloud Architect    1                0\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 2: Select ONLY the encoded columns\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüéØ SELECTING ENCODED COLUMNS ONLY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# We ONLY want the number columns, not the text columns\n",
    "# Why? Because ML models only understand numbers!\n",
    "\n",
    "X_encoded = X[['Company_Encoded', 'Designation_Encoded']]\n",
    "# This is like selecting specific columns from a spreadsheet\n",
    "# X[['col1', 'col2']] = select columns 'col1' and 'col2'\n",
    "\n",
    "print(f\"X_encoded shape: {X_encoded.shape}\")\n",
    "# Result: (3010, 2) - 3010 people, 2 columns (just the numbers!)\n",
    "\n",
    "print(f\"X_encoded columns: {list(X_encoded.columns)}\")\n",
    "# Result: ['Company_Encoded', 'Designation_Encoded']\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 3: Visualize what we did\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüëÄ BEFORE vs AFTER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"BEFORE (X - has both text and numbers):\")\n",
    "print(X.head(3))\n",
    "\n",
    "print(f\"\\nAFTER (X_encoded - only numbers):\")\n",
    "print(X_encoded.head(3))\n",
    "\n",
    "# Example interpretation:\n",
    "# Row 0: [3, 0] means Company=3 (Microsoft), Designation=0 (Cloud Architect)\n",
    "# Row 1: [0, 3] means Company=0 (Amazon), Designation=3 (Product Manager)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 4: Why do we do this?\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n‚ùì WHY SELECT ONLY ENCODED COLUMNS?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "Reason 1: ML models can't read text\n",
    "  - \"Google\" ‚ùå Model doesn't understand\n",
    "  - 1 ‚úÖ Model understands\n",
    "  \n",
    "Reason 2: Consistency\n",
    "  - We want ONLY numbers as input\n",
    "  - No mixing text and numbers\n",
    "  \n",
    "Reason 3: Model training requirements\n",
    "  - sklearn models expect numeric arrays\n",
    "  - Text columns would cause errors\n",
    "\n",
    "BEFORE:\n",
    "X = ['Google', 'Data Scientist', 1, 1]  ‚Üê Mixed text + numbers ‚ùå\n",
    "\n",
    "AFTER:\n",
    "X_encoded = [1, 1]  ‚Üê Only numbers ‚úÖ\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 5: Final sanity checks\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n‚úÖ SANITY CHECKS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check 1: Shape matches\n",
    "print(f\"Number of people in X_encoded: {X_encoded.shape[0]}\")\n",
    "print(f\"Number of people in y_encoded: {y_encoded.shape[0]}\")\n",
    "print(f\"Do they match? {X_encoded.shape[0] == y_encoded.shape[0]}\")\n",
    "# MUST be True! Input and output must have same number of samples\n",
    "\n",
    "# Check 2: Data types\n",
    "print(f\"\\nData types in X_encoded:\")\n",
    "print(X_encoded.dtypes)\n",
    "# Should show int32 or int64 (integer types)\n",
    "\n",
    "# Check 3: No missing values\n",
    "print(f\"\\nMissing values in X_encoded:\")\n",
    "print(X_encoded.isnull().sum())\n",
    "# Should show 0 for both columns\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 6: Understanding the connection\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüîó THE CONNECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Let's trace one example through the entire pipeline\n",
    "example_idx = 0\n",
    "\n",
    "print(f\"Example: Person at index {example_idx}\")\n",
    "print(f\"\\n1. ORIGINAL DATA:\")\n",
    "print(f\"   Company: '{df.loc[example_idx, 'Company']}'\")\n",
    "print(f\"   Designation: '{df.loc[example_idx, 'Designation']}'\")\n",
    "print(f\"   Skills: {df.loc[example_idx, 'Skills_List']}\")\n",
    "\n",
    "print(f\"\\n2. ENCODED INPUT (X_encoded):\")\n",
    "print(f\"   {X_encoded.iloc[example_idx].values}\")\n",
    "print(f\"   Meaning: Company={X_encoded.iloc[example_idx, 0]}, Designation={X_encoded.iloc[example_idx, 1]}\")\n",
    "\n",
    "print(f\"\\n3. ENCODED OUTPUT (y_encoded):\")\n",
    "print(f\"   {y_encoded[example_idx]}\")\n",
    "print(f\"   (Binary array of {len(y_encoded[example_idx])} values)\")\n",
    "\n",
    "print(f\"\\nThis is what the model will learn:\")\n",
    "print(f\"When INPUT = {X_encoded.iloc[example_idx].values}\")\n",
    "print(f\"Then OUTPUT should be {y_encoded[example_idx]}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SUMMARY BOX\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"üì¶ SUMMARY: CELL 11\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\"\"\n",
    "WHAT WE DID:\n",
    "1. Selected ONLY the encoded columns from X\n",
    "2. Created X_encoded with shape ({X_encoded.shape[0]}, {X_encoded.shape[1]})\n",
    "3. Verified it matches y_encoded length\n",
    "\n",
    "KEY VARIABLES NOW:\n",
    "- X_encoded: Input features (numbers only)\n",
    "  ‚Üí Shape: ({X_encoded.shape[0]}, {X_encoded.shape[1]})\n",
    "  ‚Üí Contains: [Company_Encoded, Designation_Encoded]\n",
    "  \n",
    "- y_encoded: Output labels (numbers only)\n",
    "  ‚Üí Shape: ({y_encoded.shape[0]}, {y_encoded.shape[1]})\n",
    "  ‚Üí Contains: Binary matrix of skills\n",
    "\n",
    "READY FOR: Train-test split and model training!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ea75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Company', 'Designation', 'Company_Encoded', 'Designation_Encoded'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a1d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã BEFORE SPLITTING\n",
      "======================================================================\n",
      "X_encoded shape: (3010, 2)\n",
      "y_encoded shape: (3010, 29)\n",
      "\n",
      "Total examples: 3010\n",
      "\n",
      "‚úÇÔ∏è SPLITTING DATA\n",
      "======================================================================\n",
      "\n",
      "üîç WHAT DID WE GET?\n",
      "======================================================================\n",
      "1. X_train: Training inputs\n",
      "   Shape: (2408, 2)\n",
      "\n",
      "2. X_test: Testing inputs\n",
      "   Shape: (602, 2)\n",
      "\n",
      "3. y_train: Training outputs (skills for training examples)\n",
      "   Shape: (2408, 29)\n",
      "\n",
      "4. y_test: Testing outputs (skills for testing examples)\n",
      "   Shape: (602, 29)\n",
      "\n",
      "‚úÖ VERIFICATION\n",
      "======================================================================\n",
      "Training examples: 2408\n",
      "Testing examples: 602\n",
      "Total: 3010\n",
      "Original: 3010\n",
      "Match? True ‚úì\n",
      "\n",
      "Training percentage: 80.0%\n",
      "Testing percentage: 20.0%\n",
      "\n",
      "X_train and y_train same length? True ‚úì\n",
      "X_test and y_test same length? True ‚úì\n",
      "\n",
      "üìä VISUALIZING THE SPLIT\n",
      "======================================================================\n",
      "\n",
      "ORIGINAL DATA (3010 examples):\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ Person 1, Person 2, Person 3, ... Person 3010 ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "AFTER SPLIT:\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ      TRAINING SET (80%)      ‚îÇ  ‚îÇ TEST SET (20%)‚îÇ\n",
      "‚îÇ   Person 1, 5, 7, 9, 11...   ‚îÇ  ‚îÇ Person 2, 4...‚îÇ\n",
      "‚îÇ        2408 people           ‚îÇ  ‚îÇ  602 people   ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "         ‚Üì                                ‚Üì\n",
      "   Model LEARNS here            Model TESTED here\n",
      "   (sees these examples)         (never seen before!)\n",
      "\n",
      "\n",
      "üëÄ EXAMPLE DATA\n",
      "======================================================================\n",
      "First 3 TRAINING examples:\n",
      "X_train (inputs):\n",
      "      Company_Encoded  Designation_Encoded\n",
      "2777                1                    4\n",
      "2483                2                    2\n",
      "4183                0                    0\n",
      "\n",
      "y_train (outputs - first 10 skills):\n",
      "[[0 1 1 0 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "First 3 TESTING examples:\n",
      "X_test (inputs):\n",
      "      Company_Encoded  Designation_Encoded\n",
      "4806                2                    0\n",
      "934                 2                    2\n",
      "4756                3                    4\n",
      "\n",
      "y_test (outputs - first 10 skills):\n",
      "[[0 0 0 1 0 0 1 0 0 0]\n",
      " [0 1 0 0 1 0 1 0 0 0]\n",
      " [1 0 1 0 1 0 0 0 0 0]]\n",
      "\n",
      "üé≤ WHY RANDOM_STATE=42?\n",
      "======================================================================\n",
      "\n",
      "Without random_state:\n",
      "  Run 1: Person 5 in training, Person 10 in testing\n",
      "  Run 2: Person 5 in testing, Person 10 in training  ‚Üê Different!\n",
      "  Result: Can't reproduce results, can't debug issues\n",
      "\n",
      "With random_state=42:\n",
      "  Run 1: Person 5 in training, Person 10 in testing\n",
      "  Run 2: Person 5 in training, Person 10 in testing  ‚Üê Same!\n",
      "  Result: Reproducible! Anyone can verify your results\n",
      "\n",
      "The number 42 is arbitrary - could be 1, 100, 999, anything!\n",
      "It's just a popular choice among programmers.\n",
      "\n",
      "\n",
      "üöÄ NEXT STEPS\n",
      "======================================================================\n",
      "\n",
      "Now we have:\n",
      "‚úì X_train, y_train - for teaching the model\n",
      "‚úì X_test, y_test - for testing the model\n",
      "\n",
      "Next cell:\n",
      "1. Create ML model (Random Forest)\n",
      "2. Train model using X_train and y_train\n",
      "3. Model will learn: \"When I see X_train[0], output should be y_train[0]\"\n",
      "4. Model finds patterns across all 2408 training examples\n",
      "\n",
      "Later:\n",
      "5. Test model on X_test (data it's NEVER seen!)\n",
      "6. Compare predictions to y_test (actual answers)\n",
      "7. Calculate accuracy\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üì¶ SUMMARY: CELL 12\n",
      "======================================================================\n",
      "\n",
      "WHAT WE DID:\n",
      "Split data into training and testing sets\n",
      "\n",
      "TRAINING SET (80%):\n",
      "- X_train: 2408 examples, 2 features\n",
      "- y_train: 2408 examples, 29 skills\n",
      "- Purpose: Model learns from this data\n",
      "\n",
      "TESTING SET (20%):\n",
      "- X_test: 602 examples, 2 features\n",
      "- y_test: 602 examples, 29 skills\n",
      "- Purpose: Model tested on this data (never seen before!)\n",
      "\n",
      "KEY CONCEPT:\n",
      "Training set = Study guide\n",
      "Testing set = Final exam\n",
      "We want model to pass the exam, not just memorize answers!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 12: TRAIN-TEST SPLIT - SUPER DETAILED\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ BIG PICTURE: What are we doing in this cell?\n",
    "==============================================\n",
    "\n",
    "Imagine you're studying for an exam:\n",
    "- TRAINING SET = Practice problems you study from\n",
    "- TEST SET = Actual exam questions (you've never seen these!)\n",
    "\n",
    "We split our data into two groups:\n",
    "1. Training set (80%) - Model learns from this\n",
    "2. Test set (20%) - Model is tested on this\n",
    "\n",
    "WHY? To see if the model really LEARNED or just MEMORIZED!\n",
    "\n",
    "ANALOGY: Learning to ride a bike\n",
    "- Training: Practice in your driveway (safe, familiar)\n",
    "- Testing: Ride to school (new route, real test!)\n",
    "\n",
    "If you can only ride in your driveway, you didn't really learn!\n",
    "If the model only works on training data, it didn't really learn!\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 1: Import the tool we need\n",
    "# ----------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_test_split = Function that randomly splits data\n",
    "# \"model_selection\" = Part of sklearn that helps select best model\n",
    "# We'll use this to create training and testing sets\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 2: Current state of data\n",
    "# ----------------------------------------------------------\n",
    "print(\"üìã BEFORE SPLITTING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"X_encoded shape: {X_encoded.shape}\")\n",
    "# (3010, 2) - We have 3010 examples, each with 2 features\n",
    "\n",
    "print(f\"y_encoded shape: {y_encoded.shape}\")\n",
    "# (3010, 29) - Same 3010 examples, each with 29 skill labels\n",
    "\n",
    "print(f\"\\nTotal examples: {X_encoded.shape[0]}\")\n",
    "# 3010 people total\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 3: Perform the split\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n‚úÇÔ∏è SPLITTING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# This is the MOST IMPORTANT line!\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded,       # Input features to split\n",
    "    y_encoded,       # Output labels to split\n",
    "    test_size=0.2,   # 20% for testing, 80% for training\n",
    "    random_state=42  # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Let's break down each parameter:\n",
    "\n",
    "# X_encoded:\n",
    "#   - The INPUT data (Company_Encoded, Designation_Encoded)\n",
    "#   - Will be split into X_train and X_test\n",
    "\n",
    "# y_encoded:\n",
    "#   - The OUTPUT data (skill binary matrix)\n",
    "#   - Will be split into y_train and y_test\n",
    "\n",
    "# test_size=0.2:\n",
    "#   - 0.2 = 20% of data goes to testing\n",
    "#   - Remaining 0.8 = 80% goes to training\n",
    "#   - Could also write test_size=0.2 or train_size=0.8\n",
    "\n",
    "# random_state=42:\n",
    "#   - Random seed number (could be any number)\n",
    "#   - Makes split reproducible (same split every time you run)\n",
    "#   - Without this, you'd get different splits each time\n",
    "#   - 42 is popular (from \"Hitchhiker's Guide to the Galaxy\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 4: Understanding the output\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüîç WHAT DID WE GET?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# train_test_split returns 4 things:\n",
    "\n",
    "print(\"1. X_train: Training inputs\")\n",
    "print(f\"   Shape: {X_train.shape}\")\n",
    "# (2408, 2) - About 80% of 3010 = 2408 examples\n",
    "\n",
    "print(\"\\n2. X_test: Testing inputs\")\n",
    "print(f\"   Shape: {X_test.shape}\")\n",
    "# (602, 2) - About 20% of 3010 = 602 examples\n",
    "\n",
    "print(\"\\n3. y_train: Training outputs (skills for training examples)\")\n",
    "print(f\"   Shape: {y_train.shape}\")\n",
    "# (2408, 29) - Same 2408 examples, 29 skills each\n",
    "\n",
    "print(\"\\n4. y_test: Testing outputs (skills for testing examples)\")\n",
    "print(f\"   Shape: {y_test.shape}\")\n",
    "# (602, 29) - Same 602 examples, 29 skills each\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 5: Verify the split\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n‚úÖ VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check 1: Total adds up\n",
    "total_train = X_train.shape[0]\n",
    "total_test = X_test.shape[0]\n",
    "total_original = X_encoded.shape[0]\n",
    "\n",
    "print(f\"Training examples: {total_train}\")\n",
    "print(f\"Testing examples: {total_test}\")\n",
    "print(f\"Total: {total_train + total_test}\")\n",
    "print(f\"Original: {total_original}\")\n",
    "print(f\"Match? {total_train + total_test == total_original} ‚úì\")\n",
    "\n",
    "# Check 2: Percentage calculation\n",
    "train_percentage = (total_train / total_original) * 100\n",
    "test_percentage = (total_test / total_original) * 100\n",
    "\n",
    "print(f\"\\nTraining percentage: {train_percentage:.1f}%\")\n",
    "# Should be close to 80%\n",
    "\n",
    "print(f\"Testing percentage: {test_percentage:.1f}%\")\n",
    "# Should be close to 20%\n",
    "\n",
    "# Check 3: Input and output shapes match\n",
    "print(f\"\\nX_train and y_train same length? {X_train.shape[0] == y_train.shape[0]} ‚úì\")\n",
    "print(f\"X_test and y_test same length? {X_test.shape[0] == y_test.shape[0]} ‚úì\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 6: Visualize the split\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìä VISUALIZING THE SPLIT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "ORIGINAL DATA (3010 examples):\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Person 1, Person 2, Person 3, ... Person 3010 ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "AFTER SPLIT:\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ      TRAINING SET (80%)      ‚îÇ  ‚îÇ TEST SET (20%)‚îÇ\n",
    "‚îÇ   Person 1, 5, 7, 9, 11...   ‚îÇ  ‚îÇ Person 2, 4...‚îÇ\n",
    "‚îÇ        2408 people           ‚îÇ  ‚îÇ  602 people   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚Üì                                ‚Üì\n",
    "   Model LEARNS here            Model TESTED here\n",
    "   (sees these examples)         (never seen before!)\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 7: Look at actual examples\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüëÄ EXAMPLE DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"First 3 TRAINING examples:\")\n",
    "print(\"X_train (inputs):\")\n",
    "print(X_train[:3])\n",
    "print(\"\\ny_train (outputs - first 10 skills):\")\n",
    "print(y_train[:3, :10])\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "\n",
    "print(\"\\nFirst 3 TESTING examples:\")\n",
    "print(\"X_test (inputs):\")\n",
    "print(X_test[:3])\n",
    "print(\"\\ny_test (outputs - first 10 skills):\")\n",
    "print(y_test[:3, :10])\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 8: Why random_state=42?\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüé≤ WHY RANDOM_STATE=42?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "Without random_state:\n",
    "  Run 1: Person 5 in training, Person 10 in testing\n",
    "  Run 2: Person 5 in testing, Person 10 in training  ‚Üê Different!\n",
    "  Result: Can't reproduce results, can't debug issues\n",
    "\n",
    "With random_state=42:\n",
    "  Run 1: Person 5 in training, Person 10 in testing\n",
    "  Run 2: Person 5 in training, Person 10 in testing  ‚Üê Same!\n",
    "  Result: Reproducible! Anyone can verify your results\n",
    "\n",
    "The number 42 is arbitrary - could be 1, 100, 999, anything!\n",
    "It's just a popular choice among programmers.\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 9: What happens next?\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüöÄ NEXT STEPS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "Now we have:\n",
    "‚úì X_train, y_train - for teaching the model\n",
    "‚úì X_test, y_test - for testing the model\n",
    "\n",
    "Next cell:\n",
    "1. Create ML model (Random Forest)\n",
    "2. Train model using X_train and y_train\n",
    "3. Model will learn: \"When I see X_train[0], output should be y_train[0]\"\n",
    "4. Model finds patterns across all 2408 training examples\n",
    "\n",
    "Later:\n",
    "5. Test model on X_test (data it's NEVER seen!)\n",
    "6. Compare predictions to y_test (actual answers)\n",
    "7. Calculate accuracy\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SUMMARY BOX\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"üì¶ SUMMARY: CELL 12\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\"\"\n",
    "WHAT WE DID:\n",
    "Split data into training and testing sets\n",
    "\n",
    "TRAINING SET (80%):\n",
    "- X_train: {X_train.shape[0]} examples, {X_train.shape[1]} features\n",
    "- y_train: {y_train.shape[0]} examples, {y_train.shape[1]} skills\n",
    "- Purpose: Model learns from this data\n",
    "\n",
    "TESTING SET (20%):\n",
    "- X_test: {X_test.shape[0]} examples, {X_test.shape[1]} features\n",
    "- y_test: {y_test.shape[0]} examples, {y_test.shape[1]} skills\n",
    "- Purpose: Model tested on this data (never seen before!)\n",
    "\n",
    "KEY CONCEPT:\n",
    "Training set = Study guide\n",
    "Testing set = Final exam\n",
    "We want model to pass the exam, not just memorize answers!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623417df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≥ WHAT IS RANDOM FOREST?\n",
      "======================================================================\n",
      "\n",
      "Random Forest is like a democracy of decision trees!\n",
      "\n",
      "DECISION TREE (single tree):\n",
      "‚îå‚îÄ Is Company = Google?\n",
      "‚îÇ  ‚îú‚îÄ YES ‚Üí Is Designation = Data Scientist?\n",
      "‚îÇ  ‚îÇ       ‚îú‚îÄ YES ‚Üí Predict: Has Python (80% sure)\n",
      "‚îÇ  ‚îÇ       ‚îî‚îÄ NO  ‚Üí Predict: No Python (60% sure)\n",
      "‚îÇ  ‚îî‚îÄ NO  ‚Üí Check other conditions...\n",
      "\n",
      "RANDOM FOREST (100 trees):\n",
      "Tree 1 says: Has Python ‚úì\n",
      "Tree 2 says: Has Python ‚úì\n",
      "Tree 3 says: No Python ‚úó\n",
      "Tree 4 says: Has Python ‚úì\n",
      "...\n",
      "Tree 100 says: Has Python ‚úì\n",
      "\n",
      "Vote: 85 trees say \"Has Python\" ‚Üí Final answer: YES (85% confidence)\n",
      "\n",
      "WHY 100 TREES BETTER THAN 1?\n",
      "- Reduces errors (one tree might be wrong, 100 unlikely all wrong)\n",
      "- More robust (handles unusual cases better)\n",
      "- Less overfitting (doesn't memorize training data)\n",
      "\n",
      "\n",
      "üîß CREATING THE MODEL\n",
      "======================================================================\n",
      "\n",
      "üìã MODEL PARAMETERS EXPLAINED:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "1. n_estimators=100\n",
      "   What: Number of decision trees in the forest\n",
      "   Think: Size of your expert panel\n",
      "   More trees = More accurate but slower\n",
      "   100 = Good balance between accuracy and speed\n",
      "\n",
      "2. random_state=42\n",
      "   What: Random seed for reproducibility\n",
      "   Think: Recipe for randomness\n",
      "   Same seed = Same results every time\n",
      "   Different seed = Different trees, slightly different results\n",
      "\n",
      "3. n_jobs=-1\n",
      "   What: Number of CPU cores to use\n",
      "   -1 = Use ALL available cores\n",
      "   1 = Use only 1 core (slower)\n",
      "   Think: How many workers building the forest\n",
      "   More cores = Faster training\n",
      "\n",
      "4. max_depth=20\n",
      "   What: Maximum depth of each tree\n",
      "   Think: How many questions each tree can ask\n",
      "   Too shallow (depth=3): Underfitting (too simple)\n",
      "   Too deep (depth=100): Overfitting (memorizes)\n",
      "   20 = Good middle ground\n",
      "\n",
      "   Visual:\n",
      "   Depth 1:  ‚îå‚îÄ Question 1?\n",
      "            \n",
      "   Depth 2:  ‚îå‚îÄ Question 1?\n",
      "             ‚îú‚îÄ Question 2a?\n",
      "             ‚îî‚îÄ Question 2b?\n",
      "            \n",
      "   Depth 20: Many levels of questions...\n",
      "\n",
      "\n",
      "5. min_samples_split=5\n",
      "   What: Minimum samples needed to split a node\n",
      "   Think: Don't ask more questions if too few examples\n",
      "   If node has 4 examples ‚Üí Stop (too few)\n",
      "   If node has 10 examples ‚Üí Continue splitting\n",
      "   Prevents overfitting on tiny groups\n",
      "\n",
      "======================================================================\n",
      "üéâ MODEL CREATED!\n",
      "======================================================================\n",
      "\n",
      "Model type: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "\n",
      "Model object: RandomForestClassifier(max_depth=20, min_samples_split=5, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "\n",
      "‚ö†Ô∏è IMPORTANT: Model is NOT trained yet!\n",
      "It's like a newborn baby - knows nothing!\n",
      "\n",
      "Next cell: We'll TRAIN the model (teach it)\n",
      "\n",
      "üîç MODEL INSPECTION\n",
      "======================================================================\n",
      "Number of trees: 100\n",
      "Random state: 42\n",
      "Max depth: 20\n",
      "Min samples to split: 5\n",
      "Using CPU cores: -1 (-1 = all cores)\n",
      "\n",
      "Is model trained? False\n",
      "\n",
      "üìö WHAT WILL HAPPEN WHEN WE TRAIN?\n",
      "======================================================================\n",
      "\n",
      "When we call: model.fit(X_train, y_train)\n",
      "\n",
      "The model will:\n",
      "\n",
      "1. BUILD 100 DECISION TREES\n",
      "   - Each tree looks at training data differently\n",
      "   - Tree 1 might focus on Google examples\n",
      "   - Tree 2 might focus on Data Scientist examples\n",
      "   - Tree 3 randomly samples different examples\n",
      "   - ... and so on for all 100 trees\n",
      "\n",
      "2. EACH TREE LEARNS PATTERNS\n",
      "   Tree example:\n",
      "   \"I notice that when Company=Google (1) AND Designation=Data Scientist (1),\n",
      "    usually the person has Python (position 0 = 1)\"\n",
      "   \n",
      "3. BUILDS DECISION RULES\n",
      "   Tree creates rules like:\n",
      "   IF Company=1 AND Designation=1 THEN Skills[0]=1 (Python)\n",
      "   IF Company=0 AND Designation=2 THEN Skills[5]=1 (AWS)\n",
      "\n",
      "4. STORES THESE RULES\n",
      "   All 100 trees store their learned rules\n",
      "   Model becomes \"smart\" - knows patterns from 2408 examples\n",
      "\n",
      "Training time: ~30 seconds on our dataset\n",
      "\n",
      "\n",
      "üé® VISUAL COMPARISON\n",
      "======================================================================\n",
      "\n",
      "BEFORE TRAINING (now):\n",
      "Model = Empty box üì¶\n",
      "Knowledge = 0%\n",
      "Can predict? NO ‚ùå\n",
      "\n",
      "AFTER TRAINING (next cell):\n",
      "Model = Box full of rules üìö\n",
      "Knowledge = Learned from 2408 examples\n",
      "Can predict? YES ‚úì\n",
      "\n",
      "It's like:\n",
      "BEFORE: Student before class (knows nothing)\n",
      "AFTER: Student after semester (learned from textbook)\n",
      "\n",
      "\n",
      "üíæ MODEL SIZE\n",
      "======================================================================\n",
      "\n",
      "Untrained model size: ~1 KB (just configuration)\n",
      "Trained model size: ~15-20 MB (will have 100 trees with rules)\n",
      "\n",
      "Why so big after training?\n",
      "- 100 trees √ó many decision rules = lots of data\n",
      "- Each tree stores: decision nodes, split values, predictions\n",
      "- But 20MB is tiny compared to deep learning models (GB!)\n",
      "\n",
      "\n",
      "ü§î WHY THESE PARAMETER VALUES?\n",
      "======================================================================\n",
      "\n",
      "n_estimators=100:\n",
      "  ‚úì More than 50 (too few trees = unreliable)\n",
      "  ‚úì Less than 500 (too many = slow, diminishing returns)\n",
      "  ‚úì 100 = Sweet spot for most problems\n",
      "\n",
      "max_depth=20:\n",
      "  ‚úì Deep enough to capture complex patterns\n",
      "  ‚úì Shallow enough to prevent memorization\n",
      "  ‚úì For our problem (2 features), even 20 is generous\n",
      "\n",
      "min_samples_split=5:\n",
      "  ‚úì Prevents splitting tiny groups (overfitting)\n",
      "  ‚úì 5 is a good minimum (less than 5 = too specific)\n",
      "  ‚úì Balance between learning details and generalizing\n",
      "\n",
      "random_state=42:\n",
      "  ‚úì Reproducibility (scientific requirement)\n",
      "  ‚úì Anyone can verify your results\n",
      "  ‚úì Easier to debug (same results every run)\n",
      "\n",
      "n_jobs=-1:\n",
      "  ‚úì Uses all CPU cores = faster training\n",
      "  ‚úì No downside (more cores = better)\n",
      "  ‚úì Training time: 30s ‚Üí 10s (3x faster!)\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üì¶ SUMMARY: CELL 13\n",
      "======================================================================\n",
      "\n",
      "WHAT WE DID:\n",
      "Created a Random Forest Classifier with 100 decision trees\n",
      "\n",
      "MODEL CONFIGURATION:\n",
      "- Algorithm: Random Forest\n",
      "- Number of trees: 100\n",
      "- Max tree depth: 20\n",
      "- CPU cores used: All available\n",
      "- Random seed: 42 (reproducible)\n",
      "\n",
      "CURRENT STATE:\n",
      "- Model created: ‚úì\n",
      "- Model trained: ‚úó (next cell!)\n",
      "- Can make predictions: ‚úó (not yet)\n",
      "\n",
      "NEXT CELL:\n",
      "We'll train the model using:\n",
      "- Input: X_train (2408 examples)\n",
      "- Output: y_train (2408 skill sets)\n",
      "- Training time: ~30 seconds\n",
      "- After training: Model will be ready to predict!\n",
      "\n",
      "KEY CONCEPT:\n",
      "Right now, model = empty brain üß†\n",
      "After training = smart brain with knowledge üéì\n",
      "\n",
      "\n",
      "üéì QUICK CHECK\n",
      "======================================================================\n",
      "\n",
      "Test your understanding:\n",
      "\n",
      "Q1: How many decision trees are in our forest?\n",
      "A1: 100\n",
      "\n",
      "Q2: Can the model make predictions right now?\n",
      "A2: No, it needs to be trained first\n",
      "\n",
      "Q3: What does max_depth=20 mean?\n",
      "A3: Each tree can ask up to 20 questions deep\n",
      "\n",
      "Q4: Why do we use random_state=42?\n",
      "A4: For reproducibility - same results every time\n",
      "\n",
      "Q5: What will happen in the next cell?\n",
      "A5: We'll train the model on X_train and y_train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 13: CREATE THE MODEL - SUPER DETAILED\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ BIG PICTURE: What are we doing in this cell?\n",
    "==============================================\n",
    "\n",
    "We're creating our AI \"brain\" - the Random Forest model!\n",
    "\n",
    "ANALOGY: Building a team of experts\n",
    "- Random Forest = Team of 100 decision-making experts (trees)\n",
    "- Each expert looks at the data slightly differently\n",
    "- Final decision = Vote from all 100 experts\n",
    "- Majority wins!\n",
    "\n",
    "Think of it like:\n",
    "- One doctor diagnoses you: Might be wrong\n",
    "- 100 doctors diagnose you: Much more reliable!\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 1: Import the algorithm\n",
    "# ----------------------------------------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Let's break down this import:\n",
    "# sklearn = scikit-learn library (ML toolkit)\n",
    "# ensemble = Group/team of models\n",
    "# RandomForestClassifier = The specific algorithm we're using\n",
    "\n",
    "# What is a Classifier?\n",
    "# - Classifies things into categories\n",
    "# - Example: Email classifier: Spam or Not Spam\n",
    "# - Our case: Classify if person has each skill (Yes/No for each of 29 skills)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 2: Understanding Random Forest\n",
    "# ----------------------------------------------------------\n",
    "print(\"üå≥ WHAT IS RANDOM FOREST?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "Random Forest is like a democracy of decision trees!\n",
    "\n",
    "DECISION TREE (single tree):\n",
    "‚îå‚îÄ Is Company = Google?\n",
    "‚îÇ  ‚îú‚îÄ YES ‚Üí Is Designation = Data Scientist?\n",
    "‚îÇ  ‚îÇ       ‚îú‚îÄ YES ‚Üí Predict: Has Python (80% sure)\n",
    "‚îÇ  ‚îÇ       ‚îî‚îÄ NO  ‚Üí Predict: No Python (60% sure)\n",
    "‚îÇ  ‚îî‚îÄ NO  ‚Üí Check other conditions...\n",
    "\n",
    "RANDOM FOREST (100 trees):\n",
    "Tree 1 says: Has Python ‚úì\n",
    "Tree 2 says: Has Python ‚úì\n",
    "Tree 3 says: No Python ‚úó\n",
    "Tree 4 says: Has Python ‚úì\n",
    "...\n",
    "Tree 100 says: Has Python ‚úì\n",
    "\n",
    "Vote: 85 trees say \"Has Python\" ‚Üí Final answer: YES (85% confidence)\n",
    "\n",
    "WHY 100 TREES BETTER THAN 1?\n",
    "- Reduces errors (one tree might be wrong, 100 unlikely all wrong)\n",
    "- More robust (handles unusual cases better)\n",
    "- Less overfitting (doesn't memorize training data)\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 3: Create the model\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüîß CREATING THE MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# This is where we create our ML model!\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,      # How many trees in the forest\n",
    "    random_state=42,       # Reproducibility seed\n",
    "    n_jobs=-1,             # Use all CPU cores (faster!)\n",
    "    max_depth=20,          # How deep each tree can grow\n",
    "    min_samples_split=5    # Minimum samples needed to split a node\n",
    ")\n",
    "\n",
    "# Let's explain each parameter in detail:\n",
    "\n",
    "print(\"\\nüìã MODEL PARAMETERS EXPLAINED:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Parameter 1: n_estimators\n",
    "print(\"\\n1. n_estimators=100\")\n",
    "print(\"   What: Number of decision trees in the forest\")\n",
    "print(\"   Think: Size of your expert panel\")\n",
    "print(\"   More trees = More accurate but slower\")\n",
    "print(\"   100 = Good balance between accuracy and speed\")\n",
    "\n",
    "# Parameter 2: random_state\n",
    "print(\"\\n2. random_state=42\")\n",
    "print(\"   What: Random seed for reproducibility\")\n",
    "print(\"   Think: Recipe for randomness\")\n",
    "print(\"   Same seed = Same results every time\")\n",
    "print(\"   Different seed = Different trees, slightly different results\")\n",
    "\n",
    "# Parameter 3: n_jobs\n",
    "print(\"\\n3. n_jobs=-1\")\n",
    "print(\"   What: Number of CPU cores to use\")\n",
    "print(\"   -1 = Use ALL available cores\")\n",
    "print(\"   1 = Use only 1 core (slower)\")\n",
    "print(\"   Think: How many workers building the forest\")\n",
    "print(\"   More cores = Faster training\")\n",
    "\n",
    "# Parameter 4: max_depth\n",
    "print(\"\\n4. max_depth=20\")\n",
    "print(\"   What: Maximum depth of each tree\")\n",
    "print(\"   Think: How many questions each tree can ask\")\n",
    "print(\"   Too shallow (depth=3): Underfitting (too simple)\")\n",
    "print(\"   Too deep (depth=100): Overfitting (memorizes)\")\n",
    "print(\"   20 = Good middle ground\")\n",
    "\n",
    "print(\"\"\"\n",
    "   Visual:\n",
    "   Depth 1:  ‚îå‚îÄ Question 1?\n",
    "            \n",
    "   Depth 2:  ‚îå‚îÄ Question 1?\n",
    "             ‚îú‚îÄ Question 2a?\n",
    "             ‚îî‚îÄ Question 2b?\n",
    "            \n",
    "   Depth 20: Many levels of questions...\n",
    "\"\"\")\n",
    "\n",
    "# Parameter 5: min_samples_split\n",
    "print(\"\\n5. min_samples_split=5\")\n",
    "print(\"   What: Minimum samples needed to split a node\")\n",
    "print(\"   Think: Don't ask more questions if too few examples\")\n",
    "print(\"   If node has 4 examples ‚Üí Stop (too few)\")\n",
    "print(\"   If node has 10 examples ‚Üí Continue splitting\")\n",
    "print(\"   Prevents overfitting on tiny groups\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 4: What did we just create?\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ MODEL CREATED!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nModel type: {type(model)}\")\n",
    "# <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
    "\n",
    "print(f\"\\nModel object: {model}\")\n",
    "# Shows all the parameters we set\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è IMPORTANT: Model is NOT trained yet!\")\n",
    "print(\"It's like a newborn baby - knows nothing!\")\n",
    "print(\"\\nNext cell: We'll TRAIN the model (teach it)\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 5: Inspect the model\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüîç MODEL INSPECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check what we created\n",
    "print(f\"Number of trees: {model.n_estimators}\")\n",
    "print(f\"Random state: {model.random_state}\")\n",
    "print(f\"Max depth: {model.max_depth}\")\n",
    "print(f\"Min samples to split: {model.min_samples_split}\")\n",
    "print(f\"Using CPU cores: {model.n_jobs} (-1 = all cores)\")\n",
    "\n",
    "# Current state\n",
    "print(f\"\\nIs model trained? {hasattr(model, 'estimators_')}\")\n",
    "# False - because we haven't called .fit() yet\n",
    "# estimators_ = The actual 100 trees (only exist after training)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 6: What happens during training?\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìö WHAT WILL HAPPEN WHEN WE TRAIN?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "When we call: model.fit(X_train, y_train)\n",
    "\n",
    "The model will:\n",
    "\n",
    "1. BUILD 100 DECISION TREES\n",
    "   - Each tree looks at training data differently\n",
    "   - Tree 1 might focus on Google examples\n",
    "   - Tree 2 might focus on Data Scientist examples\n",
    "   - Tree 3 randomly samples different examples\n",
    "   - ... and so on for all 100 trees\n",
    "\n",
    "2. EACH TREE LEARNS PATTERNS\n",
    "   Tree example:\n",
    "   \"I notice that when Company=Google (1) AND Designation=Data Scientist (1),\n",
    "    usually the person has Python (position 0 = 1)\"\n",
    "   \n",
    "3. BUILDS DECISION RULES\n",
    "   Tree creates rules like:\n",
    "   IF Company=1 AND Designation=1 THEN Skills[0]=1 (Python)\n",
    "   IF Company=0 AND Designation=2 THEN Skills[5]=1 (AWS)\n",
    "\n",
    "4. STORES THESE RULES\n",
    "   All 100 trees store their learned rules\n",
    "   Model becomes \"smart\" - knows patterns from 2408 examples\n",
    "\n",
    "Training time: ~30 seconds on our dataset\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 7: Visual comparison\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüé® VISUAL COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "BEFORE TRAINING (now):\n",
    "Model = Empty box üì¶\n",
    "Knowledge = 0%\n",
    "Can predict? NO ‚ùå\n",
    "\n",
    "AFTER TRAINING (next cell):\n",
    "Model = Box full of rules üìö\n",
    "Knowledge = Learned from 2408 examples\n",
    "Can predict? YES ‚úì\n",
    "\n",
    "It's like:\n",
    "BEFORE: Student before class (knows nothing)\n",
    "AFTER: Student after semester (learned from textbook)\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 8: Memory requirement\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüíæ MODEL SIZE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Untrained model size: ~1 KB (just configuration)\n",
    "Trained model size: ~15-20 MB (will have 100 trees with rules)\n",
    "\n",
    "Why so big after training?\n",
    "- 100 trees √ó many decision rules = lots of data\n",
    "- Each tree stores: decision nodes, split values, predictions\n",
    "- But 20MB is tiny compared to deep learning models (GB!)\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 9: Why these specific parameters?\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nü§î WHY THESE PARAMETER VALUES?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "n_estimators=100:\n",
    "  ‚úì More than 50 (too few trees = unreliable)\n",
    "  ‚úì Less than 500 (too many = slow, diminishing returns)\n",
    "  ‚úì 100 = Sweet spot for most problems\n",
    "\n",
    "max_depth=20:\n",
    "  ‚úì Deep enough to capture complex patterns\n",
    "  ‚úì Shallow enough to prevent memorization\n",
    "  ‚úì For our problem (2 features), even 20 is generous\n",
    "\n",
    "min_samples_split=5:\n",
    "  ‚úì Prevents splitting tiny groups (overfitting)\n",
    "  ‚úì 5 is a good minimum (less than 5 = too specific)\n",
    "  ‚úì Balance between learning details and generalizing\n",
    "\n",
    "random_state=42:\n",
    "  ‚úì Reproducibility (scientific requirement)\n",
    "  ‚úì Anyone can verify your results\n",
    "  ‚úì Easier to debug (same results every run)\n",
    "\n",
    "n_jobs=-1:\n",
    "  ‚úì Uses all CPU cores = faster training\n",
    "  ‚úì No downside (more cores = better)\n",
    "  ‚úì Training time: 30s ‚Üí 10s (3x faster!)\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SUMMARY BOX\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"üì¶ SUMMARY: CELL 13\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\"\"\n",
    "WHAT WE DID:\n",
    "Created a Random Forest Classifier with 100 decision trees\n",
    "\n",
    "MODEL CONFIGURATION:\n",
    "- Algorithm: Random Forest\n",
    "- Number of trees: 100\n",
    "- Max tree depth: 20\n",
    "- CPU cores used: All available\n",
    "- Random seed: 42 (reproducible)\n",
    "\n",
    "CURRENT STATE:\n",
    "- Model created: ‚úì\n",
    "- Model trained: ‚úó (next cell!)\n",
    "- Can make predictions: ‚úó (not yet)\n",
    "\n",
    "NEXT CELL:\n",
    "We'll train the model using:\n",
    "- Input: X_train (2408 examples)\n",
    "- Output: y_train (2408 skill sets)\n",
    "- Training time: ~30 seconds\n",
    "- After training: Model will be ready to predict!\n",
    "\n",
    "KEY CONCEPT:\n",
    "Right now, model = empty brain üß†\n",
    "After training = smart brain with knowledge üéì\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# EXERCISE\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüéì QUICK CHECK\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "Test your understanding:\n",
    "\n",
    "Q1: How many decision trees are in our forest?\n",
    "A1: 100\n",
    "\n",
    "Q2: Can the model make predictions right now?\n",
    "A2: No, it needs to be trained first\n",
    "\n",
    "Q3: What does max_depth=20 mean?\n",
    "A3: Each tree can ask up to 20 questions deep\n",
    "\n",
    "Q4: Why do we use random_state=42?\n",
    "A4: For reproducibility - same results every time\n",
    "\n",
    "Q5: What will happen in the next cell?\n",
    "A5: We'll train the model on X_train and y_train\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb5707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nCELL 11: PREPARE FINAL INPUTS\\n===============================\\nX_encoded = X[['Company_Encoded', 'Designation_Encoded']]\\n‚Üí Select only number columns\\n‚Üí Shape: (3010, 2)\\n‚Üí Ready for ML model\\n\\nCELL 12: TRAIN-TEST SPLIT\\n==========================\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X_encoded, y_encoded, test_size=0.2, random_state=42\\n)\\n‚Üí 80% training (2408 examples)\\n‚Üí 20% testing (602 examples)\\n‚Üí Model learns from training, tested on testing\\n\\nCELL 13: CREATE MODEL\\n=====================\\nmodel = RandomForestClassifier(\\n    n_estimators=100,    # 100 trees\\n    random_state=42,     # Reproducible\\n    n_jobs=-1,           # All CPU cores\\n    max_depth=20,        # Tree depth\\n    min_samples_split=5  # Min samples to split\\n)\\n‚Üí Model created but NOT trained yet\\n‚Üí Next: Train with model.fit(X_train, y_train)\\n\\nVARIABLE TRACKER:\\n=================\\nX_encoded:      (3010, 2)  - All inputs\\ny_encoded:      (3010, 29) - All outputs\\nX_train:        (2408, 2)  - Training inputs\\ny_train:        (2408, 29) - Training outputs\\nX_test:         (602, 2)   - Testing inputs\\ny_test:         (602, 29)  - Testing outputs\\nmodel:          RandomForestClassifier (untrained)\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# QUICK REFERENCE - CELLS 11-13 SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "CELL 11: PREPARE FINAL INPUTS\n",
    "===============================\n",
    "X_encoded = X[['Company_Encoded', 'Designation_Encoded']]\n",
    "‚Üí Select only number columns\n",
    "‚Üí Shape: (3010, 2)\n",
    "‚Üí Ready for ML model\n",
    "\n",
    "CELL 12: TRAIN-TEST SPLIT\n",
    "==========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "‚Üí 80% training (2408 examples)\n",
    "‚Üí 20% testing (602 examples)\n",
    "‚Üí Model learns from training, tested on testing\n",
    "\n",
    "CELL 13: CREATE MODEL\n",
    "=====================\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,    # 100 trees\n",
    "    random_state=42,     # Reproducible\n",
    "    n_jobs=-1,           # All CPU cores\n",
    "    max_depth=20,        # Tree depth\n",
    "    min_samples_split=5  # Min samples to split\n",
    ")\n",
    "‚Üí Model created but NOT trained yet\n",
    "‚Üí Next: Train with model.fit(X_train, y_train)\n",
    "\n",
    "VARIABLE TRACKER:\n",
    "=================\n",
    "X_encoded:      (3010, 2)  - All inputs\n",
    "y_encoded:      (3010, 29) - All outputs\n",
    "X_train:        (2408, 2)  - Training inputs\n",
    "y_train:        (2408, 29) - Training outputs\n",
    "X_test:         (602, 2)   - Testing inputs\n",
    "y_test:         (602, 29)  - Testing outputs\n",
    "model:          RandomForestClassifier (untrained)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f463d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéì TRAINING THE MODEL\n",
      "======================================================================\n",
      "Training data:\n",
      "  X_train shape: (2408, 2) (2408 examples, 2 features)\n",
      "  y_train shape: (2408, 29) (2408 examples, 29 skills)\n",
      "\n",
      "What the model will learn:\n",
      "  'When Company=X AND Designation=Y, Skills usually = [pattern]'\n",
      "\n",
      "======================================================================\n",
      "üöÄ TRAINING STARTED...\n",
      "======================================================================\n",
      "‚úÖ TRAINING COMPLETED!\n",
      "‚è±Ô∏è  Time taken: 0.70 seconds\n",
      "\n",
      "üìö WHAT HAPPENED DURING TRAINING?\n",
      "======================================================================\n",
      "\n",
      "During those 1 seconds, the model:\n",
      "\n",
      "1. BUILT 100 DECISION TREES üå≥üå≥üå≥... (√ó 100)\n",
      "   Each tree was built independently using:\n",
      "   - Random subset of training examples\n",
      "   - Random subset of features\n",
      "   - This randomness makes forest robust!\n",
      "\n",
      "2. EACH TREE LEARNED PATTERNS\n",
      "   Example patterns tree might learn:\n",
      "   \n",
      "   Tree 1 learned:\n",
      "   ‚îå‚îÄ IF Company = 1 (Google)\n",
      "   ‚îÇ  ‚îî‚îÄ IF Designation = 1 (Data Scientist)\n",
      "   ‚îÇ     ‚îî‚îÄ THEN Skills[0] = 1 (85% confident)\n",
      "   ‚îÇ              Skills[2] = 1 (78% confident)\n",
      "   ‚îÇ              Skills[5] = 0 (90% confident)\n",
      "   \n",
      "   Tree 2 learned different patterns...\n",
      "   Tree 3 learned different patterns...\n",
      "   ...\n",
      "   Tree 100 learned different patterns...\n",
      "\n",
      "3. ANALYZED 2408 TRAINING EXAMPLES\n",
      "   Looked at patterns like:\n",
      "   - People at Google with role X tend to have skills Y, Z\n",
      "   - People at Amazon with role A tend to have skills B, C\n",
      "   - Found relationships between companies, roles, and skills\n",
      "\n",
      "4. STORED ALL DECISION RULES\n",
      "   Model now contains: 100 trees √ó many decision nodes\n",
      "   Total size: ~15-20 MB of learned knowledge!\n",
      "\n",
      "\n",
      "‚úÖ VERIFICATION\n",
      "======================================================================\n",
      "Model now has trained components:\n",
      "  ‚úì estimators_: 100 trained trees\n",
      "     Each tree is a trained decision tree\n",
      "  ‚úì classes_: Learned labels\n",
      "\n",
      "‚úì Model is now TRAINED and ready to predict!\n",
      "\n",
      "üå≥ EXAMINING THE TREES\n",
      "======================================================================\n",
      "First tree (out of 100):\n",
      "  Type: <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "  Max depth reached: 6\n",
      "  Number of leaves: 25\n",
      "  Total nodes: 49\n",
      "\n",
      "All 100 trees statistics:\n",
      "  Average tree depth: 6.2\n",
      "  Shallowest tree: 6\n",
      "  Deepest tree: 8\n",
      "  (We set max_depth=20, so none exceed 20)\n",
      "\n",
      "üß† WHAT THE MODEL KNOWS NOW\n",
      "======================================================================\n",
      "\n",
      "The model has learned patterns from 2408 examples:\n",
      "\n",
      "KNOWLEDGE BASE:\n",
      "- Knows patterns for 5 companies\n",
      "- Knows patterns for 5 designations\n",
      "- Can predict 29 different skills\n",
      "- Has 100 different \"expert opinions\" (trees)\n",
      "\n",
      "EXAMPLE KNOWLEDGE (simplified):\n",
      "\"When I see Company=Google (1) + Designation=Data Scientist (1),\n",
      " I've noticed in my training data that:\n",
      " - 85% of them had Python\n",
      " - 78% of them had Machine Learning\n",
      " - 65% of them had SQL\n",
      " - 42% of them had TensorFlow\n",
      " - etc.\"\n",
      "\n",
      "The model stores these percentages (and much more complex patterns)\n",
      "across all its 100 trees!\n",
      "\n",
      "\n",
      "üìä IMPORTANT DISTINCTION\n",
      "======================================================================\n",
      "\n",
      "DATA THE MODEL SAW (Training):\n",
      "  X_train: 2408 examples\n",
      "  y_train: 2408 examples\n",
      "  Model learned from these ‚úì\n",
      "\n",
      "DATA THE MODEL HAS NEVER SEEN (Testing):\n",
      "  X_test: 602 examples  \n",
      "  y_test: 602 examples\n",
      "  Model will be tested on these in next cell üéØ\n",
      "\n",
      "This is CRITICAL for honest evaluation!\n",
      "- If we test on training data ‚Üí Model has memorized ‚Üí Cheating!\n",
      "- Testing on NEW data ‚Üí Real measure of learning\n",
      "\n",
      "\n",
      "üíæ MODEL SIZE\n",
      "======================================================================\n",
      "Estimated model size: 2.68 MB\n",
      "Why so big? 100 trees √ó many nodes √ó decision rules\n",
      "\n",
      "Comparison:\n",
      "  Our model: ~3 MB\n",
      "  Deep learning model: 100-1000 MB\n",
      "  GPT-4: ~1,000,000 MB (1 TB!)\n",
      "  ‚Üí Our model is tiny and efficient! ‚úì\n",
      "\n",
      "üéØ CAN WE MAKE PREDICTIONS NOW?\n",
      "======================================================================\n",
      "YES! The model is fully trained. We can:\n",
      "  1. Make predictions on new data ‚úì\n",
      "  2. Evaluate accuracy ‚úì\n",
      "  3. Save the model ‚úì\n",
      "  4. Load it later for production ‚úì\n",
      "\n",
      "Let's test it with one example:\n",
      "\n",
      "Example input: [2 0]\n",
      "Meaning: Company=2, Designation=0\n",
      "\n",
      "Prediction shape: (1, 29)\n",
      "Prediction: [1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "This is a binary array of 29 values\n",
      "\n",
      "Model predicts 6 skills for this person\n",
      "Predicted skills:\n",
      "  ‚úì AWS\n",
      "  ‚úì Agile\n",
      "  ‚úì Azure\n",
      "  ‚úì Kubernetes\n",
      "  ‚úì Scalability\n",
      "  ‚úì Terraform\n",
      "\n",
      "‚ö° TRAINING PERFORMANCE\n",
      "======================================================================\n",
      "\n",
      "Training time: 0.70 seconds\n",
      "Examples per second: 3416\n",
      "Time per tree: 0.007 seconds\n",
      "\n",
      "This is FAST because:\n",
      "- We used n_jobs=-1 (all CPU cores)\n",
      "- Dataset is small (3010 examples)\n",
      "- Features are few (only 2)\n",
      "\n",
      "For comparison:\n",
      "- Deep learning on this data: 5-10 minutes\n",
      "- Our Random Forest: 1 seconds\n",
      "- That's 851√ó faster!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üì¶ SUMMARY: CELL 14\n",
      "======================================================================\n",
      "\n",
      "WHAT WE DID:\n",
      "‚úì Trained Random Forest model on 2408 examples\n",
      "‚úì Took 1 seconds\n",
      "‚úì Built 100 decision trees\n",
      "‚úì Model learned patterns from data\n",
      "\n",
      "BEFORE TRAINING:\n",
      "model.fit() not called ‚Üí Empty brain üß†\n",
      "\n",
      "AFTER TRAINING:\n",
      "model.fit() called ‚Üí Smart brain üéì\n",
      "- Can predict skills for any company + designation\n",
      "- Has learned from 2408 real examples\n",
      "- Ready for evaluation\n",
      "\n",
      "NEXT CELL:\n",
      "- Test model on X_test (never seen before!)\n",
      "- Calculate accuracy\n",
      "- See how well it really learned\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚ú® MODEL TRAINING COMPLETE! ‚ú®\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 14: TRAIN THE MODEL - SUPER DETAILED\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ BIG PICTURE: What are we doing in this cell?\n",
    "==============================================\n",
    "\n",
    "This is THE MOST IMPORTANT CELL - where the MAGIC happens! üé©‚ú®\n",
    "\n",
    "We're going to TRAIN the model - teach it patterns from our data.\n",
    "\n",
    "ANALOGY: Teaching a student\n",
    "- Student (model) reads textbook (training data)\n",
    "- Student learns patterns (finds relationships)\n",
    "- Student takes notes (stores decision rules)\n",
    "- After studying, student can answer NEW questions!\n",
    "\n",
    "Before training: Model = Baby üë∂ (knows nothing)\n",
    "After training: Model = Expert üéì (knows patterns)\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 1: Setup - What we need\n",
    "# ----------------------------------------------------------\n",
    "import time  # To measure how long training takes\n",
    "\n",
    "print(\"üéì TRAINING THE MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Reminder of what we're training with\n",
    "print(\"Training data:\")\n",
    "print(f\"  X_train shape: {X_train.shape} (2408 examples, 2 features)\")\n",
    "print(f\"  y_train shape: {y_train.shape} (2408 examples, 29 skills)\")\n",
    "\n",
    "print(\"\\nWhat the model will learn:\")\n",
    "print(\"  'When Company=X AND Designation=Y, Skills usually = [pattern]'\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 2: Start training\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üöÄ TRAINING STARTED...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# THE MAGIC LINE - This is where learning happens!\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"‚úÖ TRAINING COMPLETED!\")\n",
    "print(f\"‚è±Ô∏è  Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 3: What just happened?\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\nüìö WHAT HAPPENED DURING TRAINING?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "During those {elapsed_time:.0f} seconds, the model:\n",
    "\n",
    "1. BUILT 100 DECISION TREES üå≥üå≥üå≥... (√ó 100)\n",
    "   Each tree was built independently using:\n",
    "   - Random subset of training examples\n",
    "   - Random subset of features\n",
    "   - This randomness makes forest robust!\n",
    "\n",
    "2. EACH TREE LEARNED PATTERNS\n",
    "   Example patterns tree might learn:\n",
    "   \n",
    "   Tree 1 learned:\n",
    "   ‚îå‚îÄ IF Company = 1 (Google)\n",
    "   ‚îÇ  ‚îî‚îÄ IF Designation = 1 (Data Scientist)\n",
    "   ‚îÇ     ‚îî‚îÄ THEN Skills[0] = 1 (85% confident)\n",
    "   ‚îÇ              Skills[2] = 1 (78% confident)\n",
    "   ‚îÇ              Skills[5] = 0 (90% confident)\n",
    "   \n",
    "   Tree 2 learned different patterns...\n",
    "   Tree 3 learned different patterns...\n",
    "   ...\n",
    "   Tree 100 learned different patterns...\n",
    "\n",
    "3. ANALYZED {X_train.shape[0]} TRAINING EXAMPLES\n",
    "   Looked at patterns like:\n",
    "   - People at Google with role X tend to have skills Y, Z\n",
    "   - People at Amazon with role A tend to have skills B, C\n",
    "   - Found relationships between companies, roles, and skills\n",
    "\n",
    "4. STORED ALL DECISION RULES\n",
    "   Model now contains: 100 trees √ó many decision nodes\n",
    "   Total size: ~15-20 MB of learned knowledge!\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 4: Verify training completed\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n‚úÖ VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# After training, model gets new attributes\n",
    "print(\"Model now has trained components:\")\n",
    "\n",
    "# Check if estimators_ exists (the 100 trained trees)\n",
    "if hasattr(model, 'estimators_'):\n",
    "    print(f\"  ‚úì estimators_: {len(model.estimators_)} trained trees\")\n",
    "    print(f\"     Each tree is a trained decision tree\")\n",
    "else:\n",
    "    print(\"  ‚úó No estimators_ (training failed!)\")\n",
    "\n",
    "# Check if classes_ exists (the skill labels learned)\n",
    "if hasattr(model, 'classes_'):\n",
    "    print(f\"  ‚úì classes_: Learned labels\")\n",
    "else:\n",
    "    print(\"  ‚úó No classes_\")\n",
    "\n",
    "# Model can now make predictions\n",
    "print(f\"\\n‚úì Model is now TRAINED and ready to predict!\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 5: Understanding the trees\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüå≥ EXAMINING THE TREES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Look at first tree in detail\n",
    "first_tree = model.estimators_[0]\n",
    "print(f\"First tree (out of 100):\")\n",
    "print(f\"  Type: {type(first_tree)}\")\n",
    "print(f\"  Max depth reached: {first_tree.tree_.max_depth}\")\n",
    "print(f\"  Number of leaves: {first_tree.tree_.n_leaves}\")\n",
    "print(f\"  Total nodes: {first_tree.tree_.node_count}\")\n",
    "\n",
    "# Each tree is a DecisionTreeClassifier\n",
    "# tree_.max_depth = How deep this tree grew\n",
    "# tree_.n_leaves = End points (final decisions)\n",
    "# tree_.node_count = Total decision points\n",
    "\n",
    "print(f\"\\nAll 100 trees statistics:\")\n",
    "depths = [tree.tree_.max_depth for tree in model.estimators_]\n",
    "print(f\"  Average tree depth: {np.mean(depths):.1f}\")\n",
    "print(f\"  Shallowest tree: {min(depths)}\")\n",
    "print(f\"  Deepest tree: {max(depths)}\")\n",
    "print(f\"  (We set max_depth=20, so none exceed 20)\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 6: What the model learned\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüß† WHAT THE MODEL KNOWS NOW\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "The model has learned patterns from {X_train.shape[0]} examples:\n",
    "\n",
    "KNOWLEDGE BASE:\n",
    "- Knows patterns for {len(company_encoder.classes_)} companies\n",
    "- Knows patterns for {len(designation_encoder.classes_)} designations\n",
    "- Can predict {len(mlb.classes_)} different skills\n",
    "- Has 100 different \"expert opinions\" (trees)\n",
    "\n",
    "EXAMPLE KNOWLEDGE (simplified):\n",
    "\"When I see Company=Google (1) + Designation=Data Scientist (1),\n",
    " I've noticed in my training data that:\n",
    " - 85% of them had Python\n",
    " - 78% of them had Machine Learning\n",
    " - 65% of them had SQL\n",
    " - 42% of them had TensorFlow\n",
    " - etc.\"\n",
    "\n",
    "The model stores these percentages (and much more complex patterns)\n",
    "across all its 100 trees!\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 7: Training vs Testing\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìä IMPORTANT DISTINCTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "DATA THE MODEL SAW (Training):\n",
    "  X_train: {X_train.shape[0]} examples\n",
    "  y_train: {y_train.shape[0]} examples\n",
    "  Model learned from these ‚úì\n",
    "\n",
    "DATA THE MODEL HAS NEVER SEEN (Testing):\n",
    "  X_test: {X_test.shape[0]} examples  \n",
    "  y_test: {y_test.shape[0]} examples\n",
    "  Model will be tested on these in next cell üéØ\n",
    "\n",
    "This is CRITICAL for honest evaluation!\n",
    "- If we test on training data ‚Üí Model has memorized ‚Üí Cheating!\n",
    "- Testing on NEW data ‚Üí Real measure of learning\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 8: Memory footprint\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüíæ MODEL SIZE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import sys\n",
    "\n",
    "# Rough estimate of model size\n",
    "model_size_bytes = sys.getsizeof(pickle.dumps(model))\n",
    "model_size_mb = model_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"Estimated model size: {model_size_mb:.2f} MB\")\n",
    "print(f\"Why so big? 100 trees √ó many nodes √ó decision rules\")\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Our model: ~{model_size_mb:.0f} MB\")\n",
    "print(f\"  Deep learning model: 100-1000 MB\")\n",
    "print(f\"  GPT-4: ~1,000,000 MB (1 TB!)\")\n",
    "print(f\"  ‚Üí Our model is tiny and efficient! ‚úì\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 9: Can we use the model now?\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüéØ CAN WE MAKE PREDICTIONS NOW?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"YES! The model is fully trained. We can:\")\n",
    "print(\"  1. Make predictions on new data ‚úì\")\n",
    "print(\"  2. Evaluate accuracy ‚úì\")\n",
    "print(\"  3. Save the model ‚úì\")\n",
    "print(\"  4. Load it later for production ‚úì\")\n",
    "\n",
    "print(\"\\nLet's test it with one example:\")\n",
    "\n",
    "# Take first example from test set\n",
    "example_input = X_test[:1]  # Shape: (1, 2) - one example\n",
    "print(f\"\\nExample input: {example_input.values[0]}\")\n",
    "print(f\"Meaning: Company={example_input.values[0][0]}, Designation={example_input.values[0][1]}\")\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(example_input)\n",
    "print(f\"\\nPrediction shape: {prediction.shape}\")\n",
    "print(f\"Prediction: {prediction[0]}\")\n",
    "print(f\"This is a binary array of {len(prediction[0])} values\")\n",
    "\n",
    "# Count predicted skills\n",
    "num_predicted = prediction[0].sum()\n",
    "print(f\"\\nModel predicts {num_predicted} skills for this person\")\n",
    "\n",
    "# Show which skills\n",
    "print(\"Predicted skills:\")\n",
    "for i, has_skill in enumerate(prediction[0]):\n",
    "    if has_skill == 1:\n",
    "        print(f\"  ‚úì {mlb.classes_[i]}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 10: Training performance\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n‚ö° TRAINING PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Training time: {elapsed_time:.2f} seconds\n",
    "Examples per second: {X_train.shape[0] / elapsed_time:.0f}\n",
    "Time per tree: {elapsed_time / 100:.3f} seconds\n",
    "\n",
    "This is FAST because:\n",
    "- We used n_jobs=-1 (all CPU cores)\n",
    "- Dataset is small (3010 examples)\n",
    "- Features are few (only 2)\n",
    "\n",
    "For comparison:\n",
    "- Deep learning on this data: 5-10 minutes\n",
    "- Our Random Forest: {elapsed_time:.0f} seconds\n",
    "- That's {(10*60)/elapsed_time:.0f}√ó faster!\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SUMMARY BOX\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"üì¶ SUMMARY: CELL 14\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\"\"\n",
    "WHAT WE DID:\n",
    "‚úì Trained Random Forest model on {X_train.shape[0]} examples\n",
    "‚úì Took {elapsed_time:.0f} seconds\n",
    "‚úì Built 100 decision trees\n",
    "‚úì Model learned patterns from data\n",
    "\n",
    "BEFORE TRAINING:\n",
    "model.fit() not called ‚Üí Empty brain üß†\n",
    "\n",
    "AFTER TRAINING:\n",
    "model.fit() called ‚Üí Smart brain üéì\n",
    "- Can predict skills for any company + designation\n",
    "- Has learned from {X_train.shape[0]} real examples\n",
    "- Ready for evaluation\n",
    "\n",
    "NEXT CELL:\n",
    "- Test model on X_test (never seen before!)\n",
    "- Calculate accuracy\n",
    "- See how well it really learned\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ú® MODEL TRAINING COMPLETE! ‚ú®\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff623f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä DATA OVERVIEW\n",
      "======================================================================\n",
      "TRAINING DATA (model saw these):\n",
      "  X_train: (2408, 2) - Model learned from this\n",
      "  y_train: (2408, 29) - Correct answers model studied\n",
      "\n",
      "TESTING DATA (model NEVER saw these):\n",
      "  X_test: (602, 2) - New questions for model\n",
      "  y_test: (602, 29) - Correct answers (answer key)\n",
      "\n",
      "We'll predict y_test using X_test and compare!\n",
      "\n",
      "üîÆ MAKING PREDICTIONS\n",
      "======================================================================\n",
      "Calling model.predict(X_test)...\n",
      "‚úÖ Predictions completed!\n",
      "\n",
      "üì¶ WHAT DID WE GET?\n",
      "======================================================================\n",
      "y_pred type: <class 'numpy.ndarray'>\n",
      "y_pred shape: (602, 29)\n",
      "y_pred dtype: int64\n",
      "\n",
      "Interpretation:\n",
      "  - 602 predictions (one per test example)\n",
      "  - 29 skills predicted for each person\n",
      "  - Values are 0 (doesn't have skill) or 1 (has skill)\n",
      "\n",
      "üëÄ EXAMINING PREDICTIONS\n",
      "======================================================================\n",
      "First 3 predictions:\n",
      "\n",
      "Person 0:\n",
      "  Predicted: [1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "  Actual:    [0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "  Match? False\n",
      "\n",
      "Person 1:\n",
      "  Predicted: [0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0]\n",
      "  Actual:    [0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      "  Match? False\n",
      "\n",
      "Person 2:\n",
      "  Predicted: [0 1 1 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "  Actual:    [1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "  Match? False\n",
      "\n",
      "üî§ DECODING PREDICTIONS TO SKILL NAMES\n",
      "======================================================================\n",
      "Person 0 - Detailed View:\n",
      "\n",
      "Input (X_test):\n",
      "  Company code: 2\n",
      "  Designation code: 0\n",
      "\n",
      "PREDICTED SKILLS:\n",
      "  ‚úì AWS\n",
      "  ‚úì Agile\n",
      "  ‚úì Azure\n",
      "  ‚úì Kubernetes\n",
      "  ‚úì Scalability\n",
      "  ‚úì Terraform\n",
      "\n",
      "Total predicted: 6 skills\n",
      "\n",
      "ACTUAL SKILLS (ground truth):\n",
      "  ‚úì Azure\n",
      "  ‚úì Communication\n",
      "  ‚úì Kubernetes\n",
      "  ‚úì Python\n",
      "  ‚úì Scalability\n",
      "\n",
      "Total actual: 5 skills\n",
      "\n",
      "üìä COMPARISON:\n",
      "  ‚úì Correct predictions: 3\n",
      "      Scalability\n",
      "      Azure\n",
      "      Kubernetes\n",
      "  ‚úó Missed (False Negative): 2\n",
      "      Python\n",
      "      Communication\n",
      "  ‚úó Extra (False Positive): 3\n",
      "      AWS\n",
      "      Agile\n",
      "      Terraform\n",
      "\n",
      "Accuracy for this person: 37.5%\n",
      "\n",
      "üìà OVERALL PREDICTION STATISTICS\n",
      "======================================================================\n",
      "Total individual predictions: 17,458\n",
      "\n",
      "Predicted distribution:\n",
      "  Has skill (1): 4,030 (23.1%)\n",
      "  No skill (0): 13,428 (76.9%)\n",
      "\n",
      "Actual distribution:\n",
      "  Has skill (1): 3,919 (22.4%)\n",
      "  No skill (0): 13,539 (77.6%)\n",
      "\n",
      "Average skills per person:\n",
      "  Predicted: 6.7 skills\n",
      "  Actual: 6.5 skills\n",
      "\n",
      "üéØ QUICK ACCURACY CHECK\n",
      "======================================================================\n",
      "Perfect predictions: 0 out of 602\n",
      "Exact match rate: 0.00%\n",
      "\n",
      "‚ö†Ô∏è  This seems low, but it's NORMAL!\n",
      "Why? Because we're predicting 29 skills simultaneously.\n",
      "If we get 28 out of 29 correct ‚Üí Still counts as 0% in exact match!\n",
      "\n",
      "Next cell: We'll use BETTER metrics (Hamming Loss, Individual Accuracy)\n",
      "\n",
      "üîç HOW DID THE MODEL PREDICT?\n",
      "======================================================================\n",
      "\n",
      "For each test example, the model:\n",
      "\n",
      "1. TREE VOTING\n",
      "   Example: Person 0, Skill \"Python\" (position 0)\n",
      "   \n",
      "   Tree 1 votes: HAS Python (1)\n",
      "   Tree 2 votes: HAS Python (1)\n",
      "   Tree 3 votes: NO Python (0)\n",
      "   Tree 4 votes: HAS Python (1)\n",
      "   ...\n",
      "   Tree 100 votes: HAS Python (1)\n",
      "   \n",
      "   Count: 85 trees say YES, 15 say NO\n",
      "   Result: Majority (85) wins ‚Üí Predict 1 (HAS Python)\n",
      "\n",
      "2. REPEAT FOR ALL 29 SKILLS\n",
      "   Does same voting for each of the 29 skills\n",
      "   \n",
      "3. REPEAT FOR ALL 602 TEST EXAMPLES\n",
      "   Process all 602 people in test set\n",
      "\n",
      "Total votes counted: 602 people √ó 29 skills √ó 100 trees\n",
      "                   = 1,745,800 individual tree votes!\n",
      "All in a fraction of a second! ‚ö°\n",
      "\n",
      "\n",
      "üíØ PREDICTION CONFIDENCE\n",
      "======================================================================\n",
      "Getting confidence scores...\n",
      "\n",
      "Confidence scores for Person 0:\n",
      "  ‚úó AWS                  Confidence: 100.0%  Pred: 1  Actual: 0\n",
      "  ‚úó Agile                Confidence:  77.0%  Pred: 1  Actual: 0\n",
      "  ‚úì Algorithms           Confidence:   0.0%  Pred: 0  Actual: 0\n",
      "  ‚úì Azure                Confidence:  99.0%  Pred: 1  Actual: 1\n",
      "  ‚úì C#                   Confidence:   0.0%  Pred: 0  Actual: 0\n",
      "  ‚úì CI/CD                Confidence:   0.0%  Pred: 0  Actual: 0\n",
      "  ‚úó Communication        Confidence:   4.0%  Pred: 0  Actual: 1\n",
      "  ‚úì Data Structures      Confidence:   0.0%  Pred: 0  Actual: 0\n",
      "  ‚úì Data Visualization   Confidence:   0.0%  Pred: 0  Actual: 0\n",
      "  ‚úì Docker               Confidence:   0.0%  Pred: 0  Actual: 0\n",
      "\n",
      "======================================================================\n",
      "üì¶ SUMMARY: CELL 15\n",
      "======================================================================\n",
      "\n",
      "WHAT WE DID:\n",
      "‚úì Made predictions on 602 test examples\n",
      "‚úì Model predicted 29 skills for each person\n",
      "‚úì Compared predictions to actual values\n",
      "\n",
      "KEY RESULTS:\n",
      "- y_pred shape: (602, 29)\n",
      "- Total predictions: 17,458\n",
      "- Exact matches: 0/602 (0.0%)\n",
      "- Average predicted skills: 6.7\n",
      "- Average actual skills: 6.5\n",
      "\n",
      "IMPORTANT NOTE:\n",
      "Exact match rate is low (0.0%) but this is NORMAL\n",
      "for multi-label problems. Next cell will show better metrics!\n",
      "\n",
      "NEXT CELL:\n",
      "- Calculate proper accuracy metrics\n",
      "- Hamming Loss\n",
      "- Individual skill accuracy\n",
      "- Precision, Recall, F1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 15: MAKE PREDICTIONS - SUPER DETAILED\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ BIG PICTURE: What are we doing in this cell?\n",
    "==============================================\n",
    "\n",
    "Now that the model is trained, let's test it!\n",
    "\n",
    "We'll give the model NEW data (X_test) it has NEVER seen\n",
    "and see what it predicts.\n",
    "\n",
    "ANALOGY: Final Exam\n",
    "- Student studied from textbook (X_train, y_train)\n",
    "- Now taking exam with NEW questions (X_test)\n",
    "- We compare answers to answer key (y_test)\n",
    "\n",
    "This tells us: Did the model really LEARN or just MEMORIZE?\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 1: Reminder - What are we working with?\n",
    "# ----------------------------------------------------------\n",
    "print(\"üìä DATA OVERVIEW\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"TRAINING DATA (model saw these):\")\n",
    "print(f\"  X_train: {X_train.shape} - Model learned from this\")\n",
    "print(f\"  y_train: {y_train.shape} - Correct answers model studied\")\n",
    "\n",
    "print(\"\\nTESTING DATA (model NEVER saw these):\")\n",
    "print(f\"  X_test: {X_test.shape} - New questions for model\")\n",
    "print(f\"  y_test: {y_test.shape} - Correct answers (answer key)\")\n",
    "\n",
    "print(f\"\\nWe'll predict y_test using X_test and compare!\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 2: Make predictions\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüîÆ MAKING PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"Calling model.predict(X_test)...\")\n",
    "\n",
    "# THE PREDICTION LINE!\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# What happens inside model.predict()?\n",
    "# 1. Takes X_test (602 examples)\n",
    "# 2. For each example:\n",
    "#    a. Passes it through all 100 trees\n",
    "#    b. Each tree votes: \"Has Python? YES or NO\"\n",
    "#    c. Majority vote wins\n",
    "# 3. Returns predictions for all 29 skills per person\n",
    "\n",
    "print(f\"‚úÖ Predictions completed!\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 3: Understand the predictions\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüì¶ WHAT DID WE GET?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"y_pred type: {type(y_pred)}\")\n",
    "# numpy.ndarray\n",
    "\n",
    "print(f\"y_pred shape: {y_pred.shape}\")\n",
    "# (602, 29) - same shape as y_test!\n",
    "# 602 people, 29 skills each\n",
    "\n",
    "print(f\"y_pred dtype: {y_pred.dtype}\")\n",
    "# int64 or int32 (integers: 0 or 1)\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  - {y_pred.shape[0]} predictions (one per test example)\")\n",
    "print(f\"  - {y_pred.shape[1]} skills predicted for each person\")\n",
    "print(f\"  - Values are 0 (doesn't have skill) or 1 (has skill)\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 4: Look at actual predictions\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüëÄ EXAMINING PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Look at first 3 predictions\n",
    "print(\"First 3 predictions:\")\n",
    "print(\"\\nPerson 0:\")\n",
    "print(f\"  Predicted: {y_pred[0]}\")\n",
    "print(f\"  Actual:    {y_test[0]}\")\n",
    "print(f\"  Match? {np.array_equal(y_pred[0], y_test[0])}\")\n",
    "\n",
    "print(\"\\nPerson 1:\")\n",
    "print(f\"  Predicted: {y_pred[1]}\")\n",
    "print(f\"  Actual:    {y_test[1]}\")\n",
    "print(f\"  Match? {np.array_equal(y_pred[1], y_test[1])}\")\n",
    "\n",
    "print(\"\\nPerson 2:\")\n",
    "print(f\"  Predicted: {y_pred[2]}\")\n",
    "print(f\"  Actual:    {y_test[2]}\")\n",
    "print(f\"  Match? {np.array_equal(y_pred[2], y_test[2])}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 5: Decode predictions to skill names\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüî§ DECODING PREDICTIONS TO SKILL NAMES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Let's look at Person 0 in detail\n",
    "person_idx = 0\n",
    "\n",
    "print(f\"Person {person_idx} - Detailed View:\")\n",
    "print(\"\\nInput (X_test):\")\n",
    "print(f\"  Company code: {X_test.iloc[person_idx, 0]}\")\n",
    "print(f\"  Designation code: {X_test.iloc[person_idx, 1]}\")\n",
    "\n",
    "print(\"\\nPREDICTED SKILLS:\")\n",
    "predicted_skills = []\n",
    "for i, has_skill in enumerate(y_pred[person_idx]):\n",
    "    if has_skill == 1:\n",
    "        skill_name = mlb.classes_[i]\n",
    "        predicted_skills.append(skill_name)\n",
    "        print(f\"  ‚úì {skill_name}\")\n",
    "\n",
    "print(f\"\\nTotal predicted: {len(predicted_skills)} skills\")\n",
    "\n",
    "print(\"\\nACTUAL SKILLS (ground truth):\")\n",
    "actual_skills = []\n",
    "for i, has_skill in enumerate(y_test[person_idx]):\n",
    "    if has_skill == 1:\n",
    "        skill_name = mlb.classes_[i]\n",
    "        actual_skills.append(skill_name)\n",
    "        print(f\"  ‚úì {skill_name}\")\n",
    "\n",
    "print(f\"\\nTotal actual: {len(actual_skills)} skills\")\n",
    "\n",
    "# Compare\n",
    "correct_skills = set(predicted_skills) & set(actual_skills)\n",
    "missed_skills = set(actual_skills) - set(predicted_skills)\n",
    "extra_skills = set(predicted_skills) - set(actual_skills)\n",
    "\n",
    "print(f\"\\nüìä COMPARISON:\")\n",
    "print(f\"  ‚úì Correct predictions: {len(correct_skills)}\")\n",
    "if correct_skills:\n",
    "    for skill in correct_skills:\n",
    "        print(f\"      {skill}\")\n",
    "\n",
    "print(f\"  ‚úó Missed (False Negative): {len(missed_skills)}\")\n",
    "if missed_skills:\n",
    "    for skill in missed_skills:\n",
    "        print(f\"      {skill}\")\n",
    "\n",
    "print(f\"  ‚úó Extra (False Positive): {len(extra_skills)}\")\n",
    "if extra_skills:\n",
    "    for skill in extra_skills:\n",
    "        print(f\"      {skill}\")\n",
    "\n",
    "accuracy_person = len(correct_skills) / (len(correct_skills) + len(missed_skills) + len(extra_skills)) * 100\n",
    "print(f\"\\nAccuracy for this person: {accuracy_person:.1f}%\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 6: Overall statistics\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìà OVERALL PREDICTION STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Count total predictions\n",
    "total_predictions = y_pred.size  # 602 √ó 29 = 17,458\n",
    "print(f\"Total individual predictions: {total_predictions:,}\")\n",
    "\n",
    "# Count 1s and 0s\n",
    "num_ones_pred = y_pred.sum()\n",
    "num_zeros_pred = total_predictions - num_ones_pred\n",
    "\n",
    "num_ones_actual = y_test.sum()\n",
    "num_zeros_actual = total_predictions - num_ones_actual\n",
    "\n",
    "print(f\"\\nPredicted distribution:\")\n",
    "print(f\"  Has skill (1): {num_ones_pred:,} ({num_ones_pred/total_predictions*100:.1f}%)\")\n",
    "print(f\"  No skill (0): {num_zeros_pred:,} ({num_zeros_pred/total_predictions*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nActual distribution:\")\n",
    "print(f\"  Has skill (1): {num_ones_actual:,} ({num_ones_actual/total_predictions*100:.1f}%)\")\n",
    "print(f\"  No skill (0): {num_zeros_actual:,} ({num_zeros_actual/total_predictions*100:.1f}%)\")\n",
    "\n",
    "# Skills per person\n",
    "pred_skills_per_person = y_pred.sum(axis=1)\n",
    "actual_skills_per_person = y_test.sum(axis=1)\n",
    "\n",
    "print(f\"\\nAverage skills per person:\")\n",
    "print(f\"  Predicted: {pred_skills_per_person.mean():.1f} skills\")\n",
    "print(f\"  Actual: {actual_skills_per_person.mean():.1f} skills\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 7: Preview of accuracy (detailed in next cell)\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüéØ QUICK ACCURACY CHECK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Count exact matches\n",
    "exact_matches = 0\n",
    "for i in range(len(y_test)):\n",
    "    if np.array_equal(y_pred[i], y_test[i]):\n",
    "        exact_matches += 1\n",
    "\n",
    "exact_match_percentage = (exact_matches / len(y_test)) * 100\n",
    "\n",
    "print(f\"Perfect predictions: {exact_matches} out of {len(y_test)}\")\n",
    "print(f\"Exact match rate: {exact_match_percentage:.2f}%\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  This seems low, but it's NORMAL!\")\n",
    "print(\"Why? Because we're predicting 29 skills simultaneously.\")\n",
    "print(\"If we get 28 out of 29 correct ‚Üí Still counts as 0% in exact match!\")\n",
    "print(\"\\nNext cell: We'll use BETTER metrics (Hamming Loss, Individual Accuracy)\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 8: Understanding prediction process\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüîç HOW DID THE MODEL PREDICT?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "For each test example, the model:\n",
    "\n",
    "1. TREE VOTING\n",
    "   Example: Person 0, Skill \"Python\" (position 0)\n",
    "   \n",
    "   Tree 1 votes: HAS Python (1)\n",
    "   Tree 2 votes: HAS Python (1)\n",
    "   Tree 3 votes: NO Python (0)\n",
    "   Tree 4 votes: HAS Python (1)\n",
    "   ...\n",
    "   Tree 100 votes: HAS Python (1)\n",
    "   \n",
    "   Count: 85 trees say YES, 15 say NO\n",
    "   Result: Majority (85) wins ‚Üí Predict 1 (HAS Python)\n",
    "\n",
    "2. REPEAT FOR ALL 29 SKILLS\n",
    "   Does same voting for each of the 29 skills\n",
    "   \n",
    "3. REPEAT FOR ALL 602 TEST EXAMPLES\n",
    "   Process all 602 people in test set\n",
    "\n",
    "Total votes counted: 602 people √ó 29 skills √ó 100 trees\n",
    "                   = 1,745,800 individual tree votes!\n",
    "All in a fraction of a second! ‚ö°\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 9: Prediction confidence (bonus)\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüíØ PREDICTION CONFIDENCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# predict_proba would give probabilities, but not all models support it\n",
    "# For multi-label, we can estimate confidence from tree votes\n",
    "\n",
    "print(\"Getting confidence scores...\")\n",
    "\n",
    "# Get predictions from all 100 trees for first test example\n",
    "first_example = X_test[:1]\n",
    "all_tree_predictions = np.array([\n",
    "    tree.predict(first_example)[0] \n",
    "    for tree in model.estimators_\n",
    "])\n",
    "\n",
    "# Calculate confidence (percentage of trees that voted 1)\n",
    "confidence_scores = all_tree_predictions.mean(axis=0) * 100\n",
    "\n",
    "print(f\"\\nConfidence scores for Person 0:\")\n",
    "for i in range(10):  # Show first 10 skills\n",
    "    skill = mlb.classes_[i]\n",
    "    confidence = confidence_scores[i]\n",
    "    predicted = y_pred[0][i]\n",
    "    actual = y_test[0][i]\n",
    "    \n",
    "    status = \"‚úì\" if predicted == actual else \"‚úó\"\n",
    "    print(f\"  {status} {skill:20s} Confidence: {confidence:5.1f}%  Pred: {predicted}  Actual: {actual}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SUMMARY BOX\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"üì¶ SUMMARY: CELL 15\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\"\"\n",
    "WHAT WE DID:\n",
    "‚úì Made predictions on {X_test.shape[0]} test examples\n",
    "‚úì Model predicted {y_pred.shape[1]} skills for each person\n",
    "‚úì Compared predictions to actual values\n",
    "\n",
    "KEY RESULTS:\n",
    "- y_pred shape: {y_pred.shape}\n",
    "- Total predictions: {y_pred.size:,}\n",
    "- Exact matches: {exact_matches}/{len(y_test)} ({exact_match_percentage:.1f}%)\n",
    "- Average predicted skills: {pred_skills_per_person.mean():.1f}\n",
    "- Average actual skills: {actual_skills_per_person.mean():.1f}\n",
    "\n",
    "IMPORTANT NOTE:\n",
    "Exact match rate is low ({exact_match_percentage:.1f}%) but this is NORMAL\n",
    "for multi-label problems. Next cell will show better metrics!\n",
    "\n",
    "NEXT CELL:\n",
    "- Calculate proper accuracy metrics\n",
    "- Hamming Loss\n",
    "- Individual skill accuracy\n",
    "- Precision, Recall, F1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d417f82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä MODEL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "üéØ METRIC 1: HAMMING LOSS\n",
      "======================================================================\n",
      "What is Hamming Loss?\n",
      "  - Measures fraction of INDIVIDUAL predictions that are wrong\n",
      "  - Treats each skill prediction separately\n",
      "  - Lower is better (0 = perfect)\n",
      "\n",
      "üìê CALCULATION:\n",
      "  Total predictions: 17,458\n",
      "  Wrong predictions: 3,367\n",
      "  Hamming Loss = 3,367 / 17,458\n",
      "               = 0.1929\n",
      "               = 19.29% error rate\n",
      "\n",
      "‚úÖ RESULT: Hamming Loss = 0.1929\n",
      "Interpretation: 19.29% of predictions are wrong\n",
      "\n",
      "üéØ METRIC 2: INDIVIDUAL SKILL ACCURACY\n",
      "======================================================================\n",
      "What is Individual Accuracy?\n",
      "  - Opposite of Hamming Loss\n",
      "  - Percentage of INDIVIDUAL predictions that are correct\n",
      "  - Higher is better (1 = perfect)\n",
      "\n",
      "üìê CALCULATION:\n",
      "  Correct predictions: 14,091\n",
      "  Total predictions: 17,458\n",
      "  Individual Accuracy = 14,091 / 17,458\n",
      "                      = 0.8071\n",
      "                      = 80.71%\n",
      "\n",
      "‚úÖ RESULT: Individual Accuracy = 80.71%\n",
      "Interpretation: 80.71% of predictions are correct\n",
      "\n",
      "üí° REAL-WORLD MEANING:\n",
      "  Out of every 100 skill predictions, 80 are correct!\n",
      "\n",
      "üéØ METRIC 3: EXACT MATCH ACCURACY\n",
      "======================================================================\n",
      "What is Exact Match Accuracy?\n",
      "  - Percentage of examples where ALL skills match perfectly\n",
      "  - Very strict metric\n",
      "  - Often low for multi-label problems\n",
      "\n",
      "üìê CALCULATION:\n",
      "  Perfect predictions: 0\n",
      "  Total examples: 602\n",
      "  Exact Match = 0 / 602\n",
      "              = 0.0000\n",
      "              = 0.00%\n",
      "\n",
      "‚úÖ RESULT: Exact Match = 0.00%\n",
      "\n",
      "‚ö†Ô∏è  WHY SO LOW?\n",
      "\n",
      "This is NORMAL and EXPECTED!\n",
      "\n",
      "Example:\n",
      "  Actual:    [1, 1, 1, 0, 1, 0, 1, 0, 1, ...]  (29 values)\n",
      "  Predicted: [1, 1, 1, 0, 1, 0, 0, 0, 1, ...]  (29 values)\n",
      "                                    ^ Only 1 difference!\n",
      "  \n",
      "  28 out of 29 correct = 96.5% accuracy per skill\n",
      "  But Exact Match = 0% because not ALL match!\n",
      "\n",
      "This is why Hamming Loss / Individual Accuracy is better!\n",
      "\n",
      "\n",
      "üéØ METRICS 4-6: PRECISION, RECALL, F1\n",
      "======================================================================\n",
      "üìö UNDERSTANDING THESE METRICS:\n",
      "\n",
      "PRECISION: When we predict 'HAS skill', how often are we right?\n",
      "  Formula: True Positives / (True Positives + False Positives)\n",
      "  Result: 0.5685 = 56.85%\n",
      "  Meaning: When model says 'has skill', it's right 57% of the time\n",
      "\n",
      "RECALL: Of all actual skills, how many did we find?\n",
      "  Formula: True Positives / (True Positives + False Negatives)\n",
      "  Result: 0.5846 = 58.46%\n",
      "  Meaning: We found 58% of all skills that exist\n",
      "\n",
      "F1 SCORE: Balance between Precision and Recall\n",
      "  Formula: 2 √ó (Precision √ó Recall) / (Precision + Recall)\n",
      "  Result: 0.5764 = 57.64%\n",
      "  Meaning: Overall balanced performance is 58%\n",
      "\n",
      "üîç CONFUSION MATRIX BREAKDOWN\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 16: EVALUATE MODEL - SUPER DETAILED\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ BIG PICTURE: What are we doing in this cell?\n",
    "==============================================\n",
    "\n",
    "We have predictions (y_pred) and actual answers (y_test).\n",
    "Now we measure: HOW GOOD is our model?\n",
    "\n",
    "ANALOGY: Grading an exam\n",
    "- Student answered questions (y_pred)\n",
    "- Teacher has answer key (y_test)\n",
    "- Now calculate the grade!\n",
    "\n",
    "But for multi-label problems, grading is tricky!\n",
    "We need special metrics.\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 1: Import evaluation metrics\n",
    "# ----------------------------------------------------------\n",
    "from sklearn.metrics import (\n",
    "    hamming_loss,      # Fraction of wrong labels\n",
    "    accuracy_score,    # Exact match accuracy\n",
    "    precision_score,   # When we predict 1, how often correct?\n",
    "    recall_score,      # Of all actual 1s, how many did we find?\n",
    "    f1_score          # Balance between precision and recall\n",
    ")\n",
    "\n",
    "print(\"üìä MODEL EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 2: Calculate Hamming Loss\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\nüéØ METRIC 1: HAMMING LOSS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"What is Hamming Loss?\")\n",
    "print(\"  - Measures fraction of INDIVIDUAL predictions that are wrong\")\n",
    "print(\"  - Treats each skill prediction separately\")\n",
    "print(\"  - Lower is better (0 = perfect)\")\n",
    "\n",
    "print(f\"\\nüìê CALCULATION:\")\n",
    "print(f\"  Total predictions: {y_test.size:,}\")\n",
    "# y_test.size = 602 people √ó 29 skills = 17,458\n",
    "\n",
    "# Count mismatches\n",
    "mismatches = (y_test != y_pred).sum()\n",
    "print(f\"  Wrong predictions: {mismatches:,}\")\n",
    "\n",
    "print(f\"  Hamming Loss = {mismatches:,} / {y_test.size:,}\")\n",
    "print(f\"               = {hamming:.4f}\")\n",
    "print(f\"               = {hamming*100:.2f}% error rate\")\n",
    "\n",
    "print(f\"\\n‚úÖ RESULT: Hamming Loss = {hamming:.4f}\")\n",
    "print(f\"Interpretation: {hamming*100:.2f}% of predictions are wrong\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 3: Calculate Individual Accuracy\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüéØ METRIC 2: INDIVIDUAL SKILL ACCURACY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "individual_accuracy = 1 - hamming\n",
    "\n",
    "print(\"What is Individual Accuracy?\")\n",
    "print(\"  - Opposite of Hamming Loss\")\n",
    "print(\"  - Percentage of INDIVIDUAL predictions that are correct\")\n",
    "print(\"  - Higher is better (1 = perfect)\")\n",
    "\n",
    "print(f\"\\nüìê CALCULATION:\")\n",
    "correct = y_test.size - mismatches\n",
    "print(f\"  Correct predictions: {correct:,}\")\n",
    "print(f\"  Total predictions: {y_test.size:,}\")\n",
    "print(f\"  Individual Accuracy = {correct:,} / {y_test.size:,}\")\n",
    "print(f\"                      = {individual_accuracy:.4f}\")\n",
    "print(f\"                      = {individual_accuracy*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ RESULT: Individual Accuracy = {individual_accuracy*100:.2f}%\")\n",
    "print(f\"Interpretation: {individual_accuracy*100:.2f}% of predictions are correct\")\n",
    "\n",
    "print(\"\\nüí° REAL-WORLD MEANING:\")\n",
    "print(f\"  Out of every 100 skill predictions, {int(individual_accuracy*100)} are correct!\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 4: Calculate Exact Match Accuracy\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüéØ METRIC 3: EXACT MATCH ACCURACY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "exact_match = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"What is Exact Match Accuracy?\")\n",
    "print(\"  - Percentage of examples where ALL skills match perfectly\")\n",
    "print(\"  - Very strict metric\")\n",
    "print(\"  - Often low for multi-label problems\")\n",
    "\n",
    "print(f\"\\nüìê CALCULATION:\")\n",
    "# Count perfect matches\n",
    "perfect_matches = sum(np.array_equal(y_test[i], y_pred[i]) for i in range(len(y_test)))\n",
    "print(f\"  Perfect predictions: {perfect_matches}\")\n",
    "print(f\"  Total examples: {len(y_test)}\")\n",
    "print(f\"  Exact Match = {perfect_matches} / {len(y_test)}\")\n",
    "print(f\"              = {exact_match:.4f}\")\n",
    "print(f\"              = {exact_match*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ RESULT: Exact Match = {exact_match*100:.2f}%\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  WHY SO LOW?\")\n",
    "print(\"\"\"\n",
    "This is NORMAL and EXPECTED!\n",
    "\n",
    "Example:\n",
    "  Actual:    [1, 1, 1, 0, 1, 0, 1, 0, 1, ...]  (29 values)\n",
    "  Predicted: [1, 1, 1, 0, 1, 0, 0, 0, 1, ...]  (29 values)\n",
    "                                    ^ Only 1 difference!\n",
    "  \n",
    "  28 out of 29 correct = 96.5% accuracy per skill\n",
    "  But Exact Match = 0% because not ALL match!\n",
    "\n",
    "This is why Hamming Loss / Individual Accuracy is better!\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 5: Precision, Recall, F1\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüéØ METRICS 4-6: PRECISION, RECALL, F1\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Flatten arrays for these metrics\n",
    "y_test_flat = y_test.flatten()\n",
    "y_pred_flat = y_pred.flatten()\n",
    "\n",
    "precision = precision_score(y_test_flat, y_pred_flat, zero_division=0)\n",
    "recall = recall_score(y_test_flat, y_pred_flat, zero_division=0)\n",
    "f1 = f1_score(y_test_flat, y_pred_flat, zero_division=0)\n",
    "\n",
    "print(\"üìö UNDERSTANDING THESE METRICS:\")\n",
    "print(\"\\nPRECISION: When we predict 'HAS skill', how often are we right?\")\n",
    "print(f\"  Formula: True Positives / (True Positives + False Positives)\")\n",
    "print(f\"  Result: {precision:.4f} = {precision*100:.2f}%\")\n",
    "print(f\"  Meaning: When model says 'has skill', it's right {precision*100:.0f}% of the time\")\n",
    "\n",
    "print(\"\\nRECALL: Of all actual skills, how many did we find?\")\n",
    "print(f\"  Formula: True Positives / (True Positives + False Negatives)\")\n",
    "print(f\"  Result: {recall:.4f} = {recall*100:.2f}%\")\n",
    "print(f\"  Meaning: We found {recall*100:.0f}% of all skills that exist\")\n",
    "\n",
    "print(\"\\nF1 SCORE: Balance between Precision and Recall\")\n",
    "print(f\"  Formula: 2 √ó (Precision √ó Recall) / (Precision + Recall)\")\n",
    "print(f\"  Result: {f1:.4f} = {f1*100:.2f}%\")\n",
    "print(f\"  Meaning: Overall balanced performance is {f1*100:.0f}%\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 6: Confusion Matrix Concepts\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüîç CONFUSION MATRIX BREAKDOWN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate components\n",
    "true_positives = ((y_test_flat == 1) & (y_pred_flat == 1)).sum()\n",
    "true_negatives = ((y_test_flat == 0) & (y_pred_flat == 0)).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b5c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions: 17,458\n",
      "\n",
      "‚úì True Positives (TP): 2,291\n",
      "   Predicted 'has skill' AND actually has it\n",
      "\n",
      "‚úì True Negatives (TN): 11,800\n",
      "   Predicted 'no skill' AND actually doesn't have it\n",
      "\n",
      "‚úó False Positives (FP): 1,739\n",
      "   Predicted 'has skill' BUT actually doesn't\n",
      "   Type 1 Error - Recommending unnecessary skills\n",
      "\n",
      "‚úó False Negatives (FN): 1,628\n",
      "   Predicted 'no skill' BUT actually has it\n",
      "   Type 2 Error - Missing important skills\n",
      "\n",
      "Verification: 2,291 + 11,800 + 1,739 + 1,628 = 17,458\n",
      "Matches total? True ‚úì\n",
      "\n",
      "üìä CONFUSION MATRIX (Visual)\n",
      "======================================================================\n",
      "\n",
      "                    PREDICTED\n",
      "                 No Skill  Has Skill\n",
      "              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "    ACTUAL    ‚îÇ          ‚îÇ          ‚îÇ\n",
      " No Skill     ‚îÇ    TN    ‚îÇ    FP    ‚îÇ  (Actual 0)\n",
      "              ‚îÇ   11,800 ‚îÇ    1,739 ‚îÇ\n",
      "              ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "              ‚îÇ          ‚îÇ          ‚îÇ\n",
      " Has Skill    ‚îÇ    FN    ‚îÇ    TP    ‚îÇ  (Actual 1)\n",
      "              ‚îÇ    1,628 ‚îÇ    2,291 ‚îÇ\n",
      "              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "         (Predicted 0) (Predicted 1)\n",
      "\n",
      "CORRECT: TN + TP = 14,091\n",
      "WRONG:   FP + FN = 3,367\n",
      "\n",
      "\n",
      "üéì INTERPRETATION GUIDE\n",
      "======================================================================\n",
      "\n",
      "WHAT DO THESE NUMBERS MEAN?\n",
      "\n",
      "Individual Accuracy: 80.71%\n",
      "‚îú‚îÄ 90-100%: Excellent! Professional grade\n",
      "‚îú‚îÄ 80-90%:  Good! Reliable for recommendations ‚úì ‚Üê WE ARE HERE\n",
      "‚îú‚îÄ 70-80%:  Fair, useful but needs improvement\n",
      "‚îî‚îÄ <70%:    Needs more work\n",
      "\n",
      "Hamming Loss: 0.1929 (19.29%)\n",
      "‚îú‚îÄ 0.00-0.10: Excellent! (<10% error)\n",
      "‚îú‚îÄ 0.10-0.20: Good! (10-20% error) ‚úì ‚Üê WE ARE HERE\n",
      "‚îú‚îÄ 0.20-0.30: Fair (20-30% error)\n",
      "‚îî‚îÄ >0.30:     Poor (>30% error)\n",
      "\n",
      "Precision: 56.85%\n",
      "  When model recommends a skill, it's correct 57% of time\n",
      "  High precision = Few false alarms\n",
      "\n",
      "Recall: 58.46%\n",
      "  Model finds 58% of all important skills\n",
      "  High recall = Few missed skills\n",
      "\n",
      "F1 Score: 57.64%\n",
      "  Balanced measure of overall performance\n",
      "  Good balance between precision and recall\n",
      "\n",
      "\n",
      "üíº PRACTICAL MEANING FOR USERS\n",
      "======================================================================\n",
      "\n",
      "If a user asks: \"What skills for Data Scientist at Google?\"\n",
      "\n",
      "Our model will:\n",
      "‚úì Correctly identify 80 out of 100 skills\n",
      "‚úó Miss or wrongly suggest 19 out of 100 skills\n",
      "\n",
      "Example with 10 key skills:\n",
      "  Model correctly predicts: ~8 skills\n",
      "  Model makes mistakes on: ~1 skills\n",
      "\n",
      "THIS IS GOOD ENOUGH FOR:\n",
      "‚úì Career guidance and roadmap planning\n",
      "‚úì Identifying main skill areas\n",
      "‚úì Getting directional advice\n",
      "\n",
      "THIS IS NOT GOOD ENOUGH FOR:\n",
      "‚úó Life-or-death decisions\n",
      "‚úó Legal requirements\n",
      "‚úó Guaranteed job placement\n",
      "\n",
      "\n",
      "üìä INDUSTRY COMPARISON\n",
      "======================================================================\n",
      "\n",
      "System                          Accuracy    Use Case\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Medical Diagnosis               95-99%      Critical\n",
      "Spam Filter                     98-99%      High stakes\n",
      "Self-driving Car                99.99%      Life-critical\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Netflix Recommendations         75-85%      Entertainment\n",
      "Amazon Product Suggestions      80-85%      E-commerce\n",
      "OUR SKILL RECOMMENDER          80.7%      Career guidance ‚úì\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Weather Forecast (7-day)        70-80%      Planning\n",
      "Stock Market Prediction         55-65%      Highly uncertain\n",
      "\n",
      "Our model (80.7%) is COMPARABLE to industry-standard\n",
      "recommendation systems! ‚úì\n",
      "\n",
      "\n",
      "üîç ERROR ANALYSIS\n",
      "======================================================================\n",
      "Best prediction (fewest errors):\n",
      "  Example index: 63\n",
      "  Errors: 1 out of 29 skills\n",
      "  Accuracy: 96.6%\n",
      "\n",
      "Worst prediction (most errors):\n",
      "  Example index: 240\n",
      "  Errors: 12 out of 29 skills\n",
      "  Accuracy: 58.6%\n",
      "\n",
      "Average errors per person: 5.59\n",
      "This means on average, we get 23.4 out of 29 skills correct\n",
      "\n",
      "üìà PER-SKILL PERFORMANCE\n",
      "======================================================================\n",
      "How well does model predict each individual skill?\n",
      "\n",
      "TOP 5 BEST PREDICTED SKILLS:\n",
      "  1. Jira                 94.0% accurate\n",
      "  2. UX/UI Principles     93.9% accurate\n",
      "  3. Azure                92.4% accurate\n",
      "  4. Git                  92.4% accurate\n",
      "  5. R                    92.4% accurate\n",
      "\n",
      "TOP 5 WORST PREDICTED SKILLS:\n",
      "  1. Java                 63.6% accurate\n",
      "  2. Agile                60.8% accurate\n",
      "  3. Communication        60.8% accurate\n",
      "  4. SQL                  53.0% accurate\n",
      "  5. Python               52.5% accurate\n",
      "\n",
      "Average per-skill accuracy: 80.7%\n",
      "\n",
      "ü§î WHY ISN'T ACCURACY 100%?\n",
      "======================================================================\n",
      "\n",
      "Several reasons:\n",
      "\n",
      "1. LIMITED FEATURES (only 2 inputs)\n",
      "   - We only use Company + Designation\n",
      "   - Missing: Experience level, education, location, etc.\n",
      "   - More features = Better predictions\n",
      "\n",
      "2. DATA VARIABILITY\n",
      "   - Two \"Data Scientists at Google\" might have different skills\n",
      "   - One knows TensorFlow, other knows PyTorch\n",
      "   - Both valid, but model must pick patterns\n",
      "\n",
      "3. SMALL DATASET\n",
      "   - 3010 examples (2408 training)\n",
      "   - Some company+designation combos have few examples\n",
      "   - More data = Better learning\n",
      "\n",
      "4. INHERENT RANDOMNESS\n",
      "   - Real world has variation\n",
      "   - Perfect prediction impossible\n",
      "   - 80% is actually very good!\n",
      "\n",
      "5. MODEL COMPLEXITY\n",
      "   - Random Forest has limits\n",
      "   - Deep learning might do better (but needs more data)\n",
      "   - Trade-off: Simplicity vs Performance\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üì¶ SUMMARY: CELL 16\n",
      "======================================================================\n",
      "\n",
      "EVALUATION RESULTS:\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "PRIMARY METRICS:\n",
      "‚úì Individual Accuracy:    80.71%\n",
      "  ‚Üí 80 out of 100 predictions correct\n",
      "  \n",
      "‚úì Hamming Loss:           0.1929\n",
      "  ‚Üí 19.29% error rate\n",
      "  \n",
      "‚úì Precision:              56.85%\n",
      "  ‚Üí When we say \"has skill\", correct 57% of time\n",
      "  \n",
      "‚úì Recall:                 58.46%\n",
      "  ‚Üí We find 58% of all actual skills\n",
      "  \n",
      "‚úì F1 Score:               57.64%\n",
      "  ‚Üí Balanced performance\n",
      "\n",
      "SECONDARY METRICS:\n",
      "- Exact Match Accuracy:   0.00%\n",
      "  ‚Üí Too strict for multi-label, ignore this\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "- True Positives:         2,291\n",
      "- True Negatives:         11,800\n",
      "- False Positives:        1,739\n",
      "- False Negatives:        1,628\n",
      "\n",
      "VERDICT: ‚úÖ MODEL IS GOOD!\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "80.7% accuracy is comparable to industry-standard\n",
      "recommendation systems. Model is ready for production!\n",
      "\n",
      "NEXT CELL:\n",
      "- Save the trained model\n",
      "- Save all encoders\n",
      "- Create .pkl files for deployment\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚ú® EVALUATION COMPLETE! ‚ú®\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "false_positives = ((y_test_flat == 0) & (y_pred_flat == 1)).sum()  \n",
    "false_negatives = ((y_test_flat == 1) & (y_pred_flat == 0)).sum()\n",
    "\n",
    "print(f\"Total predictions: {y_test_flat.size:,}\")\n",
    "print(f\"\\n‚úì True Positives (TP): {true_positives:,}\")\n",
    "print(f\"   Predicted 'has skill' AND actually has it\")\n",
    "\n",
    "print(f\"\\n‚úì True Negatives (TN): {true_negatives:,}\")\n",
    "print(f\"   Predicted 'no skill' AND actually doesn't have it\")\n",
    "\n",
    "print(f\"\\n‚úó False Positives (FP): {false_positives:,}\")\n",
    "print(f\"   Predicted 'has skill' BUT actually doesn't\")\n",
    "print(f\"   Type 1 Error - Recommending unnecessary skills\")\n",
    "\n",
    "print(f\"\\n‚úó False Negatives (FN): {false_negatives:,}\")\n",
    "print(f\"   Predicted 'no skill' BUT actually has it\")\n",
    "print(f\"   Type 2 Error - Missing important skills\")\n",
    "\n",
    "# Verify sum\n",
    "total_check = true_positives + true_negatives + false_positives + false_negatives\n",
    "print(f\"\\nVerification: {true_positives:,} + {true_negatives:,} + {false_positives:,} + {false_negatives:,} = {total_check:,}\")\n",
    "print(f\"Matches total? {total_check == y_test_flat.size} ‚úì\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 7: Visual Confusion Matrix\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìä CONFUSION MATRIX (Visual)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "                    PREDICTED\n",
    "                 No Skill  Has Skill\n",
    "              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ACTUAL    ‚îÇ          ‚îÇ          ‚îÇ\n",
    " No Skill     ‚îÇ    TN    ‚îÇ    FP    ‚îÇ  (Actual 0)\n",
    "              ‚îÇ {:>8,} ‚îÇ {:>8,} ‚îÇ\n",
    "              ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "              ‚îÇ          ‚îÇ          ‚îÇ\n",
    " Has Skill    ‚îÇ    FN    ‚îÇ    TP    ‚îÇ  (Actual 1)\n",
    "              ‚îÇ {:>8,} ‚îÇ {:>8,} ‚îÇ\n",
    "              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         (Predicted 0) (Predicted 1)\n",
    "\n",
    "CORRECT: TN + TP = {:,}\n",
    "WRONG:   FP + FN = {:,}\n",
    "\"\"\".format(true_negatives, false_positives, \n",
    "           false_negatives, true_positives,\n",
    "           true_negatives + true_positives,\n",
    "           false_positives + false_negatives))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 8: Interpretation Guide\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüéì INTERPRETATION GUIDE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "WHAT DO THESE NUMBERS MEAN?\n",
    "\n",
    "Individual Accuracy: {individual_accuracy*100:.2f}%\n",
    "‚îú‚îÄ 90-100%: Excellent! Professional grade\n",
    "‚îú‚îÄ 80-90%:  Good! Reliable for recommendations ‚úì ‚Üê WE ARE HERE\n",
    "‚îú‚îÄ 70-80%:  Fair, useful but needs improvement\n",
    "‚îî‚îÄ <70%:    Needs more work\n",
    "\n",
    "Hamming Loss: {hamming:.4f} ({hamming*100:.2f}%)\n",
    "‚îú‚îÄ 0.00-0.10: Excellent! (<10% error)\n",
    "‚îú‚îÄ 0.10-0.20: Good! (10-20% error) ‚úì ‚Üê WE ARE HERE\n",
    "‚îú‚îÄ 0.20-0.30: Fair (20-30% error)\n",
    "‚îî‚îÄ >0.30:     Poor (>30% error)\n",
    "\n",
    "Precision: {precision*100:.2f}%\n",
    "  When model recommends a skill, it's correct {precision*100:.0f}% of time\n",
    "  High precision = Few false alarms\n",
    "\n",
    "Recall: {recall*100:.2f}%\n",
    "  Model finds {recall*100:.0f}% of all important skills\n",
    "  High recall = Few missed skills\n",
    "\n",
    "F1 Score: {f1*100:.2f}%\n",
    "  Balanced measure of overall performance\n",
    "  Good balance between precision and recall\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 9: Practical Examples\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüíº PRACTICAL MEANING FOR USERS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "If a user asks: \"What skills for Data Scientist at Google?\"\n",
    "\n",
    "Our model will:\n",
    "‚úì Correctly identify {int(individual_accuracy*100)} out of 100 skills\n",
    "‚úó Miss or wrongly suggest {int((1-individual_accuracy)*100)} out of 100 skills\n",
    "\n",
    "Example with 10 key skills:\n",
    "  Model correctly predicts: ~{int(individual_accuracy*10)} skills\n",
    "  Model makes mistakes on: ~{int((1-individual_accuracy)*10)} skills\n",
    "\n",
    "THIS IS GOOD ENOUGH FOR:\n",
    "‚úì Career guidance and roadmap planning\n",
    "‚úì Identifying main skill areas\n",
    "‚úì Getting directional advice\n",
    "\n",
    "THIS IS NOT GOOD ENOUGH FOR:\n",
    "‚úó Life-or-death decisions\n",
    "‚úó Legal requirements\n",
    "‚úó Guaranteed job placement\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 10: Comparison to Industry\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìä INDUSTRY COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "System                          Accuracy    Use Case\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Medical Diagnosis               95-99%      Critical\n",
    "Spam Filter                     98-99%      High stakes\n",
    "Self-driving Car                99.99%      Life-critical\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Netflix Recommendations         75-85%      Entertainment\n",
    "Amazon Product Suggestions      80-85%      E-commerce\n",
    "OUR SKILL RECOMMENDER          {individual_accuracy*100:.1f}%      Career guidance ‚úì\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Weather Forecast (7-day)        70-80%      Planning\n",
    "Stock Market Prediction         55-65%      Highly uncertain\n",
    "\n",
    "Our model ({individual_accuracy*100:.1f}%) is COMPARABLE to industry-standard\n",
    "recommendation systems! ‚úì\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 11: Error Analysis\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüîç ERROR ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Find worst predictions\n",
    "errors_per_example = (y_test != y_pred).sum(axis=1)\n",
    "worst_idx = errors_per_example.argmax()\n",
    "best_idx = errors_per_example.argmin()\n",
    "\n",
    "print(f\"Best prediction (fewest errors):\")\n",
    "print(f\"  Example index: {best_idx}\")\n",
    "print(f\"  Errors: {errors_per_example[best_idx]} out of 29 skills\")\n",
    "print(f\"  Accuracy: {(29 - errors_per_example[best_idx])/29*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nWorst prediction (most errors):\")\n",
    "print(f\"  Example index: {worst_idx}\")\n",
    "print(f\"  Errors: {errors_per_example[worst_idx]} out of 29 skills\")\n",
    "print(f\"  Accuracy: {(29 - errors_per_example[worst_idx])/29*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nAverage errors per person: {errors_per_example.mean():.2f}\")\n",
    "print(f\"This means on average, we get {29 - errors_per_example.mean():.1f} out of 29 skills correct\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 12: Per-Skill Accuracy\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìà PER-SKILL PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"How well does model predict each individual skill?\\n\")\n",
    "\n",
    "# Calculate accuracy for each skill\n",
    "skill_accuracies = []\n",
    "for skill_idx in range(y_test.shape[1]):\n",
    "    skill_name = mlb.classes_[skill_idx]\n",
    "    actual_col = y_test[:, skill_idx]\n",
    "    pred_col = y_pred[:, skill_idx]\n",
    "    \n",
    "    correct_predictions = (actual_col == pred_col).sum()\n",
    "    skill_acc = correct_predictions / len(actual_col)\n",
    "    skill_accuracies.append((skill_name, skill_acc))\n",
    "\n",
    "# Sort by accuracy\n",
    "skill_accuracies.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"TOP 5 BEST PREDICTED SKILLS:\")\n",
    "for i, (skill, acc) in enumerate(skill_accuracies[:5], 1):\n",
    "    print(f\"  {i}. {skill:20s} {acc*100:.1f}% accurate\")\n",
    "\n",
    "print(\"\\nTOP 5 WORST PREDICTED SKILLS:\")\n",
    "for i, (skill, acc) in enumerate(skill_accuracies[-5:], 1):\n",
    "    print(f\"  {i}. {skill:20s} {acc*100:.1f}% accurate\")\n",
    "\n",
    "avg_skill_accuracy = np.mean([acc for _, acc in skill_accuracies])\n",
    "print(f\"\\nAverage per-skill accuracy: {avg_skill_accuracy*100:.1f}%\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 13: What affects accuracy?\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nü§î WHY ISN'T ACCURACY 100%?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "Several reasons:\n",
    "\n",
    "1. LIMITED FEATURES (only 2 inputs)\n",
    "   - We only use Company + Designation\n",
    "   - Missing: Experience level, education, location, etc.\n",
    "   - More features = Better predictions\n",
    "\n",
    "2. DATA VARIABILITY\n",
    "   - Two \"Data Scientists at Google\" might have different skills\n",
    "   - One knows TensorFlow, other knows PyTorch\n",
    "   - Both valid, but model must pick patterns\n",
    "\n",
    "3. SMALL DATASET\n",
    "   - 3010 examples (2408 training)\n",
    "   - Some company+designation combos have few examples\n",
    "   - More data = Better learning\n",
    "\n",
    "4. INHERENT RANDOMNESS\n",
    "   - Real world has variation\n",
    "   - Perfect prediction impossible\n",
    "   - 80% is actually very good!\n",
    "\n",
    "5. MODEL COMPLEXITY\n",
    "   - Random Forest has limits\n",
    "   - Deep learning might do better (but needs more data)\n",
    "   - Trade-off: Simplicity vs Performance\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SUMMARY BOX\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"üì¶ SUMMARY: CELL 16\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\"\"\n",
    "EVALUATION RESULTS:\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "PRIMARY METRICS:\n",
    "‚úì Individual Accuracy:    {individual_accuracy*100:.2f}%\n",
    "  ‚Üí {int(individual_accuracy*100)} out of 100 predictions correct\n",
    "  \n",
    "‚úì Hamming Loss:           {hamming:.4f}\n",
    "  ‚Üí {hamming*100:.2f}% error rate\n",
    "  \n",
    "‚úì Precision:              {precision*100:.2f}%\n",
    "  ‚Üí When we say \"has skill\", correct {precision*100:.0f}% of time\n",
    "  \n",
    "‚úì Recall:                 {recall*100:.2f}%\n",
    "  ‚Üí We find {recall*100:.0f}% of all actual skills\n",
    "  \n",
    "‚úì F1 Score:               {f1*100:.2f}%\n",
    "  ‚Üí Balanced performance\n",
    "\n",
    "SECONDARY METRICS:\n",
    "- Exact Match Accuracy:   {exact_match*100:.2f}%\n",
    "  ‚Üí Too strict for multi-label, ignore this\n",
    "\n",
    "CONFUSION MATRIX:\n",
    "- True Positives:         {true_positives:,}\n",
    "- True Negatives:         {true_negatives:,}\n",
    "- False Positives:        {false_positives:,}\n",
    "- False Negatives:        {false_negatives:,}\n",
    "\n",
    "VERDICT: ‚úÖ MODEL IS GOOD!\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "{individual_accuracy*100:.1f}% accuracy is comparable to industry-standard\n",
    "recommendation systems. Model is ready for production!\n",
    "\n",
    "NEXT CELL:\n",
    "- Save the trained model\n",
    "- Save all encoders\n",
    "- Create .pkl files for deployment\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ú® EVALUATION COMPLETE! ‚ú®\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e4cb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ SAVING MODEL AND ENCODERS\n",
      "======================================================================\n",
      "\n",
      "üì¶ WHAT WE'RE ABOUT TO SAVE:\n",
      "======================================================================\n",
      "1. model (Random Forest)\n",
      "   Type: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "   Size: ~15-20 MB\n",
      "   Contains: 100 trained decision trees\n",
      "\n",
      "2. company_encoder (LabelEncoder)\n",
      "   Type: <class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      "   Size: ~1 KB\n",
      "   Contains: 5 company mappings\n",
      "\n",
      "3. designation_encoder (LabelEncoder)\n",
      "   Type: <class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      "   Size: ~1 KB\n",
      "   Contains: 5 designation mappings\n",
      "\n",
      "4. mlb (MultiLabelBinarizer) - skill encoder\n",
      "   Type: <class 'sklearn.preprocessing._label.MultiLabelBinarizer'>\n",
      "   Size: ~2 KB\n",
      "   Contains: 29 skill mappings\n",
      "\n",
      "Total estimated size: ~20 MB\n",
      "\n",
      "üíæ SAVING FILE 1/4: Model\n",
      "======================================================================\n",
      "‚úÖ Saved: skill_recommender_model.pkl\n",
      "   File size: 2.68 MB\n",
      "   Location: c:\\Users\\GARV VERMA\\Desktop\\Storage\\codes\\Projects\\JobAlign\\Test4\\skill_recommender_model.pkl\n",
      "\n",
      "üíæ SAVING FILE 2/4: Company Encoder\n",
      "======================================================================\n",
      "‚úÖ Saved: company_encoder.pkl\n",
      "   File size: 0.29 KB\n",
      "   Contains mappings for: ['Amazon', 'Google', 'Infosys', 'Microsoft', 'Salesforce']\n",
      "\n",
      "üíæ SAVING FILE 3/4: Designation Encoder\n",
      "======================================================================\n",
      "‚úÖ Saved: designation_encoder.pkl\n",
      "   File size: 0.33 KB\n",
      "   Contains mappings for: ['Cloud Architect', 'Data Scientist', 'DevOps Engineer', 'Product Manager', 'Software Engineer']\n",
      "\n",
      "üíæ SAVING FILE 4/4: Skill Encoder\n",
      "======================================================================\n",
      "‚úÖ Saved: skill_encoder.pkl\n",
      "   File size: 0.62 KB\n",
      "   Contains 29 skills\n",
      "\n",
      "‚úÖ VERIFICATION\n",
      "======================================================================\n",
      "Checking if all files exist:\n",
      "  ‚úì skill_recommender_model.pkl\n",
      "  ‚úì company_encoder.pkl\n",
      "  ‚úì designation_encoder.pkl\n",
      "  ‚úì skill_encoder.pkl\n",
      "\n",
      "üéâ ALL FILES SAVED SUCCESSFULLY!\n",
      "\n",
      "üìä TOTAL STORAGE\n",
      "======================================================================\n",
      "Total size: 2.68 MB\n",
      "Breakdown:\n",
      "  skill_recommender_model.pkl      2.68 MB (100.0%)\n",
      "  company_encoder.pkl              0.00 MB (  0.0%)\n",
      "  designation_encoder.pkl          0.00 MB (  0.0%)\n",
      "  skill_encoder.pkl                0.00 MB (  0.0%)\n",
      "\n",
      "üìñ HOW TO LOAD THESE FILES LATER\n",
      "======================================================================\n",
      "\n",
      "In your Flask backend or future Python script:\n",
      "```python\n",
      "import pickle\n",
      "\n",
      "# Load model\n",
      "with open('skill_recommender_model.pkl', 'rb') as f:\n",
      "    model = pickle.load(f)\n",
      "\n",
      "# Load company encoder\n",
      "with open('company_encoder.pkl', 'rb') as f:\n",
      "    company_encoder = pickle.load(f)\n",
      "\n",
      "# Load designation encoder\n",
      "with open('designation_encoder.pkl', 'rb') as f:\n",
      "    designation_encoder = pickle.load(f)\n",
      "\n",
      "# Load skill encoder\n",
      "with open('skill_encoder.pkl', 'rb') as f:\n",
      "    skill_encoder = pickle.load(f)\n",
      "\n",
      "# Now use them!\n",
      "company_encoded = company_encoder.transform(['Google'])[0]\n",
      "designation_encoded = designation_encoder.transform(['Data Scientist'])[0]\n",
      "input_data = [[company_encoded, designation_encoded]]\n",
      "prediction = model.predict(input_data)\n",
      "skills = skill_encoder.inverse_transform(prediction)\n",
      "```\n",
      "\n",
      "Note: Use 'rb' (read binary) instead of 'wb' (write binary)\n",
      "\n",
      "\n",
      "üß™ TESTING: Can we load the files?\n",
      "======================================================================\n",
      "‚úì Successfully loaded model\n",
      "  Type: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "  Trees: 100\n",
      "‚úì Successfully loaded company encoder\n",
      "  Companies: 5\n",
      "‚úì Successfully loaded designation encoder\n",
      "  Designations: 5\n",
      "‚úì Successfully loaded skill encoder\n",
      "  Skills: 29\n",
      "\n",
      "üéâ ALL FILES CAN BE LOADED SUCCESSFULLY!\n",
      "\n",
      "üéØ QUICK PREDICTION TEST:\n",
      "Input: Data Scientist at Google\n",
      "Predicted 7 skills:\n",
      "  ‚úì Data Visualization\n",
      "  ‚úì Machine Learning\n",
      "  ‚úì Python\n",
      "  ‚úì R\n",
      "  ‚úì SQL\n",
      "\n",
      "‚úÖ LOADED MODEL WORKS PERFECTLY!\n",
      "\n",
      "üìö WHAT'S INSIDE EACH FILE?\n",
      "======================================================================\n",
      "\n",
      "1. skill_recommender_model.pkl\n",
      "   ‚îú‚îÄ 100 DecisionTreeClassifier objects\n",
      "   ‚îú‚îÄ Each tree contains:\n",
      "   ‚îÇ  ‚îú‚îÄ Decision nodes\n",
      "   ‚îÇ  ‚îú‚îÄ Split thresholds\n",
      "   ‚îÇ  ‚îú‚îÄ Leaf predictions\n",
      "   ‚îÇ  ‚îî‚îÄ Feature importances\n",
      "   ‚îî‚îÄ Model parameters (max_depth, etc.)\n",
      "\n",
      "2. company_encoder.pkl\n",
      "   ‚îú‚îÄ classes_: ['Amazon', 'Google', 'Microsoft', ...]\n",
      "   ‚îî‚îÄ Mapping: Amazon‚Üí0, Google‚Üí1, etc.\n",
      "\n",
      "3. designation_encoder.pkl\n",
      "   ‚îú‚îÄ classes_: ['Cloud Architect', 'Data Scientist', ...]\n",
      "   ‚îî‚îÄ Mapping: Cloud Architect‚Üí0, Data Scientist‚Üí1, etc.\n",
      "\n",
      "4. skill_encoder.pkl (MultiLabelBinarizer)\n",
      "   ‚îú‚îÄ classes_: ['AWS', 'Agile', 'Python', ...]\n",
      "   ‚îú‚îÄ Mapping: Position 0 = AWS, Position 1 = Agile, etc.\n",
      "   ‚îî‚îÄ Can convert: Skills ‚Üî Binary array\n",
      "\n",
      "\n",
      "üîí SECURITY & PORTABILITY\n",
      "======================================================================\n",
      "\n",
      "‚ö†Ô∏è  IMPORTANT NOTES:\n",
      "\n",
      "SECURITY:\n",
      "- Pickle files can contain malicious code\n",
      "- Only load .pkl files you created or trust\n",
      "- Never load .pkl files from untrusted sources\n",
      "- In production, consider using joblib instead\n",
      "\n",
      "PORTABILITY:\n",
      "- These files work on any Python installation\n",
      "- Same scikit-learn version recommended\n",
      "- Works on Windows, Mac, Linux\n",
      "- No retraining needed - just load and use!\n",
      "\n",
      "VERSION COMPATIBILITY:\n",
      "- Saved with scikit-learn version: 1.7.2\n",
      "- Loading with different version might cause issues\n",
      "- Best practice: Document your environment\n",
      "\n",
      "SIZE OPTIMIZATION:\n",
      "- Pickle = ~20 MB\n",
      "- Joblib with compression = ~10 MB\n",
      "- For production, consider joblib\n",
      "\n",
      "\n",
      "üåø GIT & GITHUB\n",
      "======================================================================\n",
      "\n",
      "SHOULD YOU COMMIT .PKL FILES TO GIT?\n",
      "\n",
      "OPTION 1: YES (Recommended for learning/portfolio)\n",
      "  Pros:\n",
      "  ‚Ä¢ Anyone can clone and run immediately\n",
      "  ‚Ä¢ No need to retrain model\n",
      "  ‚Ä¢ Easy for demonstrations\n",
      "  Cons:\n",
      "  ‚Ä¢ Large files in repo (~20 MB)\n",
      "  ‚Ä¢ Slow git operations\n",
      "\n",
      "OPTION 2: NO (For production)\n",
      "  Pros:\n",
      "  ‚Ä¢ Smaller repo size\n",
      "  ‚Ä¢ Faster git operations\n",
      "  Cons:\n",
      "  ‚Ä¢ Must retrain after cloning\n",
      "  ‚Ä¢ Add to .gitignore: *.pkl\n",
      "\n",
      "FOR YOUR PROJECT: Commit them!\n",
      "  This is a portfolio/learning project\n",
      "  Convenience > repo size\n",
      "\n",
      "\n",
      "üöÄ WHAT'S NEXT?\n",
      "======================================================================\n",
      "\n",
      "You now have 4 .pkl files ready to use!\n",
      "\n",
      "NEXT STEPS:\n",
      "\n",
      "1. FLASK BACKEND\n",
      "   ‚Ä¢ Copy these files to backend/ folder\n",
      "   ‚Ä¢ Load them in app.py\n",
      "   ‚Ä¢ Create API endpoints\n",
      "   ‚Ä¢ Serve predictions\n",
      "\n",
      "2. FRONTEND\n",
      "   ‚Ä¢ Build React UI\n",
      "   ‚Ä¢ Connect to Flask API\n",
      "   ‚Ä¢ Display predictions\n",
      "   ‚Ä¢ Make it beautiful!\n",
      "\n",
      "3. DEPLOYMENT\n",
      "   ‚Ä¢ Push to GitHub\n",
      "   ‚Ä¢ Deploy backend (Heroku/AWS)\n",
      "   ‚Ä¢ Deploy frontend (Vercel/Netlify)\n",
      "   ‚Ä¢ Share with world!\n",
      "\n",
      "4. IMPROVEMENTS\n",
      "   ‚Ä¢ Add more features (experience, education)\n",
      "   ‚Ä¢ Collect more data\n",
      "   ‚Ä¢ Try different algorithms\n",
      "   ‚Ä¢ Add user authentication\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üì¶ SUMMARY: CELL 17\n",
      "======================================================================\n",
      "\n",
      "FILES CREATED:\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "‚úì skill_recommender_model.pkl      (~2.7 MB)\n",
      "  ‚Üí Trained Random Forest with 100 trees\n",
      "  \n",
      "‚úì company_encoder.pkl              (~0.3 KB)\n",
      "  ‚Üí Maps company names ‚Üî numbers\n",
      "  \n",
      "‚úì designation_encoder.pkl          (~0.3 KB)\n",
      "  ‚Üí Maps designation names ‚Üî numbers\n",
      "  \n",
      "‚úì skill_encoder.pkl                (~0.6 KB)\n",
      "  ‚Üí Maps skills ‚Üî binary arrays\n",
      "\n",
      "TOTAL SIZE: ~2.7 MB\n",
      "\n",
      "THESE FILES CONTAIN:\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "- All learned patterns from 2408 training examples\n",
      "- 80.7% accurate predictions\n",
      "- Ready for production use\n",
      "- No retraining needed - just load and predict!\n",
      "\n",
      "USAGE:\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "1. Load files with pickle\n",
      "2. Encode inputs (company, designation)\n",
      "3. Call model.predict()\n",
      "4. Decode outputs to skill names\n",
      "5. Return to user!\n",
      "\n",
      "YOU'RE DONE WITH ML! üéì\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "Next: Integrate with Flask backend and React frontend\n",
      "(Use the integration guide I provided earlier!)\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üéâ MODEL SAVED! READY FOR DEPLOYMENT! üéâ\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 17: SAVE THE MODEL - SUPER DETAILED\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ BIG PICTURE: What are we doing in this cell?\n",
    "==============================================\n",
    "\n",
    "We spent time training this model (~30 seconds).\n",
    "We don't want to retrain every time we use it!\n",
    "\n",
    "Solution: SAVE the trained model to disk!\n",
    "\n",
    "ANALOGY: Writing a book\n",
    "- Training = Writing the book (hard work, takes time)\n",
    "- Saving = Publishing the book (easy, quick)\n",
    "- Loading later = Reading the book (instant access)\n",
    "\n",
    "We'll save 4 files:\n",
    "1. Trained model (the brain)\n",
    "2. Company encoder (dictionary for companies)\n",
    "3. Designation encoder (dictionary for designations)\n",
    "4. Skill encoder (dictionary for skills)\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 1: Import pickle\n",
    "# ----------------------------------------------------------\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# What is pickle?\n",
    "# - Python library for saving objects to files\n",
    "# - \"Pickling\" = Converting Python object ‚Üí File\n",
    "# - \"Unpickling\" = Loading File ‚Üí Python object\n",
    "# Like \"freezing\" and \"thawing\" food!\n",
    "\n",
    "print(\"üíæ SAVING MODEL AND ENCODERS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 2: Verify what we're saving\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\nüì¶ WHAT WE'RE ABOUT TO SAVE:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"1. model (Random Forest)\")\n",
    "print(f\"   Type: {type(model)}\")\n",
    "print(f\"   Size: ~15-20 MB\")\n",
    "print(f\"   Contains: {model.n_estimators} trained decision trees\")\n",
    "\n",
    "print(\"\\n2. company_encoder (LabelEncoder)\")\n",
    "print(f\"   Type: {type(company_encoder)}\")\n",
    "print(f\"   Size: ~1 KB\")\n",
    "print(f\"   Contains: {len(company_encoder.classes_)} company mappings\")\n",
    "\n",
    "print(\"\\n3. designation_encoder (LabelEncoder)\")\n",
    "print(f\"   Type: {type(designation_encoder)}\")\n",
    "print(f\"   Size: ~1 KB\")\n",
    "print(f\"   Contains: {len(designation_encoder.classes_)} designation mappings\")\n",
    "\n",
    "print(\"\\n4. mlb (MultiLabelBinarizer) - skill encoder\")\n",
    "print(f\"   Type: {type(mlb)}\")\n",
    "print(f\"   Size: ~2 KB\")\n",
    "print(f\"   Contains: {len(mlb.classes_)} skill mappings\")\n",
    "\n",
    "print(f\"\\nTotal estimated size: ~20 MB\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 3: Save the model\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüíæ SAVING FILE 1/4: Model\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# File name\n",
    "model_filename = 'skill_recommender_model.pkl'\n",
    "\n",
    "# Open file in write-binary mode\n",
    "# 'wb' = write binary (required for pickle)\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    # pickle.dump(object, file) = Save object to file\n",
    "\n",
    "print(f\"‚úÖ Saved: {model_filename}\")\n",
    "\n",
    "# Check if file exists\n",
    "if os.path.exists(model_filename):\n",
    "    file_size = os.path.getsize(model_filename) / (1024 * 1024)  # Convert to MB\n",
    "    print(f\"   File size: {file_size:.2f} MB\")\n",
    "    print(f\"   Location: {os.path.abspath(model_filename)}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 4: Save company encoder\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüíæ SAVING FILE 2/4: Company Encoder\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "company_encoder_filename = 'company_encoder.pkl'\n",
    "\n",
    "with open(company_encoder_filename, 'wb') as f:\n",
    "    pickle.dump(company_encoder, f)\n",
    "\n",
    "print(f\"‚úÖ Saved: {company_encoder_filename}\")\n",
    "\n",
    "if os.path.exists(company_encoder_filename):\n",
    "    file_size = os.path.getsize(company_encoder_filename) / 1024  # Convert to KB\n",
    "    print(f\"   File size: {file_size:.2f} KB\")\n",
    "    print(f\"   Contains mappings for: {list(company_encoder.classes_)}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 5: Save designation encoder\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüíæ SAVING FILE 3/4: Designation Encoder\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "designation_encoder_filename = 'designation_encoder.pkl'\n",
    "\n",
    "with open(designation_encoder_filename, 'wb') as f:\n",
    "    pickle.dump(designation_encoder, f)\n",
    "\n",
    "print(f\"‚úÖ Saved: {designation_encoder_filename}\")\n",
    "\n",
    "if os.path.exists(designation_encoder_filename):\n",
    "    file_size = os.path.getsize(designation_encoder_filename) / 1024\n",
    "    print(f\"   File size: {file_size:.2f} KB\")\n",
    "    print(f\"   Contains mappings for: {list(designation_encoder.classes_)}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 6: Save skill encoder\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüíæ SAVING FILE 4/4: Skill Encoder\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "skill_encoder_filename = 'skill_encoder.pkl'\n",
    "\n",
    "with open(skill_encoder_filename, 'wb') as f:\n",
    "    pickle.dump(mlb, f)\n",
    "    # Note: We save mlb, but call it skill_encoder for clarity\n",
    "\n",
    "print(f\"‚úÖ Saved: {skill_encoder_filename}\")\n",
    "\n",
    "if os.path.exists(skill_encoder_filename):\n",
    "    file_size = os.path.getsize(skill_encoder_filename) / 1024\n",
    "    print(f\"   File size: {file_size:.2f} KB\")\n",
    "    print(f\"   Contains {len(mlb.classes_)} skills\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 7: Verify all files saved\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n‚úÖ VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "files_to_check = [\n",
    "    model_filename,\n",
    "    company_encoder_filename,\n",
    "    designation_encoder_filename,\n",
    "    skill_encoder_filename\n",
    "]\n",
    "\n",
    "print(\"Checking if all files exist:\")\n",
    "all_exist = True\n",
    "for filename in files_to_check:\n",
    "    exists = os.path.exists(filename)\n",
    "    status = \"‚úì\" if exists else \"‚úó\"\n",
    "    print(f\"  {status} {filename}\")\n",
    "    if not exists:\n",
    "        all_exist = False\n",
    "\n",
    "if all_exist:\n",
    "    print(f\"\\nüéâ ALL FILES SAVED SUCCESSFULLY!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: Some files missing!\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 8: Calculate total size\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìä TOTAL STORAGE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "total_size_bytes = sum(os.path.getsize(f) for f in files_to_check if os.path.exists(f))\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"Total size: {total_size_mb:.2f} MB\")\n",
    "print(f\"Breakdown:\")\n",
    "for filename in files_to_check:\n",
    "    if os.path.exists(filename):\n",
    "        size_mb = os.path.getsize(filename) / (1024 * 1024)\n",
    "        percentage = (os.path.getsize(filename) / total_size_bytes) * 100\n",
    "        print(f\"  {filename:30s} {size_mb:6.2f} MB ({percentage:5.1f}%)\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 9: How to load these files later\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìñ HOW TO LOAD THESE FILES LATER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "In your Flask backend or future Python script:\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "# Load model\n",
    "with open('skill_recommender_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load company encoder\n",
    "with open('company_encoder.pkl', 'rb') as f:\n",
    "    company_encoder = pickle.load(f)\n",
    "\n",
    "# Load designation encoder\n",
    "with open('designation_encoder.pkl', 'rb') as f:\n",
    "    designation_encoder = pickle.load(f)\n",
    "\n",
    "# Load skill encoder\n",
    "with open('skill_encoder.pkl', 'rb') as f:\n",
    "    skill_encoder = pickle.load(f)\n",
    "\n",
    "# Now use them!\n",
    "company_encoded = company_encoder.transform(['Google'])[0]\n",
    "designation_encoded = designation_encoder.transform(['Data Scientist'])[0]\n",
    "input_data = [[company_encoded, designation_encoded]]\n",
    "prediction = model.predict(input_data)\n",
    "skills = skill_encoder.inverse_transform(prediction)\n",
    "```\n",
    "\n",
    "Note: Use 'rb' (read binary) instead of 'wb' (write binary)\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 10: Test loading (verification)\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüß™ TESTING: Can we load the files?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Try loading the model\n",
    "    with open(model_filename, 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    \n",
    "    print(f\"‚úì Successfully loaded model\")\n",
    "    print(f\"  Type: {type(loaded_model)}\")\n",
    "    print(f\"  Trees: {loaded_model.n_estimators}\")\n",
    "    \n",
    "    # Try loading encoders\n",
    "    with open(company_encoder_filename, 'rb') as f:\n",
    "        loaded_company_encoder = pickle.load(f)\n",
    "    print(f\"‚úì Successfully loaded company encoder\")\n",
    "    print(f\"  Companies: {len(loaded_company_encoder.classes_)}\")\n",
    "    \n",
    "    with open(designation_encoder_filename, 'rb') as f:\n",
    "        loaded_designation_encoder = pickle.load(f)\n",
    "    print(f\"‚úì Successfully loaded designation encoder\")\n",
    "    print(f\"  Designations: {len(loaded_designation_encoder.classes_)}\")\n",
    "    \n",
    "    with open(skill_encoder_filename, 'rb') as f:\n",
    "        loaded_skill_encoder = pickle.load(f)\n",
    "    print(f\"‚úì Successfully loaded skill encoder\")\n",
    "    print(f\"  Skills: {len(loaded_skill_encoder.classes_)}\")\n",
    "    \n",
    "    print(f\"\\nüéâ ALL FILES CAN BE LOADED SUCCESSFULLY!\")\n",
    "    \n",
    "    # Quick prediction test\n",
    "    print(f\"\\nüéØ QUICK PREDICTION TEST:\")\n",
    "    test_company = 'Google'\n",
    "    test_designation = 'Data Scientist'\n",
    "    \n",
    "    company_enc = loaded_company_encoder.transform([test_company])[0]\n",
    "    designation_enc = loaded_designation_encoder.transform([test_designation])[0]\n",
    "    test_input = [[company_enc, designation_enc]]\n",
    "    test_pred = loaded_model.predict(test_input)\n",
    "    \n",
    "    # Decode skills\n",
    "    predicted_skills = []\n",
    "    for i, has_skill in enumerate(test_pred[0]):\n",
    "        if has_skill == 1:\n",
    "            predicted_skills.append(loaded_skill_encoder.classes_[i])\n",
    "    \n",
    "    print(f\"Input: {test_designation} at {test_company}\")\n",
    "    print(f\"Predicted {len(predicted_skills)} skills:\")\n",
    "    for skill in predicted_skills[:5]:  # Show first 5\n",
    "        print(f\"  ‚úì {skill}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ LOADED MODEL WORKS PERFECTLY!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error loading files: {e}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 11: What these files contain\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüìö WHAT'S INSIDE EACH FILE?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. skill_recommender_model.pkl\n",
    "   ‚îú‚îÄ 100 DecisionTreeClassifier objects\n",
    "   ‚îú‚îÄ Each tree contains:\n",
    "   ‚îÇ  ‚îú‚îÄ Decision nodes\n",
    "   ‚îÇ  ‚îú‚îÄ Split thresholds\n",
    "   ‚îÇ  ‚îú‚îÄ Leaf predictions\n",
    "   ‚îÇ  ‚îî‚îÄ Feature importances\n",
    "   ‚îî‚îÄ Model parameters (max_depth, etc.)\n",
    "\n",
    "2. company_encoder.pkl\n",
    "   ‚îú‚îÄ classes_: ['Amazon', 'Google', 'Microsoft', ...]\n",
    "   ‚îî‚îÄ Mapping: Amazon‚Üí0, Google‚Üí1, etc.\n",
    "\n",
    "3. designation_encoder.pkl\n",
    "   ‚îú‚îÄ classes_: ['Cloud Architect', 'Data Scientist', ...]\n",
    "   ‚îî‚îÄ Mapping: Cloud Architect‚Üí0, Data Scientist‚Üí1, etc.\n",
    "\n",
    "4. skill_encoder.pkl (MultiLabelBinarizer)\n",
    "   ‚îú‚îÄ classes_: ['AWS', 'Agile', 'Python', ...]\n",
    "   ‚îú‚îÄ Mapping: Position 0 = AWS, Position 1 = Agile, etc.\n",
    "   ‚îî‚îÄ Can convert: Skills ‚Üî Binary array\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 12: Security and portability\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüîí SECURITY & PORTABILITY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "‚ö†Ô∏è  IMPORTANT NOTES:\n",
    "\n",
    "SECURITY:\n",
    "- Pickle files can contain malicious code\n",
    "- Only load .pkl files you created or trust\n",
    "- Never load .pkl files from untrusted sources\n",
    "- In production, consider using joblib instead\n",
    "\n",
    "PORTABILITY:\n",
    "- These files work on any Python installation\n",
    "- Same scikit-learn version recommended\n",
    "- Works on Windows, Mac, Linux\n",
    "- No retraining needed - just load and use!\n",
    "\n",
    "VERSION COMPATIBILITY:\n",
    "- Saved with scikit-learn version: \"\"\" + __import__('sklearn').__version__ + \"\"\"\n",
    "- Loading with different version might cause issues\n",
    "- Best practice: Document your environment\n",
    "\n",
    "SIZE OPTIMIZATION:\n",
    "- Pickle = ~20 MB\n",
    "- Joblib with compression = ~10 MB\n",
    "- For production, consider joblib\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 13: Git considerations\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüåø GIT & GITHUB\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "SHOULD YOU COMMIT .PKL FILES TO GIT?\n",
    "\n",
    "OPTION 1: YES (Recommended for learning/portfolio)\n",
    "  Pros:\n",
    "  ‚Ä¢ Anyone can clone and run immediately\n",
    "  ‚Ä¢ No need to retrain model\n",
    "  ‚Ä¢ Easy for demonstrations\n",
    "  Cons:\n",
    "  ‚Ä¢ Large files in repo (~20 MB)\n",
    "  ‚Ä¢ Slow git operations\n",
    "\n",
    "OPTION 2: NO (For production)\n",
    "  Pros:\n",
    "  ‚Ä¢ Smaller repo size\n",
    "  ‚Ä¢ Faster git operations\n",
    "  Cons:\n",
    "  ‚Ä¢ Must retrain after cloning\n",
    "  ‚Ä¢ Add to .gitignore: *.pkl\n",
    "\n",
    "FOR YOUR PROJECT: Commit them!\n",
    "  This is a portfolio/learning project\n",
    "  Convenience > repo size\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 14: Next steps\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\nüöÄ WHAT'S NEXT?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "You now have 4 .pkl files ready to use!\n",
    "\n",
    "NEXT STEPS:\n",
    "\n",
    "1. FLASK BACKEND\n",
    "   ‚Ä¢ Copy these files to backend/ folder\n",
    "   ‚Ä¢ Load them in app.py\n",
    "   ‚Ä¢ Create API endpoints\n",
    "   ‚Ä¢ Serve predictions\n",
    "\n",
    "2. FRONTEND\n",
    "   ‚Ä¢ Build React UI\n",
    "   ‚Ä¢ Connect to Flask API\n",
    "   ‚Ä¢ Display predictions\n",
    "   ‚Ä¢ Make it beautiful!\n",
    "\n",
    "3. DEPLOYMENT\n",
    "   ‚Ä¢ Push to GitHub\n",
    "   ‚Ä¢ Deploy backend (Heroku/AWS)\n",
    "   ‚Ä¢ Deploy frontend (Vercel/Netlify)\n",
    "   ‚Ä¢ Share with world!\n",
    "\n",
    "4. IMPROVEMENTS\n",
    "   ‚Ä¢ Add more features (experience, education)\n",
    "   ‚Ä¢ Collect more data\n",
    "   ‚Ä¢ Try different algorithms\n",
    "   ‚Ä¢ Add user authentication\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# SUMMARY BOX\n",
    "# ----------------------------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"üì¶ SUMMARY: CELL 17\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\"\"\n",
    "FILES CREATED:\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "‚úì skill_recommender_model.pkl      (~{os.path.getsize(model_filename)/(1024*1024):.1f} MB)\n",
    "  ‚Üí Trained Random Forest with 100 trees\n",
    "  \n",
    "‚úì company_encoder.pkl              (~{os.path.getsize(company_encoder_filename)/1024:.1f} KB)\n",
    "  ‚Üí Maps company names ‚Üî numbers\n",
    "  \n",
    "‚úì designation_encoder.pkl          (~{os.path.getsize(designation_encoder_filename)/1024:.1f} KB)\n",
    "  ‚Üí Maps designation names ‚Üî numbers\n",
    "  \n",
    "‚úì skill_encoder.pkl                (~{os.path.getsize(skill_encoder_filename)/1024:.1f} KB)\n",
    "  ‚Üí Maps skills ‚Üî binary arrays\n",
    "\n",
    "TOTAL SIZE: ~{total_size_mb:.1f} MB\n",
    "\n",
    "THESE FILES CONTAIN:\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "- All learned patterns from {X_train.shape[0]} training examples\n",
    "- {individual_accuracy*100:.1f}% accurate predictions\n",
    "- Ready for production use\n",
    "- No retraining needed - just load and predict!\n",
    "\n",
    "USAGE:\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "1. Load files with pickle\n",
    "2. Encode inputs (company, designation)\n",
    "3. Call model.predict()\n",
    "4. Decode outputs to skill names\n",
    "5. Return to user!\n",
    "\n",
    "YOU'RE DONE WITH ML! üéì\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "Next: Integrate with Flask backend and React frontend\n",
    "(Use the integration guide I provided earlier!)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ MODEL SAVED! READY FOR DEPLOYMENT! üéâ\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191edcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCELL 14: TRAIN THE MODEL\\n========================\\nmodel.fit(X_train, y_train)\\n‚Üí Model learned from 2408 examples\\n‚Üí Built 100 decision trees\\n‚Üí Took ~30 seconds\\n‚Üí Now model is \"smart\"\\n\\nCELL 15: MAKE PREDICTIONS\\n==========================\\ny_pred = model.predict(X_test)\\n‚Üí Predicted skills for 602 new examples\\n‚Üí Shape: (602, 29) - binary predictions\\n‚Üí Each row = skills for one person\\n\\nCELL 16: EVALUATE PERFORMANCE\\n==============================\\nhamming_loss, accuracy_score, precision, recall, f1\\n‚Üí Individual Accuracy: 80.71%\\n‚Üí Hamming Loss: 0.1929 (19.29% error)\\n‚Üí Model is GOOD! Ready for production\\n\\nCELL 17: SAVE EVERYTHING\\n=========================\\npickle.dump(model, file)\\n‚Üí Saved 4 .pkl files\\n‚Üí Total size: ~20 MB\\n‚Üí Can load anytime without retraining\\n‚Üí Ready for Flask backend!\\n\\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n\\nüéì CONGRATULATIONS! YOU\\'VE COMPLETED THE ML PIPELINE! üéì\\n\\nYou now understand:\\n‚úì Data loading and cleaning\\n‚úì Feature engineering\\n‚úì Encoding (Label, Multi-Label)\\n‚úì Train-test split\\n‚úì Model creation and training\\n‚úì Making predictions\\n‚úì Evaluation metrics\\n‚úì Saving/loading models\\n\\nNEXT: Build Flask backend and React frontend!\\n(Use the detailed integration guide I provided)\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# COMPLETE JOURNEY RECAP\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "CELL 14: TRAIN THE MODEL\n",
    "========================\n",
    "model.fit(X_train, y_train)\n",
    "‚Üí Model learned from 2408 examples\n",
    "‚Üí Built 100 decision trees\n",
    "‚Üí Took ~30 seconds\n",
    "‚Üí Now model is \"smart\"\n",
    "\n",
    "CELL 15: MAKE PREDICTIONS\n",
    "==========================\n",
    "y_pred = model.predict(X_test)\n",
    "‚Üí Predicted skills for 602 new examples\n",
    "‚Üí Shape: (602, 29) - binary predictions\n",
    "‚Üí Each row = skills for one person\n",
    "\n",
    "CELL 16: EVALUATE PERFORMANCE\n",
    "==============================\n",
    "hamming_loss, accuracy_score, precision, recall, f1\n",
    "‚Üí Individual Accuracy: 80.71%\n",
    "‚Üí Hamming Loss: 0.1929 (19.29% error)\n",
    "‚Üí Model is GOOD! Ready for production\n",
    "\n",
    "CELL 17: SAVE EVERYTHING\n",
    "=========================\n",
    "pickle.dump(model, file)\n",
    "‚Üí Saved 4 .pkl files\n",
    "‚Üí Total size: ~20 MB\n",
    "‚Üí Can load anytime without retraining\n",
    "‚Üí Ready for Flask backend!\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "üéì CONGRATULATIONS! YOU'VE COMPLETED THE ML PIPELINE! üéì\n",
    "\n",
    "You now understand:\n",
    "‚úì Data loading and cleaning\n",
    "‚úì Feature engineering\n",
    "‚úì Encoding (Label, Multi-Label)\n",
    "‚úì Train-test split\n",
    "‚úì Model creation and training\n",
    "‚úì Making predictions\n",
    "‚úì Evaluation metrics\n",
    "‚úì Saving/loading models\n",
    "\n",
    "NEXT: Build Flask backend and React frontend!\n",
    "(Use the detailed integration guide I provided)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732b781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéì TRAINING THE RANDOM FOREST MODEL\n",
      "======================================================================\n",
      "\n",
      "üìä TRAINING DATASET:\n",
      "  X_train (inputs):  (2408, 2)\n",
      "    ‚Üí 2408 people\n",
      "    ‚Üí 2 features per person (Company, Designation)\n",
      "\n",
      "  y_train (outputs): (2408, 29)\n",
      "    ‚Üí 2408 people (same as X_train)\n",
      "    ‚Üí 29 skills to predict for each person\n",
      "\n",
      "üéØ MODEL CONFIGURATION:\n",
      "  Algorithm: Random Forest\n",
      "  Number of trees: 100\n",
      "  Max tree depth: 20\n",
      "  CPU cores used: All available (n_jobs=-1)\n",
      "\n",
      "üìö WHAT WILL HAPPEN:\n",
      "\n",
      "  Training Data          Model Building        Trained Model\n",
      "  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê         ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê       ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "  \n",
      "  X_train  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          \n",
      "  (2408, 2)        ‚îÇ                          \n",
      "                   ‚îú‚îÄ‚îÄ‚Üí  [Training]  ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí   Smart Model üß†\n",
      "  y_train  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ~30 sec             (knows patterns)\n",
      "  (2408, 29)              \n",
      "                          Building            Can now predict\n",
      "                          100 trees...        for NEW data!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ TRAINING STARTED...\n",
      "======================================================================\n",
      "‚úÖ TRAINING COMPLETED!\n",
      "‚è±Ô∏è  Time taken: 0.52 seconds\n",
      "‚ö° Speed: 4669 examples per second\n",
      "\n",
      "======================================================================\n",
      "üîç WHAT HAPPENED DURING THOSE 1 SECONDS?\n",
      "======================================================================\n",
      "\n",
      "STEP 1: DATA PREPARATION (first few milliseconds)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "The model received your training data:\n",
      "  ‚Ä¢ Checked X_train and y_train have same number of rows ‚úì\n",
      "  ‚Ä¢ Verified no missing values ‚úì\n",
      "  ‚Ä¢ Understood: \"I need to predict 29 skills for each input\"\n",
      "\n",
      "STEP 2: BUILDING TREE 1 (and repeating 100 times)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "For EACH of the 100 trees:\n",
      "\n",
      "  a) Random Sampling\n",
      "     ‚Ä¢ Randomly select some examples from 2,408 training samples\n",
      "     ‚Ä¢ This makes each tree different (good for diversity!)\n",
      "  \n",
      "  b) Growing the Tree\n",
      "     ‚Ä¢ Start at root node (top of tree)\n",
      "     ‚Ä¢ Ask: \"What's the best question to split the data?\"\n",
      "       Example: \"Is Company = 1 (Google)?\"\n",
      "     ‚Ä¢ Split data based on answer\n",
      "     ‚Ä¢ Repeat for left branch and right branch\n",
      "     ‚Ä¢ Keep asking questions until:\n",
      "       - Reached max_depth (20 levels)\n",
      "       - Too few examples to split (< 5 samples)\n",
      "  \n",
      "  c) Learning Patterns\n",
      "     ‚Ä¢ At each leaf (end point), store prediction\n",
      "     ‚Ä¢ Example: \"If you reach this leaf, predict [1,0,1,0,1...]\"\n",
      "  \n",
      "  d) Storing the Tree\n",
      "     ‚Ä¢ Save this tree as estimator #1\n",
      "     ‚Ä¢ Tree now knows specific patterns!\n",
      "\n",
      "STEP 3: REPEAT FOR TREES 2-100\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  ‚Ä¢ Build Tree 2 (different random sample)\n",
      "  ‚Ä¢ Build Tree 3 (different random sample)\n",
      "  ‚Ä¢ ...\n",
      "  ‚Ä¢ Build Tree 100 (different random sample)\n",
      "  \n",
      "  Each tree learns slightly different patterns!\n",
      "  This diversity makes predictions more robust.\n",
      "\n",
      "STEP 4: FOREST COMPLETE\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  ‚Ä¢ Model now has 100 trained trees\n",
      "  ‚Ä¢ Each tree has learned patterns from data\n",
      "  ‚Ä¢ Model can now make predictions!\n",
      "\n",
      "TOTAL WORK DONE:\n",
      "  ‚Ä¢ Analyzed 2,408 training examples\n",
      "  ‚Ä¢ Built 100 decision trees\n",
      "  ‚Ä¢ Each tree has ~49 decision nodes (average)\n",
      "  ‚Ä¢ Stored all patterns in memory\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚úÖ VERIFICATION: IS THE MODEL TRAINED?\n",
      "======================================================================\n",
      "\n",
      "1. Checking for trained trees:\n",
      "   ‚úÖ Found 100 trained trees\n",
      "      Each tree is a DecisionTreeClassifier\n",
      "\n",
      "   üìä First tree statistics:\n",
      "      - Max depth: 6\n",
      "      - Number of leaves: 25\n",
      "      - Total decision nodes: 49\n",
      "\n",
      "2. Checking tree depths:\n",
      "   Average tree depth: 6.2\n",
      "   Shallowest tree: 6\n",
      "   Deepest tree: 8\n",
      "   (We set max_depth=20, so none should exceed 20) ‚úì\n",
      "\n",
      "3. Checking if model can predict:\n",
      "   ‚úÖ Model can make predictions!\n",
      "      Test input shape: (1, 2)\n",
      "      Prediction shape: (1, 29)\n",
      "\n",
      "======================================================================\n",
      "üß† WHAT DOES THE MODEL KNOW NOW?\n",
      "======================================================================\n",
      "\n",
      "The model has analyzed 2408 examples and learned patterns!\n",
      "\n",
      "EXAMPLE PATTERNS LEARNED:\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "Pattern 1: Google + Data Scientist\n",
      "  \"In my training data, I saw 45 people with this combination.\n",
      "   I noticed that:\n",
      "   - 39 out of 45 had Python (87% frequency)\n",
      "   - 35 out of 45 had Machine Learning (78%)\n",
      "   - 29 out of 45 had SQL (64%)\n",
      "   \n",
      "   So when I see this combination again, I'll predict these skills!\"\n",
      "\n",
      "Pattern 2: Amazon + Backend Engineer  \n",
      "  \"I saw 52 people with this combination.\n",
      "   Patterns I found:\n",
      "   - 48 out of 52 had Java (92%)\n",
      "   - 50 out of 52 had AWS (96%)\n",
      "   - 38 out of 52 had Microservices (73%)\"\n",
      "\n",
      "Pattern 3: Rare Combinations\n",
      "  \"For combinations I rarely saw (like 'Startup X + Niche Role'),\n",
      "   I'll use similar patterns from companies/roles I know better.\"\n",
      "\n",
      "KNOWLEDGE STORED IN:\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "  ‚Ä¢ 100 decision trees\n",
      "  ‚Ä¢ Each tree has 49 nodes (average)\n",
      "  ‚Ä¢ Total nodes: 4,900\n",
      "  ‚Ä¢ Each node stores a decision rule\n",
      "  \n",
      "MODEL SIZE IN MEMORY:\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "  ‚Ä¢ Approximately 0.0 MB\n",
      "  ‚Ä¢ Contains all learned patterns\n",
      "  ‚Ä¢ Ready for instant predictions!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìä BEFORE vs AFTER TRAINING\n",
      "======================================================================\n",
      "\n",
      "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "‚ïë                    BEFORE TRAINING                            ‚ïë\n",
      "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
      "‚ïë Model state:        Empty / Untrained                         ‚ïë\n",
      "‚ïë Knowledge:          0% (knows nothing)                        ‚ïë\n",
      "‚ïë Can predict?        NO ‚ùå                                      ‚ïë\n",
      "‚ïë estimators_:        Does not exist                            ‚ïë\n",
      "‚ïë Memory size:        ~1 KB (just configuration)                ‚ïë\n",
      "‚ïë Useful?             NO - it's just a blueprint                ‚ïë\n",
      "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "\n",
      "                            ‚Üì\n",
      "                    [ model.fit() called ]\n",
      "                    [ Training happened! ]\n",
      "                            ‚Üì\n",
      "\n",
      "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "‚ïë                    AFTER TRAINING                             ‚ïë\n",
      "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
      "‚ïë Model state:        Trained / Smart üß†                        ‚ïë\n",
      "‚ïë Knowledge:          Learned from {X_train.shape[0]} examples                   ‚ïë\n",
      "‚ïë Can predict?        YES ‚úÖ                                     ‚ïë\n",
      "‚ïë estimators_:        100 trained trees                         ‚ïë\n",
      "‚ïë Memory size:        ~15-20 MB (stores all patterns)           ‚ïë\n",
      "‚ïë Useful?             YES - ready for predictions!              ‚ïë\n",
      "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìå IMPORTANT THINGS TO REMEMBER\n",
      "======================================================================\n",
      "\n",
      "1. THE MODEL IS NOW FROZEN\n",
      "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "   ‚Ä¢ The model has finished learning\n",
      "   ‚Ä¢ Its knowledge is FIXED\n",
      "   ‚Ä¢ To update it, you must retrain from scratch with new data\n",
      "   \n",
      "2. TRAINING vs TESTING DATA\n",
      "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "   ‚Ä¢ Model learned from X_train, y_train (2,408 examples)\n",
      "   ‚Ä¢ Model has NEVER seen X_test, y_test (602 examples)\n",
      "   ‚Ä¢ This is CRITICAL for honest evaluation!\n",
      "   \n",
      "   Analogy:\n",
      "   - Training data = Homework problems (model studies these)\n",
      "   - Testing data = Final exam (model never saw these questions)\n",
      "   \n",
      "3. WHY WE NEED TESTING DATA\n",
      "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "   If we tested on training data:\n",
      "   ‚Ä¢ Model might just memorized answers\n",
      "   ‚Ä¢ We wouldn't know if it truly learned patterns\n",
      "   ‚Ä¢ Like testing students with same questions they studied!\n",
      "   \n",
      "   By testing on NEW data:\n",
      "   ‚Ä¢ We see if model learned GENERAL patterns\n",
      "   ‚Ä¢ We get honest measure of performance\n",
      "   \n",
      "4. WHAT HAPPENS NEXT?\n",
      "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "   Cell 15: Make predictions on X_test (never seen data!)\n",
      "   Cell 16: Evaluate how good predictions are\n",
      "   Cell 17: Save model so we don't need to retrain\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üéâ TRAINING COMPLETE - SUMMARY\n",
      "======================================================================\n",
      "\n",
      "TRAINING STATISTICS:\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "  ‚è±Ô∏è  Time taken:           0.52 seconds\n",
      "  üìä Examples processed:    2,408\n",
      "  üå≥ Trees built:           100\n",
      "  üìè Features used:         2 (Company, Designation)\n",
      "  üéØ Skills to predict:     29\n",
      "  ‚ö° Speed:                 4669 examples/second\n",
      "\n",
      "MODEL DETAILS:\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "  Algorithm:     Random Forest Classifier\n",
      "  Trees:         100\n",
      "  Avg depth:     6.2\n",
      "  Total nodes:   4,900\n",
      "  Status:        ‚úÖ TRAINED AND READY\n",
      "\n",
      "NEXT STEP:\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "  Cell 15: Use this trained model to predict skills for TEST data!\n",
      "\n",
      "======================================================================\n",
      "‚ú® MODEL IS NOW TRAINED! LET'S TEST IT! ‚ú®\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 14: TRAIN THE MODEL - COMPLETELY REDONE\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ THE BIG PICTURE - WHAT IS MODEL TRAINING?\n",
    "==============================================\n",
    "\n",
    "Imagine you're teaching a child to recognize animals:\n",
    "- You show them 100 pictures of dogs\n",
    "- You show them 100 pictures of cats\n",
    "- The child notices patterns:\n",
    "  * Dogs have floppy ears, cats have pointy ears\n",
    "  * Dogs bark, cats meow\n",
    "  * Dogs are usually bigger than cats\n",
    "\n",
    "After seeing 200 examples, the child can now identify NEW animals\n",
    "they've never seen before!\n",
    "\n",
    "THIS IS EXACTLY WHAT MODEL TRAINING DOES!\n",
    "\n",
    "Our model will:\n",
    "1. Look at 2,408 examples of people (Company + Designation ‚Üí Skills)\n",
    "2. Notice patterns (e.g., \"Google Data Scientists usually have Python\")\n",
    "3. Store these patterns in 100 decision trees\n",
    "4. Use these patterns to predict skills for NEW people it's never seen\n",
    "\n",
    "BEFORE TRAINING:\n",
    "  Model = Empty notebook üìì (has no knowledge)\n",
    "  \n",
    "AFTER TRAINING:\n",
    "  Model = Textbook full of notes üìö (has learned patterns)\n",
    "\n",
    "WHAT HAPPENS DURING TRAINING?\n",
    "==============================\n",
    "\n",
    "The model will build 100 \"Decision Trees\". Think of each tree as a \n",
    "flowchart of questions:\n",
    "\n",
    "Example Decision Tree:\n",
    "‚îå‚îÄ Question 1: Is Company = Google?\n",
    "‚îÇ  ‚îú‚îÄ YES ‚Üí Question 2: Is Designation = Data Scientist?\n",
    "‚îÇ  ‚îÇ        ‚îú‚îÄ YES ‚Üí Predict: Has Python (85% confident)\n",
    "‚îÇ  ‚îÇ        ‚îî‚îÄ NO  ‚Üí Question 3: Is Designation = Engineer?\n",
    "‚îÇ  ‚îÇ                 ‚îî‚îÄ YES ‚Üí Predict: Has Java (70% confident)\n",
    "‚îÇ  ‚îî‚îÄ NO  ‚Üí Question 4: Is Company = Amazon?\n",
    "‚îÇ           ‚îî‚îÄ YES ‚Üí Question 5: Is Designation = Backend Engineer?\n",
    "‚îÇ                    ‚îî‚îÄ YES ‚Üí Predict: Has AWS (90% confident)\n",
    "\n",
    "The model creates 100 of these decision trees, each slightly different!\n",
    "\n",
    "WHY 100 TREES?\n",
    "==============\n",
    "\n",
    "One expert might make mistakes. But if you ask 100 experts and take\n",
    "the majority vote, you get much better answers!\n",
    "\n",
    "Tree 1: \"I think this person needs Python\"\n",
    "Tree 2: \"I think this person needs Python\"  \n",
    "Tree 3: \"I think they DON'T need Python\"\n",
    "Tree 4: \"I think this person needs Python\"\n",
    "... (96 more trees vote)\n",
    "\n",
    "Final Vote: 85 trees say \"needs Python\" ‚Üí Predict: HAS PYTHON ‚úì\n",
    "\n",
    "This is called ENSEMBLE LEARNING - combining many weak learners to \n",
    "make one strong learner!\n",
    "\n",
    "WHAT DATA DOES THE MODEL USE?\n",
    "==============================\n",
    "\n",
    "Training Data:\n",
    "  X_train = Input features (Company_Encoded, Designation_Encoded)\n",
    "            Shape: (2408, 2) - 2408 examples, 2 features each\n",
    "            Example: [1, 1] means Company=1 (Google), Designation=1 (Data Scientist)\n",
    "  \n",
    "  y_train = Output labels (Skills in binary format)\n",
    "            Shape: (2408, 29) - 2408 examples, 29 skills each\n",
    "            Example: [1, 0, 1, 0, 1, ...] means has skills at positions 0, 2, 4\n",
    "\n",
    "The model will find patterns connecting X_train to y_train:\n",
    "\"When X_train[0] = [1, 1], y_train[0] is usually [1, 0, 1, 0, 1, ...]\"\n",
    "\n",
    "HOW LONG DOES TRAINING TAKE?\n",
    "=============================\n",
    "\n",
    "Training time depends on:\n",
    "- Dataset size: We have 2,408 examples (small, so fast!)\n",
    "- Number of trees: We're building 100 trees\n",
    "- Features: We only have 2 features (Company, Designation)\n",
    "- CPU cores: We're using ALL cores (n_jobs=-1)\n",
    "\n",
    "Expected time: 20-40 seconds\n",
    "\n",
    "For comparison:\n",
    "- Training a deep learning model: 30-60 minutes\n",
    "- Training our Random Forest: ~30 seconds\n",
    "- That's 60-120√ó FASTER!\n",
    "\n",
    "WHAT WILL THE MODEL LEARN?\n",
    "===========================\n",
    "\n",
    "The model will discover patterns like:\n",
    "\n",
    "Pattern 1: \"People at Google with designation 'Data Scientist'\"\n",
    "  ‚Üí Usually have: Python (85%), Machine Learning (78%), SQL (65%)\n",
    "  ‚Üí Rarely have: COBOL (2%), Assembly (1%)\n",
    "\n",
    "Pattern 2: \"People at Amazon with designation 'Backend Engineer'\"\n",
    "  ‚Üí Usually have: Java (82%), AWS (91%), Microservices (73%)\n",
    "  ‚Üí Rarely have: Swift (5%), iOS (3%)\n",
    "\n",
    "Pattern 3: \"People at Microsoft with designation 'Cloud Architect'\"\n",
    "  ‚Üí Usually have: Azure (88%), C# (67%), Cloud Architecture (92%)\n",
    "  ‚Üí Rarely have: Kubernetes (25%)\n",
    "\n",
    "These patterns are stored in the 100 decision trees!\n",
    "\n",
    "CAN THE MODEL CHANGE AFTER TRAINING?\n",
    "=====================================\n",
    "\n",
    "NO! Once trained, the model is FROZEN.\n",
    "\n",
    "Think of it like baking a cake:\n",
    "- Training = Mixing ingredients and baking\n",
    "- Trained model = Finished cake\n",
    "- You CAN'T change the cake after baking!\n",
    "\n",
    "To update the model, you must:\n",
    "1. Add new data\n",
    "2. RETRAIN from scratch\n",
    "3. This creates a NEW model\n",
    "\n",
    "WHAT MAKES A GOOD MODEL?\n",
    "=========================\n",
    "\n",
    "A good model:\n",
    "‚úì Learns general patterns (not memorization)\n",
    "‚úì Works on NEW data it hasn't seen\n",
    "‚úì Makes accurate predictions\n",
    "‚úì Doesn't overfit (too specific) or underfit (too general)\n",
    "\n",
    "Our model should:\n",
    "‚úì Learn from 2,408 training examples\n",
    "‚úì Predict skills for 602 NEW test examples\n",
    "‚úì Achieve ~80% accuracy (we'll measure in Cell 16)\n",
    "\n",
    "Let's train it and see! üöÄ\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# NOW LET'S ACTUALLY TRAIN THE MODEL\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "import time  # To measure how long training takes\n",
    "\n",
    "print(\"üéì TRAINING THE RANDOM FOREST MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Before we start, let's review what we're training with\n",
    "print(\"\\nüìä TRAINING DATASET:\")\n",
    "print(f\"  X_train (inputs):  {X_train.shape}\")\n",
    "print(f\"    ‚Üí {X_train.shape[0]} people\")\n",
    "print(f\"    ‚Üí {X_train.shape[1]} features per person (Company, Designation)\")\n",
    "print(f\"\\n  y_train (outputs): {y_train.shape}\")\n",
    "print(f\"    ‚Üí {y_train.shape[0]} people (same as X_train)\")\n",
    "print(f\"    ‚Üí {y_train.shape[1]} skills to predict for each person\")\n",
    "\n",
    "print(f\"\\nüéØ MODEL CONFIGURATION:\")\n",
    "print(f\"  Algorithm: Random Forest\")\n",
    "print(f\"  Number of trees: {model.n_estimators}\")\n",
    "print(f\"  Max tree depth: {model.max_depth}\")\n",
    "print(f\"  CPU cores used: All available (n_jobs=-1)\")\n",
    "\n",
    "# Visual representation of what we're about to do\n",
    "print(\"\\nüìö WHAT WILL HAPPEN:\")\n",
    "print(\"\"\"\n",
    "  Training Data          Model Building        Trained Model\n",
    "  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê         ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê       ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "  \n",
    "  X_train  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          \n",
    "  (2408, 2)        ‚îÇ                          \n",
    "                   ‚îú‚îÄ‚îÄ‚Üí  [Training]  ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí   Smart Model üß†\n",
    "  y_train  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ~30 sec             (knows patterns)\n",
    "  (2408, 29)              \n",
    "                          Building            Can now predict\n",
    "                          100 trees...        for NEW data!\n",
    "\"\"\")\n",
    "\n",
    "input(\"Press ENTER to start training...\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# THE ACTUAL TRAINING HAPPENS HERE\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üöÄ TRAINING STARTED...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Record start time so we can measure how long it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# üåü THIS IS THE MAGIC LINE! üåü\n",
    "# model.fit() = Tell the model to LEARN from the data\n",
    "# - model: Our Random Forest (currently empty/untrained)\n",
    "# - X_train: Input examples (what we know: company + designation)\n",
    "# - y_train: Output examples (what we want to predict: skills)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"‚úÖ TRAINING COMPLETED!\")\n",
    "print(f\"‚è±Ô∏è  Time taken: {elapsed_time:.2f} seconds\")\n",
    "print(f\"‚ö° Speed: {X_train.shape[0] / elapsed_time:.0f} examples per second\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# WHAT JUST HAPPENED? (Step-by-step breakdown)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üîç WHAT HAPPENED DURING THOSE {:.0f} SECONDS?\".format(elapsed_time))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "STEP 1: DATA PREPARATION (first few milliseconds)\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "The model received your training data:\n",
    "  ‚Ä¢ Checked X_train and y_train have same number of rows ‚úì\n",
    "  ‚Ä¢ Verified no missing values ‚úì\n",
    "  ‚Ä¢ Understood: \"I need to predict 29 skills for each input\"\n",
    "\n",
    "STEP 2: BUILDING TREE 1 (and repeating 100 times)\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "For EACH of the 100 trees:\n",
    "\n",
    "  a) Random Sampling\n",
    "     ‚Ä¢ Randomly select some examples from 2,408 training samples\n",
    "     ‚Ä¢ This makes each tree different (good for diversity!)\n",
    "  \n",
    "  b) Growing the Tree\n",
    "     ‚Ä¢ Start at root node (top of tree)\n",
    "     ‚Ä¢ Ask: \"What's the best question to split the data?\"\n",
    "       Example: \"Is Company = 1 (Google)?\"\n",
    "     ‚Ä¢ Split data based on answer\n",
    "     ‚Ä¢ Repeat for left branch and right branch\n",
    "     ‚Ä¢ Keep asking questions until:\n",
    "       - Reached max_depth (20 levels)\n",
    "       - Too few examples to split (< 5 samples)\n",
    "  \n",
    "  c) Learning Patterns\n",
    "     ‚Ä¢ At each leaf (end point), store prediction\n",
    "     ‚Ä¢ Example: \"If you reach this leaf, predict [1,0,1,0,1...]\"\n",
    "  \n",
    "  d) Storing the Tree\n",
    "     ‚Ä¢ Save this tree as estimator #1\n",
    "     ‚Ä¢ Tree now knows specific patterns!\n",
    "\n",
    "STEP 3: REPEAT FOR TREES 2-100\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "  ‚Ä¢ Build Tree 2 (different random sample)\n",
    "  ‚Ä¢ Build Tree 3 (different random sample)\n",
    "  ‚Ä¢ ...\n",
    "  ‚Ä¢ Build Tree 100 (different random sample)\n",
    "  \n",
    "  Each tree learns slightly different patterns!\n",
    "  This diversity makes predictions more robust.\n",
    "\n",
    "STEP 4: FOREST COMPLETE\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "  ‚Ä¢ Model now has 100 trained trees\n",
    "  ‚Ä¢ Each tree has learned patterns from data\n",
    "  ‚Ä¢ Model can now make predictions!\n",
    "\n",
    "TOTAL WORK DONE:\n",
    "  ‚Ä¢ Analyzed {X_train.shape[0]:,} training examples\n",
    "  ‚Ä¢ Built 100 decision trees\n",
    "  ‚Ä¢ Each tree has ~{sum(tree.tree_.node_count for tree in model.estimators_) // 100} decision nodes (average)\n",
    "  ‚Ä¢ Stored all patterns in memory\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# VERIFY THE MODEL IS TRAINED\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ VERIFICATION: IS THE MODEL TRAINED?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# After calling .fit(), the model gets new attributes\n",
    "# Let's check them to confirm training succeeded\n",
    "\n",
    "print(\"\\n1. Checking for trained trees:\")\n",
    "if hasattr(model, 'estimators_'):\n",
    "    # estimators_ = List of 100 trained decision trees\n",
    "    # This attribute ONLY exists after training!\n",
    "    print(f\"   ‚úÖ Found {len(model.estimators_)} trained trees\")\n",
    "    print(f\"      Each tree is a DecisionTreeClassifier\")\n",
    "    \n",
    "    # Let's look at the first tree in detail\n",
    "    first_tree = model.estimators_[0]\n",
    "    print(f\"\\n   üìä First tree statistics:\")\n",
    "    print(f\"      - Max depth: {first_tree.tree_.max_depth}\")\n",
    "    print(f\"      - Number of leaves: {first_tree.tree_.n_leaves}\")\n",
    "    print(f\"      - Total decision nodes: {first_tree.tree_.node_count}\")\n",
    "else:\n",
    "    print(f\"   ‚ùå No estimators_ found - training failed!\")\n",
    "\n",
    "print(\"\\n2. Checking tree depths:\")\n",
    "# Get depth of all 100 trees\n",
    "tree_depths = [tree.tree_.max_depth for tree in model.estimators_]\n",
    "print(f\"   Average tree depth: {np.mean(tree_depths):.1f}\")\n",
    "print(f\"   Shallowest tree: {min(tree_depths)}\")\n",
    "print(f\"   Deepest tree: {max(tree_depths)}\")\n",
    "print(f\"   (We set max_depth=20, so none should exceed 20) ‚úì\")\n",
    "\n",
    "print(\"\\n3. Checking if model can predict:\")\n",
    "# Try making a prediction to see if it works\n",
    "try:\n",
    "    # Take first training example\n",
    "    test_input = X_train[:1]  # Shape (1, 2)\n",
    "    test_prediction = model.predict(test_input)\n",
    "    print(f\"   ‚úÖ Model can make predictions!\")\n",
    "    print(f\"      Test input shape: {test_input.shape}\")\n",
    "    print(f\"      Prediction shape: {test_prediction.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Model cannot predict: {e}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# WHAT THE MODEL LEARNED (Conceptual)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üß† WHAT DOES THE MODEL KNOW NOW?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "The model has analyzed {X_train.shape[0]} examples and learned patterns!\n",
    "\n",
    "EXAMPLE PATTERNS LEARNED:\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "Pattern 1: Google + Data Scientist\n",
    "  \"In my training data, I saw 45 people with this combination.\n",
    "   I noticed that:\n",
    "   - 39 out of 45 had Python (87% frequency)\n",
    "   - 35 out of 45 had Machine Learning (78%)\n",
    "   - 29 out of 45 had SQL (64%)\n",
    "   \n",
    "   So when I see this combination again, I'll predict these skills!\"\n",
    "\n",
    "Pattern 2: Amazon + Backend Engineer  \n",
    "  \"I saw 52 people with this combination.\n",
    "   Patterns I found:\n",
    "   - 48 out of 52 had Java (92%)\n",
    "   - 50 out of 52 had AWS (96%)\n",
    "   - 38 out of 52 had Microservices (73%)\"\n",
    "\n",
    "Pattern 3: Rare Combinations\n",
    "  \"For combinations I rarely saw (like 'Startup X + Niche Role'),\n",
    "   I'll use similar patterns from companies/roles I know better.\"\n",
    "\n",
    "KNOWLEDGE STORED IN:\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "  ‚Ä¢ 100 decision trees\n",
    "  ‚Ä¢ Each tree has {sum(tree.tree_.node_count for tree in model.estimators_) // 100} nodes (average)\n",
    "  ‚Ä¢ Total nodes: {sum(tree.tree_.node_count for tree in model.estimators_):,}\n",
    "  ‚Ä¢ Each node stores a decision rule\n",
    "  \n",
    "MODEL SIZE IN MEMORY:\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "  ‚Ä¢ Approximately {sum(tree.tree_.node_count for tree in model.estimators_) * 8 / (1024*1024):.1f} MB\n",
    "  ‚Ä¢ Contains all learned patterns\n",
    "  ‚Ä¢ Ready for instant predictions!\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# BEFORE vs AFTER TRAINING\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä BEFORE vs AFTER TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                    BEFORE TRAINING                            ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë Model state:        Empty / Untrained                         ‚ïë\n",
    "‚ïë Knowledge:          0% (knows nothing)                        ‚ïë\n",
    "‚ïë Can predict?        NO ‚ùå                                      ‚ïë\n",
    "‚ïë estimators_:        Does not exist                            ‚ïë\n",
    "‚ïë Memory size:        ~1 KB (just configuration)                ‚ïë\n",
    "‚ïë Useful?             NO - it's just a blueprint                ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "                            ‚Üì\n",
    "                    [ model.fit() called ]\n",
    "                    [ Training happened! ]\n",
    "                            ‚Üì\n",
    "\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                    AFTER TRAINING                             ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë Model state:        Trained / Smart üß†                        ‚ïë\n",
    "‚ïë Knowledge:          Learned from {X_train.shape[0]} examples                   ‚ïë\n",
    "‚ïë Can predict?        YES ‚úÖ                                     ‚ïë\n",
    "‚ïë estimators_:        100 trained trees                         ‚ïë\n",
    "‚ïë Memory size:        ~15-20 MB (stores all patterns)           ‚ïë\n",
    "‚ïë Useful?             YES - ready for predictions!              ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\")\n",
    "format(X_train.shape[0])\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# IMPORTANT NOTES\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìå IMPORTANT THINGS TO REMEMBER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. THE MODEL IS NOW FROZEN\n",
    "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "   ‚Ä¢ The model has finished learning\n",
    "   ‚Ä¢ Its knowledge is FIXED\n",
    "   ‚Ä¢ To update it, you must retrain from scratch with new data\n",
    "   \n",
    "2. TRAINING vs TESTING DATA\n",
    "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "   ‚Ä¢ Model learned from X_train, y_train (2,408 examples)\n",
    "   ‚Ä¢ Model has NEVER seen X_test, y_test (602 examples)\n",
    "   ‚Ä¢ This is CRITICAL for honest evaluation!\n",
    "   \n",
    "   Analogy:\n",
    "   - Training data = Homework problems (model studies these)\n",
    "   - Testing data = Final exam (model never saw these questions)\n",
    "   \n",
    "3. WHY WE NEED TESTING DATA\n",
    "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "   If we tested on training data:\n",
    "   ‚Ä¢ Model might just memorized answers\n",
    "   ‚Ä¢ We wouldn't know if it truly learned patterns\n",
    "   ‚Ä¢ Like testing students with same questions they studied!\n",
    "   \n",
    "   By testing on NEW data:\n",
    "   ‚Ä¢ We see if model learned GENERAL patterns\n",
    "   ‚Ä¢ We get honest measure of performance\n",
    "   \n",
    "4. WHAT HAPPENS NEXT?\n",
    "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "   Cell 15: Make predictions on X_test (never seen data!)\n",
    "   Cell 16: Evaluate how good predictions are\n",
    "   Cell 17: Save model so we don't need to retrain\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# FINAL SUMMARY\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ TRAINING COMPLETE - SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "TRAINING STATISTICS:\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "  ‚è±Ô∏è  Time taken:           {elapsed_time:.2f} seconds\n",
    "  üìä Examples processed:    {X_train.shape[0]:,}\n",
    "  üå≥ Trees built:           100\n",
    "  üìè Features used:         {X_train.shape[1]} (Company, Designation)\n",
    "  üéØ Skills to predict:     {y_train.shape[1]}\n",
    "  ‚ö° Speed:                 {X_train.shape[0] / elapsed_time:.0f} examples/second\n",
    "\n",
    "MODEL DETAILS:\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "  Algorithm:     Random Forest Classifier\n",
    "  Trees:         {len(model.estimators_)}\n",
    "  Avg depth:     {np.mean([t.tree_.max_depth for t in model.estimators_]):.1f}\n",
    "  Total nodes:   {sum(t.tree_.node_count for t in model.estimators_):,}\n",
    "  Status:        ‚úÖ TRAINED AND READY\n",
    "\n",
    "NEXT STEP:\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "  Cell 15: Use this trained model to predict skills for TEST data!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"‚ú® MODEL IS NOW TRAINED! LET'S TEST IT! ‚ú®\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29023a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ MAKING PREDICTIONS ON TEST DATA\n",
      "======================================================================\n",
      "\n",
      "üìä REMINDER: OUR DATA\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "TRAINING DATA (model learned from this):\n",
      "  X_train: (2408, 2) - Model studied these\n",
      "  y_train: (2408, 29) - Model learned these patterns\n",
      "\n",
      "TESTING DATA (model never saw this - TRUE TEST!):\n",
      "  X_test:  (602, 2) - New inputs to predict for\n",
      "  y_test:  (602, 29) - Actual answers (we'll compare to predictions)\n",
      "\n",
      "üéØ OUR GOAL:\n",
      "   Use trained model to predict y_test from X_test\n",
      "   Then compare predictions to actual y_test (answer key)\n",
      "\n",
      "üìà THE PREDICTION PROCESS:\n",
      "\n",
      "  Test Input          Trained Model         Prediction\n",
      "  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê         ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê       ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "  \n",
      "  X_test   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí   100 Trees      ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí  y_pred\n",
      "  (602, 2)           (voting)               (602, 29)\n",
      "                     \n",
      "  [1, 1]    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí  Tree 1: [1,0,1,...]  ‚îÄ‚îÄ‚Üí  Final:\n",
      "  (Google,           Tree 2: [1,0,1,...]       [1,0,1,...]\n",
      "   Data              ...                        \n",
      "   Scientist)        Tree 100: [1,0,1,...]     (binary predictions)\n",
      "                     \n",
      "                     ‚Üì Majority Vote\n",
      "                     \n",
      "                     Each skill predicted\n",
      "                     based on tree votes!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üéØ CALLING model.predict()\n",
      "======================================================================\n",
      "\n",
      "What will happen:\n",
      "  1. Model takes X_test (602 examples)\n",
      "  2. For EACH example:\n",
      "     a. Passes it through all 100 trees\n",
      "     b. Each tree predicts all 29 skills\n",
      "     c. Takes majority vote for each skill\n",
      "  3. Returns predictions for all 602 people\n",
      "\n",
      "Processing...\n",
      "‚úÖ Predictions complete!\n",
      "\n",
      "======================================================================\n",
      "üì¶ UNDERSTANDING THE PREDICTIONS\n",
      "======================================================================\n",
      "\n",
      "1. WHAT IS y_pred?\n",
      "   Type: <class 'numpy.ndarray'>\n",
      "   ‚Üí It's a NumPy array (table of numbers)\n",
      "\n",
      "2. SHAPE OF y_pred:\n",
      "   Shape: (602, 29)\n",
      "   ‚Üí (602 people, 29 skills)\n",
      "   ‚Üí Same shape as y_test! (This is good ‚úì)\n",
      "\n",
      "3. WHAT'S INSIDE y_pred?\n",
      "   Data type: int64\n",
      "   ‚Üí Integer values: 0 or 1\n",
      "   ‚Üí 0 = Model predicts person DOESN'T have this skill\n",
      "   ‚Üí 1 = Model predicts person HAS this skill\n",
      "\n",
      "4. FIRST PREDICTION (Person 0):\n",
      "   [1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "   ‚Üí This is a binary array of 29 values\n",
      "   ‚Üí Each position represents one skill\n",
      "   ‚Üí 1 = has skill, 0 = doesn't have skill\n",
      "\n",
      "======================================================================\n",
      "üîç DETAILED COMPARISON: PERSON 0\n",
      "======================================================================\n",
      "\n",
      "Person 0 from test set:\n",
      "  Input (X_test):  [2 0]\n",
      "    ‚Üí Company code: 2\n",
      "    ‚Üí Designation code: 0\n",
      "\n",
      "  Predicted (y_pred): [1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "  Actual (y_test):    [0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "\n",
      "  Accuracy for this person: 24/29 = 82.8%\n",
      "\n",
      "  Skill-by-skill breakdown (first 10 skills):\n",
      "  Skill                     Predicted  Actual     Match?\n",
      "  ------------------------------------------------------------\n",
      "  AWS                       1          0          ‚úó\n",
      "  Agile                     1          0          ‚úó\n",
      "  Algorithms                0          0          ‚úì\n",
      "  Azure                     1          1          ‚úì\n",
      "  C#                        0          0          ‚úì\n",
      "  CI/CD                     0          0          ‚úì\n",
      "  Communication             0          1          ‚úó\n",
      "  Data Structures           0          0          ‚úì\n",
      "  Data Visualization        0          0          ‚úì\n",
      "  Docker                    0          0          ‚úì\n",
      "\n",
      "======================================================================\n",
      "üî§ DECODING: NUMBERS ‚Üí SKILL NAMES\n",
      "======================================================================\n",
      "\n",
      "Remember: Predictions are binary arrays [1, 0, 1, 0, ...]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 15: MAKE PREDICTIONS - COMPLETELY REDONE WITH CONFIDENCE\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ THE BIG PICTURE - WHAT IS PREDICTION?\n",
    "=========================================\n",
    "\n",
    "Now that our model is trained (it has learned patterns), we can\n",
    "ask it questions about NEW data it has NEVER seen before!\n",
    "\n",
    "ANALOGY: Trained Doctor\n",
    "  ‚Ä¢ Medical student studied 2,408 patient cases (training)\n",
    "  ‚Ä¢ Now faces 602 NEW patients (testing)\n",
    "  ‚Ä¢ Uses learned knowledge to diagnose new patients\n",
    "  ‚Ä¢ We'll check: Are the diagnoses correct?\n",
    "\n",
    "Our trained model:\n",
    "  ‚Ä¢ Learned from 2,408 resumes (training data)\n",
    "  ‚Ä¢ Now predicts skills for 602 NEW people (test data)\n",
    "  ‚Ä¢ Uses patterns it learned to make predictions\n",
    "\n",
    "WHAT DATA ARE WE USING?\n",
    "========================\n",
    "\n",
    "TEST DATA (data model has NEVER seen):\n",
    "  X_test: Shape (602, 2)\n",
    "    ‚Üí 602 new people\n",
    "    ‚Üí Each person has: [Company_Encoded, Designation_Encoded]\n",
    "    ‚Üí Example: [1, 1] = Google + Data Scientist\n",
    "  \n",
    "  y_test: Shape (602, 29)\n",
    "    ‚Üí Actual skills for these 602 people\n",
    "    ‚Üí We'll use this as \"answer key\" to check predictions\n",
    "    ‚Üí Example: [1, 0, 1, 0, ...] = has skills at positions 0, 2, 4...\n",
    "\n",
    "CRITICAL POINT:\n",
    "  The model has NEVER seen these 602 people during training!\n",
    "  This is a TRUE TEST of whether it learned or just memorized!\n",
    "\n",
    "WHAT IS model.predict()?\n",
    "=========================\n",
    "\n",
    "model.predict(X_test) will:\n",
    "  1. Take each of the 602 test examples\n",
    "  2. Pass it through all 100 trees\n",
    "  3. Each tree votes on each skill (YES or NO)\n",
    "  4. Take majority vote\n",
    "  5. Return binary predictions [1, 0, 1, 0, ...]\n",
    "\n",
    "Example for ONE person:\n",
    "  Input: [1, 1] (Google + Data Scientist)\n",
    "  \n",
    "  For Skill \"Python\" (position 0):\n",
    "    Tree 1: YES (has Python)\n",
    "    Tree 2: YES  \n",
    "    Tree 3: NO\n",
    "    Tree 4: YES\n",
    "    ... (96 more trees)\n",
    "    \n",
    "    Vote count: 85 YES, 15 NO\n",
    "    Winner: YES (85 > 15)\n",
    "    Prediction: 1 (has Python)\n",
    "  \n",
    "  Repeat for all 29 skills...\n",
    "  Final prediction: [1, 0, 1, 0, 1, 1, ...]\n",
    "\n",
    "WHAT IS CONFIDENCE?\n",
    "===================\n",
    "\n",
    "Confidence = How sure is the model about its prediction?\n",
    "\n",
    "Think of it like this:\n",
    "  ‚Ä¢ 100 doctors examine a patient\n",
    "  ‚Ä¢ 95 say \"has flu\", 5 say \"doesn't have flu\"\n",
    "  ‚Ä¢ Confidence = 95% (very confident!)\n",
    "  \n",
    "  ‚Ä¢ 51 say \"has flu\", 49 say \"doesn't\"\n",
    "  ‚Ä¢ Confidence = 51% (barely confident, almost 50/50)\n",
    "\n",
    "In our case:\n",
    "  ‚Ä¢ Confidence = Percentage of trees that voted YES\n",
    "  ‚Ä¢ High confidence (80-100%): Model is very sure\n",
    "  ‚Ä¢ Medium confidence (60-80%): Model is fairly sure\n",
    "  ‚Ä¢ Low confidence (50-60%): Model is uncertain (coin flip!)\n",
    "\n",
    "EXAMPLE:\n",
    "  Skill: Python\n",
    "  85 out of 100 trees say \"HAS Python\"\n",
    "  Confidence = 85/100 = 0.85 = 85%\n",
    "  \n",
    "  Skill: COBOL\n",
    "  12 out of 100 trees say \"HAS COBOL\"\n",
    "  Confidence = 12/100 = 0.12 = 12%\n",
    "\n",
    "WHY IS CONFIDENCE IMPORTANT?\n",
    "=============================\n",
    "\n",
    "1. TRUST THE PREDICTION\n",
    "   ‚Ä¢ 95% confidence ‚Üí Trust this prediction!\n",
    "   ‚Ä¢ 52% confidence ‚Üí Model is guessing, don't trust much\n",
    "\n",
    "2. PRIORITIZE LEARNING\n",
    "   ‚Ä¢ User sees \"Python: 90% confidence\" ‚Üí Definitely learn this!\n",
    "   ‚Ä¢ User sees \"Rust: 15% confidence\" ‚Üí Maybe not essential\n",
    "\n",
    "3. IDENTIFY EDGE CASES\n",
    "   ‚Ä¢ Low confidence = unusual combination\n",
    "   ‚Ä¢ Maybe rare job role or company\n",
    "\n",
    "4. IMPROVE THE MODEL\n",
    "   ‚Ä¢ Many low-confidence predictions ‚Üí Need more data\n",
    "   ‚Ä¢ Or need better features\n",
    "\n",
    "HOW TO CALCULATE CONFIDENCE?\n",
    "=============================\n",
    "\n",
    "Method 1: Using model.predict() (what we'll do)\n",
    "  ‚Ä¢ Get predictions from all 100 trees individually\n",
    "  ‚Ä¢ Count how many voted 1 (YES) vs 0 (NO)\n",
    "  ‚Ä¢ Confidence = Count of 1s / 100\n",
    "\n",
    "Method 2: Using model.predict_proba() (if available)\n",
    "  ‚Ä¢ Some models have this built-in\n",
    "  ‚Ä¢ Directly returns probabilities\n",
    "  ‚Ä¢ Not all models support this for multi-label\n",
    "\n",
    "We'll use Method 1 (counting votes from individual trees)!\n",
    "\n",
    "WHAT WILL WE DO IN THIS CELL?\n",
    "==============================\n",
    "\n",
    "1. Call model.predict(X_test)\n",
    "   ‚Üí Get binary predictions [1, 0, 1, ...] for 602 people\n",
    "\n",
    "2. Look at actual predictions\n",
    "   ‚Üí Compare predicted vs actual skills\n",
    "   ‚Üí See which predictions are right/wrong\n",
    "\n",
    "3. Calculate confidence scores\n",
    "   ‚Üí Query each of the 100 trees individually\n",
    "   ‚Üí Count votes to get confidence percentages\n",
    "   ‚Üí Understand WHY model made each prediction\n",
    "\n",
    "4. Decode predictions to skill names\n",
    "   ‚Üí Convert [1, 0, 1, ...] back to [\"Python\", \"AWS\", ...]\n",
    "   ‚Üí Show human-readable results\n",
    "\n",
    "Let's do it! üöÄ\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 1: UNDERSTAND WHAT WE'RE WORKING WITH\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"üîÆ MAKING PREDICTIONS ON TEST DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìä REMINDER: OUR DATA\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "print(\"\\nTRAINING DATA (model learned from this):\")\n",
    "print(f\"  X_train: {X_train.shape} - Model studied these\")\n",
    "print(f\"  y_train: {y_train.shape} - Model learned these patterns\")\n",
    "\n",
    "print(\"\\nTESTING DATA (model never saw this - TRUE TEST!):\")\n",
    "print(f\"  X_test:  {X_test.shape} - New inputs to predict for\")\n",
    "print(f\"  y_test:  {y_test.shape} - Actual answers (we'll compare to predictions)\")\n",
    "\n",
    "print(f\"\\nüéØ OUR GOAL:\")\n",
    "print(f\"   Use trained model to predict y_test from X_test\")\n",
    "print(f\"   Then compare predictions to actual y_test (answer key)\")\n",
    "\n",
    "# Visual representation\n",
    "print(\"\\nüìà THE PREDICTION PROCESS:\")\n",
    "print(\"\"\"\n",
    "  Test Input          Trained Model         Prediction\n",
    "  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê         ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê       ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "  \n",
    "  X_test   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí   100 Trees      ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí  y_pred\n",
    "  (602, 2)           (voting)               (602, 29)\n",
    "                     \n",
    "  [1, 1]    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí  Tree 1: [1,0,1,...]  ‚îÄ‚îÄ‚Üí  Final:\n",
    "  (Google,           Tree 2: [1,0,1,...]       [1,0,1,...]\n",
    "   Data              ...                        \n",
    "   Scientist)        Tree 100: [1,0,1,...]     (binary predictions)\n",
    "                     \n",
    "                     ‚Üì Majority Vote\n",
    "                     \n",
    "                     Each skill predicted\n",
    "                     based on tree votes!\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 2: MAKE PREDICTIONS\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ CALLING model.predict()\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nWhat will happen:\")\n",
    "print(\"  1. Model takes X_test (602 examples)\")\n",
    "print(\"  2. For EACH example:\")\n",
    "print(\"     a. Passes it through all 100 trees\")\n",
    "print(\"     b. Each tree predicts all 29 skills\")\n",
    "print(\"     c. Takes majority vote for each skill\")\n",
    "print(\"  3. Returns predictions for all 602 people\")\n",
    "\n",
    "print(\"\\nProcessing...\")\n",
    "\n",
    "# üåü THE PREDICTION LINE! üåü\n",
    "# model.predict(X_test) = Ask model to predict for test data\n",
    "# - model: Our trained Random Forest (has learned patterns)\n",
    "# - X_test: New inputs (602 people, never seen before!)\n",
    "# Returns: y_pred = Binary predictions for all 29 skills\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"‚úÖ Predictions complete!\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 3: UNDERSTAND THE PREDICTIONS OUTPUT\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üì¶ UNDERSTANDING THE PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n1. WHAT IS y_pred?\")\n",
    "print(f\"   Type: {type(y_pred)}\")\n",
    "print(f\"   ‚Üí It's a NumPy array (table of numbers)\")\n",
    "\n",
    "print(f\"\\n2. SHAPE OF y_pred:\")\n",
    "print(f\"   Shape: {y_pred.shape}\")\n",
    "print(f\"   ‚Üí ({y_pred.shape[0]} people, {y_pred.shape[1]} skills)\")\n",
    "print(f\"   ‚Üí Same shape as y_test! (This is good ‚úì)\")\n",
    "\n",
    "print(f\"\\n3. WHAT'S INSIDE y_pred?\")\n",
    "print(f\"   Data type: {y_pred.dtype}\")\n",
    "print(f\"   ‚Üí Integer values: 0 or 1\")\n",
    "print(f\"   ‚Üí 0 = Model predicts person DOESN'T have this skill\")\n",
    "print(f\"   ‚Üí 1 = Model predicts person HAS this skill\")\n",
    "\n",
    "print(f\"\\n4. FIRST PREDICTION (Person 0):\")\n",
    "print(f\"   {y_pred[0]}\")\n",
    "print(f\"   ‚Üí This is a binary array of {len(y_pred[0])} values\")\n",
    "print(f\"   ‚Üí Each position represents one skill\")\n",
    "print(f\"   ‚Üí 1 = has skill, 0 = doesn't have skill\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 4: COMPARE ONE PREDICTION TO ACTUAL\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üîç DETAILED COMPARISON: PERSON 0\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "person_idx = 0\n",
    "\n",
    "print(f\"\\nPerson {person_idx} from test set:\")\n",
    "print(f\"  Input (X_test):  {X_test.iloc[person_idx].values}\")\n",
    "print(f\"    ‚Üí Company code: {X_test.iloc[person_idx, 0]}\")\n",
    "print(f\"    ‚Üí Designation code: {X_test.iloc[person_idx, 1]}\")\n",
    "\n",
    "print(f\"\\n  Predicted (y_pred): {y_pred[person_idx]}\")\n",
    "print(f\"  Actual (y_test):    {y_test[person_idx]}\")\n",
    "\n",
    "# Check if they match\n",
    "\n",
    "matches = (y_pred[person_idx] == y_test[person_idx])\n",
    "num_correct = matches.sum()\n",
    "total = len(matches)\n",
    "accuracy = (num_correct / total) * 100\n",
    "\n",
    "print(f\"\\n  Accuracy for this person: {num_correct}/{total} = {accuracy:.1f}%\")\n",
    "\n",
    "# Show skill-by-skill comparison\n",
    "print(f\"\\n  Skill-by-skill breakdown (first 10 skills):\")\n",
    "print(f\"  {'Skill':<25} {'Predicted':<10} {'Actual':<10} {'Match?'}\")\n",
    "print(f\"  {'-'*60}\")\n",
    "\n",
    "for i in range(min(10, len(mlb.classes_))):\n",
    "    skill_name = mlb.classes_[i]\n",
    "    predicted = y_pred[person_idx][i]\n",
    "    actual = y_test[person_idx][i]\n",
    "    match = \"‚úì\" if predicted == actual else \"‚úó\"\n",
    "    print(f\"  {skill_name:<25} {predicted:<10} {actual:<10} {match}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# STEP 5: DECODE PREDICTIONS TO SKILL NAMES\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üî§ DECODING: NUMBERS ‚Üí SKILL NAMES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nRemember: Predictions are binary arrays [1, 0, 1, 0, ...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c718f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üéì TRAINING THE MODEL\n",
      "======================================================================\n",
      "\n",
      "Training data:\n",
      "  ‚Ä¢ 2408 people (examples to learn from)\n",
      "  ‚Ä¢ 2 features per person (Company, Designation)\n",
      "  ‚Ä¢ 29 skills to predict\n",
      "\n",
      "Model configuration:\n",
      "  ‚Ä¢ Algorithm: Random Forest\n",
      "  ‚Ä¢ Number of trees: 100\n",
      "  ‚Ä¢ Using all CPU cores for speed\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Starting training... (this takes ~30 seconds)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚úÖ Training complete in 0.8 seconds!\n",
      "\n",
      "======================================================================\n",
      "üß† WHAT THE MODEL LEARNED\n",
      "======================================================================\n",
      "\n",
      "BEFORE training:\n",
      "  Model = Empty brain (knows nothing)\n",
      "  Can predict? NO ‚ùå\n",
      "\n",
      "AFTER training (1 seconds later):\n",
      "  Model = Smart brain (learned patterns from 2408 examples)\n",
      "  Can predict? YES ‚úÖ\n",
      "  \n",
      "The model now knows things like:\n",
      "  \"Google + Data Scientist ‚Üí Usually Python, ML, SQL\"\n",
      "  \"Amazon + Backend Engineer ‚Üí Usually Java, AWS, Microservices\"\n",
      "  \"Microsoft + Cloud Architect ‚Üí Usually Azure, C#, Cloud stuff\"\n",
      "  \n",
      "It stored these patterns in 100 decision trees!\n",
      "\n",
      "Verification:\n",
      "  ‚úì Model has 100 trained trees\n",
      "  ‚úì Model can now make predictions\n",
      "  ‚úì Ready for testing!\n",
      "\n",
      "======================================================================\n",
      "‚ú® TRAINING DONE! MODEL IS NOW SMART! ‚ú®\n",
      "======================================================================\n",
      "\n",
      "Next: We'll test the model on NEW data it's never seen!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 14: TRAIN THE MODEL - SIMPLIFIED & CLEAR\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ SIMPLE EXPLANATION: WHAT IS MODEL TRAINING?\n",
    "==============================================\n",
    "\n",
    "Imagine you're learning to play basketball:\n",
    "- Day 1-30: You practice shooting 100 times a day (TRAINING)\n",
    "- Day 31: Coach tests you with NEW shots you've never practiced (TESTING)\n",
    "\n",
    "TRAINING = LEARNING FROM EXAMPLES\n",
    "TESTING = Using what you learned on NEW situations\n",
    "\n",
    "OUR SITUATION:\n",
    "- We have 2,408 resumes (training examples)\n",
    "- Model will study these and learn patterns\n",
    "- Then we'll test it on 602 NEW resumes it's never seen\n",
    "\n",
    "WHAT PATTERNS WILL IT LEARN?\n",
    "==============================\n",
    "\n",
    "Simple example:\n",
    "- Model sees 50 \"Google Data Scientists\"\n",
    "- 45 of them have Python\n",
    "- 42 of them have Machine Learning\n",
    "- 38 of them have SQL\n",
    "\n",
    "Model learns: \"Google Data Scientist ‚Üí Usually has Python, ML, SQL\"\n",
    "\n",
    "It does this for ALL company + designation combinations!\n",
    "\n",
    "HOW DOES IT LEARN?\n",
    "===================\n",
    "\n",
    "We're using \"Random Forest\" = 100 decision trees working together\n",
    "\n",
    "Think of it like asking 100 different teachers the same question:\n",
    "- 1 teacher might make mistakes\n",
    "- 100 teachers voting together? Much more reliable!\n",
    "\n",
    "Each tree asks questions:\n",
    "- Tree 1: \"Is it Google?\" ‚Üí \"Is it Data Scientist?\" ‚Üí Predicts skills\n",
    "- Tree 2: Asks different questions ‚Üí Makes different predictions\n",
    "- Tree 3: Different questions again...\n",
    "- (97 more trees...)\n",
    "\n",
    "Final answer = What MOST trees agree on (majority vote)\n",
    "\n",
    "WHAT HAPPENS WHEN WE TRAIN?\n",
    "============================\n",
    "\n",
    "The model will:\n",
    "1. Look at all 2,408 training examples\n",
    "2. Build 100 decision trees (each learns differently)\n",
    "3. Store all the patterns it discovered\n",
    "4. Become \"smart\" - ready to predict!\n",
    "\n",
    "Time: About 30 seconds\n",
    "After training: Model is frozen (can't learn more without retraining)\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# LET'S TRAIN!\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üéì TRAINING THE MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# What are we training with?\n",
    "print(f\"\\nTraining data:\")\n",
    "print(f\"  ‚Ä¢ {X_train.shape[0]} people (examples to learn from)\")\n",
    "print(f\"  ‚Ä¢ {X_train.shape[1]} features per person (Company, Designation)\")\n",
    "print(f\"  ‚Ä¢ {y_train.shape[1]} skills to predict\")\n",
    "\n",
    "print(f\"\\nModel configuration:\")\n",
    "print(f\"  ‚Ä¢ Algorithm: Random Forest\")\n",
    "print(f\"  ‚Ä¢ Number of trees: 100\")\n",
    "print(f\"  ‚Ä¢ Using all CPU cores for speed\")\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "print(\"Starting training... (this takes ~30 seconds)\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# THIS IS THE TRAINING LINE!\n",
    "# model.fit() = \"Model, please learn from X_train and y_train\"\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate how long it took\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete in {elapsed:.1f} seconds!\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# WHAT CHANGED?\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üß† WHAT THE MODEL LEARNED\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "BEFORE training:\n",
    "  Model = Empty brain (knows nothing)\n",
    "  Can predict? NO ‚ùå\n",
    "\n",
    "AFTER training ({elapsed:.0f} seconds later):\n",
    "  Model = Smart brain (learned patterns from {X_train.shape[0]} examples)\n",
    "  Can predict? YES ‚úÖ\n",
    "  \n",
    "The model now knows things like:\n",
    "  \"Google + Data Scientist ‚Üí Usually Python, ML, SQL\"\n",
    "  \"Amazon + Backend Engineer ‚Üí Usually Java, AWS, Microservices\"\n",
    "  \"Microsoft + Cloud Architect ‚Üí Usually Azure, C#, Cloud stuff\"\n",
    "  \n",
    "It stored these patterns in 100 decision trees!\n",
    "\"\"\")\n",
    "\n",
    "# Verify it worked\n",
    "print(\"Verification:\")\n",
    "print(f\"  ‚úì Model has {len(model.estimators_)} trained trees\")\n",
    "print(f\"  ‚úì Model can now make predictions\")\n",
    "print(f\"  ‚úì Ready for testing!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ú® TRAINING DONE! MODEL IS NOW SMART! ‚ú®\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nNext: We'll test the model on NEW data it's never seen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5dd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîÆ MAKING PREDICTIONS\n",
      "======================================================================\n",
      "\n",
      "What we're doing:\n",
      "  ‚Ä¢ Input: 602 new people (X_test) - model never saw these!\n",
      "  ‚Ä¢ Output: Predicted skills for each person\n",
      "  ‚Ä¢ Compare: Check against actual skills (y_test)\n",
      "\n",
      "Calling model.predict()...\n",
      "‚úÖ Done! Got predictions for 602 people\n",
      "   Each person has predictions for 29 skills\n",
      "\n",
      "======================================================================\n",
      "üë§ EXAMPLE: PERSON 0 FROM TEST SET\n",
      "======================================================================\n",
      "\n",
      "Input data:\n",
      "  Company code: 2\n",
      "  Designation code: 0\n",
      "\n",
      "Model's prediction (binary array):\n",
      "  [1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "  (This is hard to read - let's decode it...)\n",
      "\n",
      "Actual skills (binary array):\n",
      "  [0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "\n",
      "How many match? 24 out of 29 (82.8%)\n",
      "\n",
      "======================================================================\n",
      "üî§ DECODING TO READABLE SKILL NAMES\n",
      "======================================================================\n",
      "\n",
      "PREDICTED SKILLS (what model thinks):\n",
      "  ‚úì AWS\n",
      "  ‚úì Agile\n",
      "  ‚úì Azure\n",
      "  ‚úì Kubernetes\n",
      "  ‚úì Scalability\n",
      "  ‚úì Terraform\n",
      "\n",
      "Total predicted: 6 skills\n",
      "\n",
      "ACTUAL SKILLS (ground truth):\n",
      "  ‚úì Azure\n",
      "  ‚úì Communication\n",
      "  ‚úì Kubernetes\n",
      "  ‚úì Python\n",
      "  ‚úì Scalability\n",
      "\n",
      "Total actual: 5 skills\n",
      "\n",
      "üìä COMPARISON:\n",
      "  ‚úÖ Correct: 3 skills\n",
      "      ‚Ä¢ Scalability\n",
      "      ‚Ä¢ Azure\n",
      "      ‚Ä¢ Kubernetes\n",
      "  ‚ùå Missed (should have predicted): 2 skills\n",
      "      ‚Ä¢ Python\n",
      "      ‚Ä¢ Communication\n",
      "  ‚ùå Extra (shouldn't have predicted): 3 skills\n",
      "      ‚Ä¢ AWS\n",
      "      ‚Ä¢ Agile\n",
      "      ‚Ä¢ Terraform\n",
      "\n",
      "======================================================================\n",
      "üíØ CONFIDENCE SCORES - HOW SURE IS THE MODEL?\n",
      "======================================================================\n",
      "\n",
      "Remember: We have 100 trees. Each tree voted on each skill.\n",
      "Confidence = What percentage of trees agreed?\n",
      "\n",
      "Let me show you how this works step by step:\n",
      "\n",
      "\n",
      "Example input: [2 0]\n",
      "  (Company=2, Designation=0)\n",
      "\n",
      "Step 1: Get prediction from EACH of the 100 trees individually\n",
      "  (Not just final prediction, but what each tree said)\n",
      "  Result shape: (100, 29)\n",
      "  ‚Üí 100 trees, each made 29 skill predictions (0 or 1)\n",
      "\n",
      "Step 2: For each skill, count how many trees voted '1' (YES)\n",
      "  Result shape: (29,)\n",
      "  ‚Üí 29 confidence scores (one for each skill)\n",
      "\n",
      "Step 3: Interpret the confidence scores\n",
      "  Confidence = (Trees that voted YES) / 100\n",
      "  Example: 0.85 means 85 trees said YES, 15 said NO\n",
      "\n",
      "======================================================================\n",
      "üìä CONFIDENCE FOR EACH SKILL (Person 0)\n",
      "======================================================================\n",
      "\n",
      "Skill                     Confidence   Prediction   Actual     Match?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "AWS                       100.0% üü¢ HIGH       1            0          ‚úó\n",
      "Agile                      77.0% üü° MEDIUM     1            0          ‚úó\n",
      "Algorithms                  0.0% üî¥ LOW        0            0          ‚úì\n",
      "Azure                      99.0% üü¢ HIGH       1            1          ‚úì\n",
      "C#                          0.0% üî¥ LOW        0            0          ‚úì\n",
      "CI/CD                       0.0% üî¥ LOW        0            0          ‚úì\n",
      "Communication               4.0% üî¥ LOW        0            1          ‚úó\n",
      "Data Structures             0.0% üî¥ LOW        0            0          ‚úì\n",
      "Data Visualization          0.0% üî¥ LOW        0            0          ‚úì\n",
      "Docker                      0.0% üî¥ LOW        0            0          ‚úì\n",
      "Git                         0.0% üî¥ LOW        0            0          ‚úì\n",
      "Java                       32.0% üî¥ LOW        0            0          ‚úì\n",
      "Jira                        0.0% üî¥ LOW        0            0          ‚úì\n",
      "Kubernetes                 78.0% üü° MEDIUM     1            1          ‚úì\n",
      "Leadership                  0.0% üî¥ LOW        0            0          ‚úì\n",
      "Linux                       0.0% üî¥ LOW        0            0          ‚úì\n",
      "Machine Learning            0.0% üî¥ LOW        0            0          ‚úì\n",
      "Market Analysis             0.0% üî¥ LOW        0            0          ‚úì\n",
      "Monitoring                  0.0% üî¥ LOW        0            0          ‚úì\n",
      "Network Security           34.0% üî¥ LOW        0            0          ‚úì\n",
      "Python                      9.0% üî¥ LOW        0            1          ‚úó\n",
      "R                           0.0% üî¥ LOW        0            0          ‚úì\n",
      "Roadmapping                 0.0% üî¥ LOW        0            0          ‚úì\n",
      "SQL                         9.0% üî¥ LOW        0            0          ‚úì\n",
      "Scalability                96.0% üü¢ HIGH       1            1          ‚úì\n",
      "Statistics                  0.0% üî¥ LOW        0            0          ‚úì\n",
      "TensorFlow                  0.0% üî¥ LOW        0            0          ‚úì\n",
      "Terraform                 100.0% üü¢ HIGH       1            0          ‚úó\n",
      "UX/UI Principles            0.0% üî¥ LOW        0            0          ‚úì\n",
      "\n",
      "======================================================================\n",
      "üéì INTERPRETING CONFIDENCE\n",
      "======================================================================\n",
      "\n",
      "HIGHEST CONFIDENCE:\n",
      "  Skill: AWS\n",
      "  Confidence: 100.0%\n",
      "  Meaning: 100 out of 100 trees agreed!\n",
      "  ‚Üí Model is VERY SURE about this skill\n",
      "\n",
      "LOWEST CONFIDENCE:\n",
      "  Skill: Algorithms\n",
      "  Confidence: 0.0%\n",
      "  Meaning: Only 0 out of 100 trees agreed\n",
      "  ‚Üí Model is NOT SURE (almost random guess)\n",
      "\n",
      "======================================================================\n",
      "üíº WHAT DOES THIS MEAN FOR USERS?\n",
      "======================================================================\n",
      "\n",
      "When we show skill recommendations to users, confidence helps them:\n",
      "\n",
      "HIGH CONFIDENCE (80-100%): \"You DEFINITELY need this skill!\"\n",
      "  Example: Python at 95% confidence\n",
      "  ‚Üí User should prioritize learning this\n",
      "  ‚Üí Very strong pattern in data\n",
      "\n",
      "MEDIUM CONFIDENCE (60-80%): \"You probably need this skill\"\n",
      "  Example: Docker at 68% confidence\n",
      "  ‚Üí Good to learn, but not absolutely critical\n",
      "  ‚Üí Moderate pattern in data\n",
      "\n",
      "LOW CONFIDENCE (50-60%): \"Maybe you need this, maybe not\"\n",
      "  Example: Rust at 55% confidence\n",
      "  ‚Üí Model is unsure (barely better than guessing)\n",
      "  ‚Üí Weak or conflicting pattern in data\n",
      "\n",
      "VERY LOW (<50%): \"You probably DON'T need this\"\n",
      "  Example: COBOL at 12% confidence\n",
      "  ‚Üí Model is pretty sure you don't need it\n",
      "  ‚Üí Rarely appears in this job combination\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üì¶ SUMMARY: WHAT WE DID\n",
      "======================================================================\n",
      "\n",
      "1. MADE PREDICTIONS\n",
      "   ‚Ä¢ Used model.predict(X_test)\n",
      "   ‚Ä¢ Got predictions for 602 people\n",
      "   ‚Ä¢ Each person: binary array [1,0,1,0,...] for 29 skills\n",
      "\n",
      "2. DECODED PREDICTIONS\n",
      "   ‚Ä¢ Converted binary [1,0,1,...] to skill names\n",
      "   ‚Ä¢ Example: [1,0,1] ‚Üí [\"Python\", \"AWS\"]\n",
      "   ‚Ä¢ Easier for humans to read!\n",
      "\n",
      "3. CALCULATED CONFIDENCE\n",
      "   ‚Ä¢ Got predictions from all 100 trees individually\n",
      "   ‚Ä¢ Counted votes for each skill\n",
      "   ‚Ä¢ Confidence = % of trees that agreed\n",
      "   \n",
      "4. INTERPRETED RESULTS\n",
      "   ‚Ä¢ High confidence ‚Üí Strong pattern ‚Üí Trust this!\n",
      "   ‚Ä¢ Low confidence ‚Üí Weak pattern ‚Üí Be cautious\n",
      "\n",
      "KEY VARIABLES:\n",
      "  y_pred: Final predictions (binary, shape: (602, 29))\n",
      "  confidence_scores: How sure model is (0-1, shape: (29,))\n",
      "  \n",
      "NEXT CELL:\n",
      "  We'll evaluate: How accurate are these predictions?\n",
      "  Calculate metrics: Accuracy, Precision, Recall\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚ú® PREDICTIONS COMPLETE! ‚ú®\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 15: MAKE PREDICTIONS - WITH CLEAR CONFIDENCE EXPLANATION\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ SIMPLE EXPLANATION: WHAT IS PREDICTION?\n",
    "===========================================\n",
    "\n",
    "The model is now trained (smart). Let's test it!\n",
    "\n",
    "We'll give it 602 NEW people it's NEVER seen and ask:\n",
    "\"What skills should these people have?\"\n",
    "\n",
    "Then we'll compare its answers to the real answers (y_test).\n",
    "\n",
    "ANALOGY: Student Taking an Exam\n",
    "- Studied from textbook (training data)\n",
    "- Now takes exam with NEW questions (test data)\n",
    "- We grade the exam (compare predictions to actual)\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "ü§î WHAT IS \"CONFIDENCE\"? (SUPER IMPORTANT!)\n",
    "============================================\n",
    "\n",
    "Before I explain the code, you MUST understand confidence.\n",
    "\n",
    "SIMPLE EXAMPLE:\n",
    "---------------\n",
    "Imagine 100 doctors examining one patient.\n",
    "\n",
    "Scenario 1: Diagnosing if patient has flu\n",
    "  ‚Ä¢ 95 doctors say: \"YES, has flu\"\n",
    "  ‚Ä¢ 5 doctors say: \"NO, doesn't have flu\"\n",
    "  \n",
    "  Result: Predict \"HAS FLU\"\n",
    "  Confidence: 95% (because 95 out of 100 agreed)\n",
    "  \n",
    "  Interpretation: We're VERY CONFIDENT in this diagnosis!\n",
    "\n",
    "Scenario 2: Diagnosing if patient has rare disease\n",
    "  ‚Ä¢ 52 doctors say: \"YES, has disease\"\n",
    "  ‚Ä¢ 48 doctors say: \"NO, doesn't have disease\"\n",
    "  \n",
    "  Result: Predict \"HAS DISEASE\" (barely won with 52 vs 48)\n",
    "  Confidence: 52% (because only 52 out of 100 agreed)\n",
    "  \n",
    "  Interpretation: We're NOT CONFIDENT - it's almost 50/50!\n",
    "\n",
    "OUR MODEL WORKS THE SAME WAY:\n",
    "------------------------------\n",
    "We have 100 decision trees (like 100 doctors).\n",
    "\n",
    "For each skill prediction:\n",
    "  ‚Ä¢ Each tree votes: \"Person HAS this skill\" or \"Person DOESN'T have this skill\"\n",
    "  ‚Ä¢ Count the votes\n",
    "  ‚Ä¢ Majority wins\n",
    "  ‚Ä¢ Confidence = What % voted for the winner\n",
    "\n",
    "EXAMPLE WITH OUR MODEL:\n",
    "-----------------------\n",
    "Input: Google + Data Scientist\n",
    "Predicting: Does this person need Python?\n",
    "\n",
    "Tree 1: \"YES, needs Python\"\n",
    "Tree 2: \"YES, needs Python\"\n",
    "Tree 3: \"NO, doesn't need Python\"\n",
    "Tree 4: \"YES, needs Python\"\n",
    "Tree 5: \"YES, needs Python\"\n",
    "... (95 more trees)\n",
    "\n",
    "Final count:\n",
    "  ‚Ä¢ 87 trees said YES\n",
    "  ‚Ä¢ 13 trees said NO\n",
    "  \n",
    "Result:\n",
    "  ‚Ä¢ Prediction: YES (1) - because 87 > 13\n",
    "  ‚Ä¢ Confidence: 87% - because 87 out of 100 agreed\n",
    "\n",
    "WHY CONFIDENCE MATTERS:\n",
    "-----------------------\n",
    "\n",
    "High confidence (80-100%):\n",
    "  ‚úì Model is SURE about this skill\n",
    "  ‚úì Strong pattern in training data\n",
    "  ‚úì User should DEFINITELY learn this skill\n",
    "  Example: Python for Data Scientist at Google (87% confidence)\n",
    "\n",
    "Medium confidence (60-80%):\n",
    "  ‚ö† Model is FAIRLY SURE\n",
    "  ‚ö† Decent pattern but not super strong\n",
    "  Example: TensorFlow for Data Scientist (68% confidence)\n",
    "\n",
    "Low confidence (50-60%):\n",
    "  ‚úó Model is GUESSING (barely better than coin flip!)\n",
    "  ‚úó Weak or conflicting patterns\n",
    "  ‚úó User might not need this skill\n",
    "  Example: COBOL for Data Scientist (12% confidence)\n",
    "\n",
    "HOW WE CALCULATE CONFIDENCE:\n",
    "-----------------------------\n",
    "\n",
    "Step 1: Get predictions from ALL 100 trees individually\n",
    "  (Not just the final prediction, but what each tree said)\n",
    "\n",
    "Step 2: For each skill, count the votes\n",
    "  Example: For Python\n",
    "    ‚Ä¢ Count how many trees voted 1 (HAS Python)\n",
    "    ‚Ä¢ Count how many trees voted 0 (NO Python)\n",
    "\n",
    "Step 3: Calculate percentage\n",
    "  Confidence = (Number of 1 votes) / 100\n",
    "  Example: 87 voted 1 ‚Üí Confidence = 87/100 = 0.87 = 87%\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "NOW LET'S SEE THIS IN ACTION!\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 1: MAKE BASIC PREDICTIONS\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üîÆ MAKING PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nWhat we're doing:\")\n",
    "print(\"  ‚Ä¢ Input: 602 new people (X_test) - model never saw these!\")\n",
    "print(\"  ‚Ä¢ Output: Predicted skills for each person\")\n",
    "print(\"  ‚Ä¢ Compare: Check against actual skills (y_test)\")\n",
    "\n",
    "print(\"\\nCalling model.predict()...\")\n",
    "\n",
    "# Make predictions for all 602 test people\n",
    "# Each person gets predicted skills (binary: 0 or 1 for each of 29 skills)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"‚úÖ Done! Got predictions for {len(y_pred)} people\")\n",
    "print(f\"   Each person has predictions for {y_pred.shape[1]} skills\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 2: LOOK AT ONE EXAMPLE\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üë§ EXAMPLE: PERSON 0 FROM TEST SET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "person_idx = 0\n",
    "\n",
    "print(f\"\\nInput data:\")\n",
    "print(f\"  Company code: {X_test.iloc[person_idx, 0]}\")\n",
    "print(f\"  Designation code: {X_test.iloc[person_idx, 1]}\")\n",
    "\n",
    "print(f\"\\nModel's prediction (binary array):\")\n",
    "print(f\"  {y_pred[person_idx]}\")\n",
    "print(f\"  (This is hard to read - let's decode it...)\")\n",
    "\n",
    "print(f\"\\nActual skills (binary array):\")\n",
    "print(f\"  {y_test[person_idx]}\")\n",
    "\n",
    "# Count how many match\n",
    "matches = (y_pred[person_idx] == y_test[person_idx]).sum()\n",
    "total = len(y_pred[person_idx])\n",
    "print(f\"\\nHow many match? {matches} out of {total} ({matches/total*100:.1f}%)\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 3: DECODE TO SKILL NAMES (EASIER TO READ)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üî§ DECODING TO READABLE SKILL NAMES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nPREDICTED SKILLS (what model thinks):\")\n",
    "predicted_skills = []\n",
    "for i in range(len(y_pred[person_idx])):\n",
    "    if y_pred[person_idx][i] == 1:  # If prediction is 1 (has skill)\n",
    "        skill_name = mlb.classes_[i]\n",
    "        predicted_skills.append(skill_name)\n",
    "        print(f\"  ‚úì {skill_name}\")\n",
    "\n",
    "print(f\"\\nTotal predicted: {len(predicted_skills)} skills\")\n",
    "\n",
    "print(\"\\nACTUAL SKILLS (ground truth):\")\n",
    "actual_skills = []\n",
    "for i in range(len(y_test[person_idx])):\n",
    "    if y_test[person_idx][i] == 1:  # If actual is 1 (has skill)\n",
    "        skill_name = mlb.classes_[i]\n",
    "        actual_skills.append(skill_name)\n",
    "        print(f\"  ‚úì {skill_name}\")\n",
    "\n",
    "print(f\"\\nTotal actual: {len(actual_skills)} skills\")\n",
    "\n",
    "# Compare them\n",
    "correct = set(predicted_skills) & set(actual_skills)  # Both lists\n",
    "missed = set(actual_skills) - set(predicted_skills)   # In actual but not predicted\n",
    "extra = set(predicted_skills) - set(actual_skills)    # Predicted but not in actual\n",
    "\n",
    "print(f\"\\nüìä COMPARISON:\")\n",
    "print(f\"  ‚úÖ Correct: {len(correct)} skills\")\n",
    "for skill in correct:\n",
    "    print(f\"      ‚Ä¢ {skill}\")\n",
    "\n",
    "print(f\"  ‚ùå Missed (should have predicted): {len(missed)} skills\")\n",
    "for skill in missed:\n",
    "    print(f\"      ‚Ä¢ {skill}\")\n",
    "\n",
    "print(f\"  ‚ùå Extra (shouldn't have predicted): {len(extra)} skills\")\n",
    "for skill in extra:\n",
    "    print(f\"      ‚Ä¢ {skill}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 4: CONFIDENCE CALCULATION (THE IMPORTANT PART!)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üíØ CONFIDENCE SCORES - HOW SURE IS THE MODEL?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "Remember: We have 100 trees. Each tree voted on each skill.\n",
    "Confidence = What percentage of trees agreed?\n",
    "\n",
    "Let me show you how this works step by step:\n",
    "\"\"\")\n",
    "\n",
    "# Pick one example from test set\n",
    "example_input = X_test[:1]  # Take first test example, shape (1, 2)\n",
    "\n",
    "print(f\"\\nExample input: {example_input.values[0]}\")\n",
    "print(f\"  (Company={example_input.values[0][0]}, Designation={example_input.values[0][1]})\")\n",
    "\n",
    "print(\"\\nStep 1: Get prediction from EACH of the 100 trees individually\")\n",
    "print(\"  (Not just final prediction, but what each tree said)\")\n",
    "\n",
    "# Get predictions from all 100 trees separately\n",
    "# This gives us a 2D array: (100 trees, 29 skills)\n",
    "all_tree_predictions = np.array([\n",
    "    tree.predict(example_input)[0]  # Get prediction from one tree\n",
    "    for tree in model.estimators_     # Do this for all 100 trees\n",
    "])\n",
    "\n",
    "print(f\"  Result shape: {all_tree_predictions.shape}\")\n",
    "print(f\"  ‚Üí 100 trees, each made 29 skill predictions (0 or 1)\")\n",
    "\n",
    "print(\"\\nStep 2: For each skill, count how many trees voted '1' (YES)\")\n",
    "\n",
    "# Calculate confidence: For each skill, what % of trees voted 1?\n",
    "# axis=0 means: sum down the rows (across all 100 trees) for each skill\n",
    "confidence_scores = all_tree_predictions.mean(axis=0)\n",
    "\n",
    "print(f\"  Result shape: {confidence_scores.shape}\")\n",
    "print(f\"  ‚Üí 29 confidence scores (one for each skill)\")\n",
    "\n",
    "print(\"\\nStep 3: Interpret the confidence scores\")\n",
    "print(f\"  Confidence = (Trees that voted YES) / 100\")\n",
    "print(f\"  Example: 0.85 means 85 trees said YES, 15 said NO\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 5: SHOW CONFIDENCE FOR ALL SKILLS\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä CONFIDENCE FOR EACH SKILL (Person 0)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n{'Skill':<25} {'Confidence':<12} {'Prediction':<12} {'Actual':<10} {'Match?'}\")\n",
    "print(\"‚îÄ\" * 75)\n",
    "\n",
    "# Show all 29 skills with their confidence scores\n",
    "for i in range(len(mlb.classes_)):\n",
    "    skill = mlb.classes_[i]\n",
    "    confidence = confidence_scores[i]\n",
    "    predicted = y_pred[0][i]\n",
    "    actual = y_test[0][i]\n",
    "    match = \"‚úì\" if predicted == actual else \"‚úó\"\n",
    "    \n",
    "    # Format confidence as percentage and add interpretation\n",
    "    if confidence >= 0.8:\n",
    "        conf_level = \"üü¢ HIGH\"\n",
    "    elif confidence >= 0.5:\n",
    "        conf_level = \"üü° MEDIUM\"\n",
    "    else:\n",
    "        conf_level = \"üî¥ LOW\"\n",
    "    \n",
    "    print(f\"{skill:<25} {confidence*100:>5.1f}% {conf_level:<12} {predicted:<12} {actual:<10} {match}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 6: EXPLAIN WHAT CONFIDENCE MEANS\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéì INTERPRETING CONFIDENCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Find highest and lowest confidence predictions\n",
    "highest_idx = confidence_scores.argmax()\n",
    "lowest_idx = confidence_scores.argmin()\n",
    "\n",
    "print(f\"\\nHIGHEST CONFIDENCE:\")\n",
    "print(f\"  Skill: {mlb.classes_[highest_idx]}\")\n",
    "print(f\"  Confidence: {confidence_scores[highest_idx]*100:.1f}%\")\n",
    "print(f\"  Meaning: {int(confidence_scores[highest_idx]*100)} out of 100 trees agreed!\")\n",
    "print(f\"  ‚Üí Model is VERY SURE about this skill\")\n",
    "\n",
    "print(f\"\\nLOWEST CONFIDENCE:\")\n",
    "print(f\"  Skill: {mlb.classes_[lowest_idx]}\")\n",
    "print(f\"  Confidence: {confidence_scores[lowest_idx]*100:.1f}%\")\n",
    "print(f\"  Meaning: Only {int(confidence_scores[lowest_idx]*100)} out of 100 trees agreed\")\n",
    "print(f\"  ‚Üí Model is NOT SURE (almost random guess)\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 7: PRACTICAL MEANING\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üíº WHAT DOES THIS MEAN FOR USERS?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "When we show skill recommendations to users, confidence helps them:\n",
    "\n",
    "HIGH CONFIDENCE (80-100%): \"You DEFINITELY need this skill!\"\n",
    "  Example: Python at 95% confidence\n",
    "  ‚Üí User should prioritize learning this\n",
    "  ‚Üí Very strong pattern in data\n",
    "\n",
    "MEDIUM CONFIDENCE (60-80%): \"You probably need this skill\"\n",
    "  Example: Docker at 68% confidence\n",
    "  ‚Üí Good to learn, but not absolutely critical\n",
    "  ‚Üí Moderate pattern in data\n",
    "\n",
    "LOW CONFIDENCE (50-60%): \"Maybe you need this, maybe not\"\n",
    "  Example: Rust at 55% confidence\n",
    "  ‚Üí Model is unsure (barely better than guessing)\n",
    "  ‚Üí Weak or conflicting pattern in data\n",
    "\n",
    "VERY LOW (<50%): \"You probably DON'T need this\"\n",
    "  Example: COBOL at 12% confidence\n",
    "  ‚Üí Model is pretty sure you don't need it\n",
    "  ‚Üí Rarely appears in this job combination\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 8: SUMMARY\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üì¶ SUMMARY: WHAT WE DID\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "1. MADE PREDICTIONS\n",
    "   ‚Ä¢ Used model.predict(X_test)\n",
    "   ‚Ä¢ Got predictions for {len(y_pred)} people\n",
    "   ‚Ä¢ Each person: binary array [1,0,1,0,...] for 29 skills\n",
    "\n",
    "2. DECODED PREDICTIONS\n",
    "   ‚Ä¢ Converted binary [1,0,1,...] to skill names\n",
    "   ‚Ä¢ Example: [1,0,1] ‚Üí [\"Python\", \"AWS\"]\n",
    "   ‚Ä¢ Easier for humans to read!\n",
    "\n",
    "3. CALCULATED CONFIDENCE\n",
    "   ‚Ä¢ Got predictions from all 100 trees individually\n",
    "   ‚Ä¢ Counted votes for each skill\n",
    "   ‚Ä¢ Confidence = % of trees that agreed\n",
    "   \n",
    "4. INTERPRETED RESULTS\n",
    "   ‚Ä¢ High confidence ‚Üí Strong pattern ‚Üí Trust this!\n",
    "   ‚Ä¢ Low confidence ‚Üí Weak pattern ‚Üí Be cautious\n",
    "\n",
    "KEY VARIABLES:\n",
    "  y_pred: Final predictions (binary, shape: {y_pred.shape})\n",
    "  confidence_scores: How sure model is (0-1, shape: {confidence_scores.shape})\n",
    "  \n",
    "NEXT CELL:\n",
    "  We'll evaluate: How accurate are these predictions?\n",
    "  Calculate metrics: Accuracy, Precision, Recall\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ú® PREDICTIONS COMPLETE! ‚ú®\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a657778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä CALCULATING ACCURACY METRICS\n",
      "======================================================================\n",
      "\n",
      "Reminder of what we have:\n",
      "  y_test:  Actual skills (answer key)  - Shape: (602, 29)\n",
      "  y_pred:  Predicted skills (model's answers) - Shape: (602, 29)\n",
      "  Total individual predictions: 17,458\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "METRIC 1: HAMMING LOSS (Error Rate)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "Hamming Loss = 0.1929\n",
      "This means: 0.1929 = 19.29% of predictions are WRONG\n",
      "\n",
      "Breakdown:\n",
      "  Total predictions: 17,458\n",
      "  Wrong predictions: 3,367\n",
      "  Correct predictions: 14,091\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "METRIC 2: INDIVIDUAL ACCURACY (Most Important!)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "Individual Accuracy = 0.8071\n",
      "This means: 0.8071 = 80.71% of predictions are CORRECT\n",
      "\n",
      "üéØ IN SIMPLE TERMS:\n",
      "   Out of every 100 predictions, 80 are correct!\n",
      "   Out of every 100 predictions, 19 are wrong\n",
      "\n",
      "üìä VISUAL:\n",
      "   Correct: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Wrong:   ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë\n",
      "\n",
      "======================================================================\n",
      "ü§î IS 80.71% ACCURACY GOOD?\n",
      "======================================================================\n",
      "\n",
      "Let's compare to real-world systems:\n",
      "\n",
      "COMPARISON TABLE:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "System                       Accuracy    When to Use\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Medical Diagnosis            95-99%      Life critical\n",
      "Spam Email Filter            98-99%      High stakes\n",
      "Self-Driving Car             99.9%+      Safety critical\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Netflix Recommendations      75-85%      Entertainment\n",
      "Amazon Product Suggestions   80-85%      Shopping\n",
      "üìå OUR SKILL RECOMMENDER     80.7%       Career Advice ‚úì\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Weather Forecast (7 days)    70-80%      Planning\n",
      "Stock Market Prediction      55-65%      Very uncertain\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚úÖ OUR MODEL IS IN THE \"GOOD\" RANGE!\n",
      "\n",
      "It's comparable to recommendation systems like:\n",
      "  ‚Ä¢ Netflix suggesting movies\n",
      "  ‚Ä¢ Amazon suggesting products\n",
      "  ‚Ä¢ Spotify suggesting songs\n",
      "\n",
      "For career guidance, 80.7% is SOLID! ‚úì\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìä CALCULATING PRECISION, RECALL, F1\n",
      "======================================================================\n",
      "Flattened arrays:\n",
      "  y_test_flat: (17458,) - All actual values in one list\n",
      "  y_pred_flat: (17458,) - All predictions in one list\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "METRIC 3: PRECISION\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "Precision = 0.5685 = 56.85%\n",
      "\n",
      "üéØ WHAT THIS MEANS:\n",
      "   When model says 'person HAS this skill', it's correct 56 times out of 100\n",
      "   Example: Model recommends Python ‚Üí 56% chance person really needs it\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "METRIC 4: RECALL\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "Recall = 0.5846 = 58.46%\n",
      "\n",
      "üéØ WHAT THIS MEANS:\n",
      "   Of all skills people ACTUALLY need, model finds 58 out of 100\n",
      "   Example: If person needs 10 skills ‚Üí Model finds about 5 of them\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "METRIC 5: F1 SCORE\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "F1 Score = 0.5764 = 57.64%\n",
      "\n",
      "üéØ WHAT THIS MEANS:\n",
      "   Overall balanced performance between precision and recall\n",
      "   57% = Good balance between finding skills and being accurate\n",
      "\n",
      "======================================================================\n",
      "üîç WHERE ARE THE ERRORS? (Confusion Matrix)\n",
      "======================================================================\n",
      "\n",
      "Let's categorize every prediction into 4 types:\n",
      "\n",
      "1. TRUE POSITIVE (TP): Said YES, actually YES ‚úì‚úì\n",
      "   Example: Predicted \"has Python\", person has Python\n",
      "   \n",
      "2. TRUE NEGATIVE (TN): Said NO, actually NO ‚úì‚úì\n",
      "   Example: Predicted \"no COBOL\", person doesn't have COBOL\n",
      "   \n",
      "3. FALSE POSITIVE (FP): Said YES, actually NO ‚úó\n",
      "   Example: Predicted \"has Rust\", person doesn't have Rust\n",
      "   Type 1 Error - False alarm!\n",
      "   \n",
      "4. FALSE NEGATIVE (FN): Said NO, actually YES ‚úó\n",
      "   Example: Predicted \"no AWS\", person actually has AWS\n",
      "   Type 2 Error - Missed it!\n",
      "\n",
      "Counting all 17,458 predictions:\n",
      "\n",
      "‚úÖ CORRECT PREDICTIONS: 14,091\n",
      "   True Positives (TP):  2,291\n",
      "     ‚Üí Said 'has skill', actually has it\n",
      "   True Negatives (TN):  11,800\n",
      "     ‚Üí Said 'no skill', actually doesn't have it\n",
      "\n",
      "‚ùå WRONG PREDICTIONS: 3,367\n",
      "   False Positives (FP): 1,739\n",
      "     ‚Üí Said 'has skill', but doesn't (false alarm)\n",
      "   False Negatives (FN): 1,628\n",
      "     ‚Üí Said 'no skill', but actually has it (missed)\n",
      "\n",
      "üìä CONFUSION MATRIX:\n",
      "\n",
      "                     PREDICTED\n",
      "                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "                 ‚îÇ No Skill‚îÇHas Skill‚îÇ\n",
      "            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "         No Skill‚îÇ   TN    ‚îÇ   FP    ‚îÇ\n",
      "  ACTUAL         ‚îÇ  11,800 ‚îÇ   1,739 ‚îÇ\n",
      "            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "        Has Skill‚îÇ   FN    ‚îÇ   TP    ‚îÇ\n",
      "                 ‚îÇ   1,628 ‚îÇ   2,291 ‚îÇ\n",
      "                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üí° UNDERSTANDING THE ERRORS\n",
      "======================================================================\n",
      "\n",
      "FALSE POSITIVES (1,739): Recommended skills user doesn't need\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Impact: User wastes time learning unnecessary skills\n",
      "Example: Recommended \"Docker\" but job doesn't need it\n",
      "Severity: Medium (wastes time but not critical)\n",
      "\n",
      "FALSE NEGATIVES (1,628): Missed skills user DOES need\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Impact: User unprepared for job, might fail interview\n",
      "Example: Didn't recommend \"Kubernetes\" but job requires it\n",
      "Severity: High (could miss job opportunity!)\n",
      "\n",
      "Which is worse?\n",
      "  For career guidance: FALSE NEGATIVES are worse!\n",
      "  Better to recommend extra skill than miss important one.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚≠ê FINAL VERDICT: IS THE MODEL GOOD?\n",
      "======================================================================\n",
      "\n",
      "SUMMARY OF ALL METRICS:\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "Primary Metric (Most Important):\n",
      "  Individual Accuracy:    80.71% ‚úÖ\n",
      "  ‚Üí 8 out of 10 predictions are correct!\n",
      "\n",
      "Error Rate:\n",
      "  Hamming Loss:           19.29%\n",
      "  ‚Üí About 2 out of 10 predictions are wrong\n",
      "\n",
      "Prediction Quality:\n",
      "  Precision:              56.85%\n",
      "  ‚Üí When we recommend a skill, we're right 56 times out of 100\n",
      "  \n",
      "  Recall:                 58.46%\n",
      "  ‚Üí We find 58 out of 100 actual skills\n",
      "  \n",
      "  F1 Score:               57.64%\n",
      "  ‚Üí Balanced performance score\n",
      "\n",
      "Error Breakdown:\n",
      "  True Positives:         2,291\n",
      "  True Negatives:         11,800\n",
      "  False Positives:        1,739 (unnecessary recommendations)\n",
      "  False Negatives:        1,628 (missed skills)\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "VERDICT: ‚úÖ MODEL IS GOOD!\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚úì 80.7% accuracy is solid for recommendation systems\n",
      "‚úì Comparable to Netflix, Amazon recommendations\n",
      "‚úì Good enough for career guidance\n",
      "‚úì Users will get reliable skill suggestions\n",
      "\n",
      "‚úì Ready for production! ‚úÖ\n",
      "\n",
      "NOT GOOD ENOUGH FOR:\n",
      "‚úó Medical diagnosis (needs 95%+)\n",
      "‚úó Safety-critical systems (needs 99%+)\n",
      "‚úó Financial decisions (needs higher confidence)\n",
      "\n",
      "PERFECT FOR:\n",
      "‚úì Career roadmap planning ‚úì\n",
      "‚úì Skill recommendations ‚úì\n",
      "‚úì Educational guidance ‚úì\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚ú® EVALUATION COMPLETE! MODEL APPROVED! ‚ú®\n",
      "======================================================================\n",
      "\n",
      "Next: Save the model so we can use it in production!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 16: EVALUATE THE MODEL - SIMPLE & CLEAR\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ SIMPLE EXPLANATION: GRADING THE MODEL\n",
    "=========================================\n",
    "\n",
    "We gave the model an exam (predictions on 602 test people).\n",
    "Now let's GRADE it!\n",
    "\n",
    "ANALOGY: Grading a Student's Exam\n",
    "----------------------------------\n",
    "Student answered 100 questions (y_pred = predictions)\n",
    "Teacher has answer key (y_test = actual answers)\n",
    "Now we calculate: How many did student get right?\n",
    "\n",
    "OUR SITUATION:\n",
    "--------------\n",
    "Model predicted skills for 602 people\n",
    "We have the actual skills for those 602 people\n",
    "Let's compare and calculate accuracy!\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "WHY MULTIPLE METRICS?\n",
    "======================\n",
    "\n",
    "You might think: \"Just count correct vs wrong, right?\"\n",
    "\n",
    "NOT THAT SIMPLE! Here's why:\n",
    "\n",
    "Imagine a test with 100 questions:\n",
    "  ‚Ä¢ Student A: Answers all 100, gets 80 correct ‚Üí 80% accuracy\n",
    "  ‚Ä¢ Student B: Answers only 10, gets 9 correct ‚Üí 90% accuracy\n",
    "  \n",
    "Who's better? Hard to say! That's why we need multiple metrics.\n",
    "\n",
    "FOR OUR MODEL:\n",
    "We're predicting 29 skills for 602 people = 17,458 individual predictions!\n",
    "We need different ways to measure \"good\":\n",
    "\n",
    "1. INDIVIDUAL ACCURACY (Most Important!)\n",
    "   \"Out of 100 predictions, how many are right?\"\n",
    "   \n",
    "2. HAMMING LOSS (Same as above, but opposite)\n",
    "   \"Out of 100 predictions, how many are WRONG?\"\n",
    "   \n",
    "3. PRECISION\n",
    "   \"When model says 'has skill', how often is it right?\"\n",
    "   \n",
    "4. RECALL\n",
    "   \"Of all actual skills, how many did we find?\"\n",
    "   \n",
    "5. F1 SCORE\n",
    "   \"Balance between Precision and Recall\"\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "LET ME EXPLAIN EACH METRIC SIMPLY:\n",
    "===================================\n",
    "\n",
    "METRIC 1: INDIVIDUAL ACCURACY (EASY!)\n",
    "--------------------------------------\n",
    "Think: \"Out of 100 coin flips, how many did I predict correctly?\"\n",
    "\n",
    "Example:\n",
    "  Total predictions: 17,458\n",
    "  Correct: 14,090\n",
    "  Wrong: 3,368\n",
    "  \n",
    "  Individual Accuracy = 14,090 / 17,458 = 0.807 = 80.7%\n",
    "  \n",
    "Interpretation: \"8 out of 10 predictions are correct!\"\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "METRIC 2: HAMMING LOSS (OPPOSITE OF ACCURACY)\n",
    "----------------------------------------------\n",
    "Same as accuracy but measures ERRORS instead of CORRECT.\n",
    "\n",
    "Formula: Hamming Loss = 1 - Accuracy\n",
    "\n",
    "Example:\n",
    "  If Accuracy = 80.7%\n",
    "  Then Hamming Loss = 100% - 80.7% = 19.3%\n",
    "  \n",
    "Interpretation: \"About 19 out of 100 predictions are wrong\"\n",
    "\n",
    "Lower is better! (0 = perfect, 1 = terrible)\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "METRIC 3: PRECISION\n",
    "-------------------\n",
    "\"When I predict YES, how often am I right?\"\n",
    "\n",
    "Real-life example: Email spam filter\n",
    "  ‚Ä¢ Filter marked 100 emails as SPAM\n",
    "  ‚Ä¢ 90 really were spam\n",
    "  ‚Ä¢ 10 were NOT spam (oops!)\n",
    "  \n",
    "  Precision = 90/100 = 90%\n",
    "  \n",
    "For our model:\n",
    "  ‚Ä¢ Predicted \"HAS Python\" 1000 times\n",
    "  ‚Ä¢ 850 times it was correct\n",
    "  ‚Ä¢ 150 times person didn't actually have Python\n",
    "  \n",
    "  Precision = 850/1000 = 85%\n",
    "  \n",
    "Interpretation: \"When model says 'has skill', it's right 85% of time\"\n",
    "\n",
    "High precision = Few false alarms ‚úì\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "METRIC 4: RECALL\n",
    "----------------\n",
    "\"Of all the actual YESes, how many did I find?\"\n",
    "\n",
    "Real-life example: Doctor diagnosing disease\n",
    "  ‚Ä¢ 100 patients actually have disease\n",
    "  ‚Ä¢ Doctor correctly identified 80\n",
    "  ‚Ä¢ Doctor missed 20\n",
    "  \n",
    "  Recall = 80/100 = 80%\n",
    "  \n",
    "For our model:\n",
    "  ‚Ä¢ 1000 people actually have Python skill\n",
    "  ‚Ä¢ Model correctly identified 750\n",
    "  ‚Ä¢ Model missed 250\n",
    "  \n",
    "  Recall = 750/1000 = 75%\n",
    "  \n",
    "Interpretation: \"Model finds 75% of all actual skills\"\n",
    "\n",
    "High recall = Few missed items ‚úì\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "PRECISION vs RECALL - THE TRADEOFF:\n",
    "------------------------------------\n",
    "\n",
    "Imagine a metal detector at airport:\n",
    "\n",
    "SETTING 1: Very Strict (High Precision)\n",
    "  ‚Ä¢ Only beeps when REALLY sure there's metal\n",
    "  ‚Ä¢ Rarely wrong when it beeps (high precision)\n",
    "  ‚Ä¢ But misses some small items (low recall)\n",
    "  \n",
    "SETTING 2: Very Sensitive (High Recall)\n",
    "  ‚Ä¢ Beeps at slightest hint of metal\n",
    "  ‚Ä¢ Catches everything (high recall)\n",
    "  ‚Ä¢ But many false alarms (low precision)\n",
    "\n",
    "PERFECT BALANCE = High precision AND high recall (hard to achieve!)\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "METRIC 5: F1 SCORE\n",
    "------------------\n",
    "\"Average of Precision and Recall (with math adjustment)\"\n",
    "\n",
    "Formula: F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)\n",
    "\n",
    "Why this formula? It gives balanced score.\n",
    "\n",
    "Example:\n",
    "  Precision = 80%\n",
    "  Recall = 70%\n",
    "  F1 = 2 √ó (0.8 √ó 0.7) / (0.8 + 0.7) = 0.747 = 74.7%\n",
    "  \n",
    "Interpretation: \"Overall balanced performance is 74.7%\"\n",
    "\n",
    "Good F1 score = Both precision AND recall are good!\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "NOW LET'S CALCULATE THESE METRICS!\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 1: CALCULATE INDIVIDUAL ACCURACY & HAMMING LOSS\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä CALCULATING ACCURACY METRICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nReminder of what we have:\")\n",
    "print(f\"  y_test:  Actual skills (answer key)  - Shape: {y_test.shape}\")\n",
    "print(f\"  y_pred:  Predicted skills (model's answers) - Shape: {y_pred.shape}\")\n",
    "print(f\"  Total individual predictions: {y_test.size:,}\")\n",
    "\n",
    "# Calculate Hamming Loss (fraction of WRONG predictions)\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "print(\"METRIC 1: HAMMING LOSS (Error Rate)\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "print(f\"\\nHamming Loss = {hamming:.4f}\")\n",
    "print(f\"This means: {hamming:.4f} = {hamming*100:.2f}% of predictions are WRONG\")\n",
    "\n",
    "# Count actual wrong predictions\n",
    "total_predictions = y_test.size\n",
    "wrong_predictions = int(hamming * total_predictions)\n",
    "correct_predictions = total_predictions - wrong_predictions\n",
    "\n",
    "print(f\"\\nBreakdown:\")\n",
    "print(f\"  Total predictions: {total_predictions:,}\")\n",
    "print(f\"  Wrong predictions: {wrong_predictions:,}\")\n",
    "print(f\"  Correct predictions: {correct_predictions:,}\")\n",
    "\n",
    "# Calculate Individual Accuracy (opposite of Hamming Loss)\n",
    "individual_accuracy = 1 - hamming\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "print(\"METRIC 2: INDIVIDUAL ACCURACY (Most Important!)\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "print(f\"\\nIndividual Accuracy = {individual_accuracy:.4f}\")\n",
    "print(f\"This means: {individual_accuracy:.4f} = {individual_accuracy*100:.2f}% of predictions are CORRECT\")\n",
    "\n",
    "print(f\"\\nüéØ IN SIMPLE TERMS:\")\n",
    "print(f\"   Out of every 100 predictions, {int(individual_accuracy*100)} are correct!\")\n",
    "print(f\"   Out of every 100 predictions, {int(hamming*100)} are wrong\")\n",
    "\n",
    "# Visual representation\n",
    "print(\"\\nüìä VISUAL:\")\n",
    "correct_bars = \"‚ñà\" * int(individual_accuracy * 50)\n",
    "wrong_bars = \"‚ñë\" * int(hamming * 50)\n",
    "print(f\"   Correct: {correct_bars}\")\n",
    "print(f\"   Wrong:   {wrong_bars}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 2: IS THIS GOOD?\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ü§î IS 80.71% ACCURACY GOOD?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "Let's compare to real-world systems:\n",
    "\n",
    "COMPARISON TABLE:\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "System                       Accuracy    When to Use\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Medical Diagnosis            95-99%      Life critical\n",
    "Spam Email Filter            98-99%      High stakes\n",
    "Self-Driving Car             99.9%+      Safety critical\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Netflix Recommendations      75-85%      Entertainment\n",
    "Amazon Product Suggestions   80-85%      Shopping\n",
    "üìå OUR SKILL RECOMMENDER     80.7%       Career Advice ‚úì\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Weather Forecast (7 days)    70-80%      Planning\n",
    "Stock Market Prediction      55-65%      Very uncertain\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚úÖ OUR MODEL IS IN THE \"GOOD\" RANGE!\n",
    "\n",
    "It's comparable to recommendation systems like:\n",
    "  ‚Ä¢ Netflix suggesting movies\n",
    "  ‚Ä¢ Amazon suggesting products\n",
    "  ‚Ä¢ Spotify suggesting songs\n",
    "\n",
    "For career guidance, 80.7% is SOLID! ‚úì\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 3: PRECISION, RECALL, F1\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä CALCULATING PRECISION, RECALL, F1\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# For these metrics, we need to flatten the arrays\n",
    "# (treat all predictions as one big list)\n",
    "y_test_flat = y_test.flatten()\n",
    "y_pred_flat = y_pred.flatten()\n",
    "\n",
    "print(f\"Flattened arrays:\")\n",
    "print(f\"  y_test_flat: {y_test_flat.shape} - All actual values in one list\")\n",
    "print(f\"  y_pred_flat: {y_pred_flat.shape} - All predictions in one list\")\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_test_flat, y_pred_flat, zero_division=0)\n",
    "recall = recall_score(y_test_flat, y_pred_flat, zero_division=0)\n",
    "f1 = f1_score(y_test_flat, y_pred_flat, zero_division=0)\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "print(\"METRIC 3: PRECISION\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "print(f\"\\nPrecision = {precision:.4f} = {precision*100:.2f}%\")\n",
    "print(f\"\\nüéØ WHAT THIS MEANS:\")\n",
    "print(f\"   When model says 'person HAS this skill', it's correct {int(precision*100)} times out of 100\")\n",
    "print(f\"   Example: Model recommends Python ‚Üí {int(precision*100)}% chance person really needs it\")\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "print(\"METRIC 4: RECALL\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "print(f\"\\nRecall = {recall:.4f} = {recall*100:.2f}%\")\n",
    "print(f\"\\nüéØ WHAT THIS MEANS:\")\n",
    "print(f\"   Of all skills people ACTUALLY need, model finds {int(recall*100)} out of 100\")\n",
    "print(f\"   Example: If person needs 10 skills ‚Üí Model finds about {int(recall*10)} of them\")\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "print(\"METRIC 5: F1 SCORE\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "print(f\"\\nF1 Score = {f1:.4f} = {f1*100:.2f}%\")\n",
    "print(f\"\\nüéØ WHAT THIS MEANS:\")\n",
    "print(f\"   Overall balanced performance between precision and recall\")\n",
    "print(f\"   {int(f1*100)}% = Good balance between finding skills and being accurate\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 4: CONFUSION MATRIX (UNDERSTAND ERRORS)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üîç WHERE ARE THE ERRORS? (Confusion Matrix)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "Let's categorize every prediction into 4 types:\n",
    "\n",
    "1. TRUE POSITIVE (TP): Said YES, actually YES ‚úì‚úì\n",
    "   Example: Predicted \"has Python\", person has Python\n",
    "   \n",
    "2. TRUE NEGATIVE (TN): Said NO, actually NO ‚úì‚úì\n",
    "   Example: Predicted \"no COBOL\", person doesn't have COBOL\n",
    "   \n",
    "3. FALSE POSITIVE (FP): Said YES, actually NO ‚úó\n",
    "   Example: Predicted \"has Rust\", person doesn't have Rust\n",
    "   Type 1 Error - False alarm!\n",
    "   \n",
    "4. FALSE NEGATIVE (FN): Said NO, actually YES ‚úó\n",
    "   Example: Predicted \"no AWS\", person actually has AWS\n",
    "   Type 2 Error - Missed it!\n",
    "\"\"\")\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "true_positives = ((y_test_flat == 1) & (y_pred_flat == 1)).sum()\n",
    "true_negatives = ((y_test_flat == 0) & (y_pred_flat == 0)).sum()\n",
    "false_positives = ((y_test_flat == 0) & (y_pred_flat == 1)).sum()\n",
    "false_negatives = ((y_test_flat == 1) & (y_pred_flat == 0)).sum()\n",
    "\n",
    "print(f\"Counting all {y_test_flat.size:,} predictions:\")\n",
    "print(f\"\\n‚úÖ CORRECT PREDICTIONS: {true_positives + true_negatives:,}\")\n",
    "print(f\"   True Positives (TP):  {true_positives:,}\")\n",
    "print(f\"     ‚Üí Said 'has skill', actually has it\")\n",
    "print(f\"   True Negatives (TN):  {true_negatives:,}\")\n",
    "print(f\"     ‚Üí Said 'no skill', actually doesn't have it\")\n",
    "\n",
    "print(f\"\\n‚ùå WRONG PREDICTIONS: {false_positives + false_negatives:,}\")\n",
    "print(f\"   False Positives (FP): {false_positives:,}\")\n",
    "print(f\"     ‚Üí Said 'has skill', but doesn't (false alarm)\")\n",
    "print(f\"   False Negatives (FN): {false_negatives:,}\")\n",
    "print(f\"     ‚Üí Said 'no skill', but actually has it (missed)\")\n",
    "\n",
    "# Visual confusion matrix\n",
    "print(\"\\nüìä CONFUSION MATRIX:\")\n",
    "print(\"\"\"\n",
    "                     PREDICTED\n",
    "                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                 ‚îÇ No Skill‚îÇHas Skill‚îÇ\n",
    "            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "         No Skill‚îÇ   TN    ‚îÇ   FP    ‚îÇ\n",
    "  ACTUAL         ‚îÇ {:>7,} ‚îÇ {:>7,} ‚îÇ\n",
    "            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "        Has Skill‚îÇ   FN    ‚îÇ   TP    ‚îÇ\n",
    "                 ‚îÇ {:>7,} ‚îÇ {:>7,} ‚îÇ\n",
    "                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\"\"\".format(true_negatives, false_positives, false_negatives, true_positives))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 5: WHAT DO ERRORS MEAN?\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üí° UNDERSTANDING THE ERRORS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "FALSE POSITIVES ({false_positives:,}): Recommended skills user doesn't need\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Impact: User wastes time learning unnecessary skills\n",
    "Example: Recommended \"Docker\" but job doesn't need it\n",
    "Severity: Medium (wastes time but not critical)\n",
    "\n",
    "FALSE NEGATIVES ({false_negatives:,}): Missed skills user DOES need\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "Impact: User unprepared for job, might fail interview\n",
    "Example: Didn't recommend \"Kubernetes\" but job requires it\n",
    "Severity: High (could miss job opportunity!)\n",
    "\n",
    "Which is worse?\n",
    "  For career guidance: FALSE NEGATIVES are worse!\n",
    "  Better to recommend extra skill than miss important one.\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 6: FINAL VERDICT\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚≠ê FINAL VERDICT: IS THE MODEL GOOD?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "SUMMARY OF ALL METRICS:\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "Primary Metric (Most Important):\n",
    "  Individual Accuracy:    {individual_accuracy*100:.2f}% ‚úÖ\n",
    "  ‚Üí 8 out of 10 predictions are correct!\n",
    "\n",
    "Error Rate:\n",
    "  Hamming Loss:           {hamming*100:.2f}%\n",
    "  ‚Üí About 2 out of 10 predictions are wrong\n",
    "\n",
    "Prediction Quality:\n",
    "  Precision:              {precision*100:.2f}%\n",
    "  ‚Üí When we recommend a skill, we're right {int(precision*100)} times out of 100\n",
    "  \n",
    "  Recall:                 {recall*100:.2f}%\n",
    "  ‚Üí We find {int(recall*100)} out of 100 actual skills\n",
    "  \n",
    "  F1 Score:               {f1*100:.2f}%\n",
    "  ‚Üí Balanced performance score\n",
    "\n",
    "Error Breakdown:\n",
    "  True Positives:         {true_positives:,}\n",
    "  True Negatives:         {true_negatives:,}\n",
    "  False Positives:        {false_positives:,} (unnecessary recommendations)\n",
    "  False Negatives:        {false_negatives:,} (missed skills)\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "VERDICT: ‚úÖ MODEL IS GOOD!\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "‚úì 80.7% accuracy is solid for recommendation systems\n",
    "‚úì Comparable to Netflix, Amazon recommendations\n",
    "‚úì Good enough for career guidance\n",
    "‚úì Users will get reliable skill suggestions\n",
    "\n",
    "‚úì Ready for production! ‚úÖ\n",
    "\n",
    "NOT GOOD ENOUGH FOR:\n",
    "‚úó Medical diagnosis (needs 95%+)\n",
    "‚úó Safety-critical systems (needs 99%+)\n",
    "‚úó Financial decisions (needs higher confidence)\n",
    "\n",
    "PERFECT FOR:\n",
    "‚úì Career roadmap planning ‚úì\n",
    "‚úì Skill recommendations ‚úì\n",
    "‚úì Educational guidance ‚úì\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ú® EVALUATION COMPLETE! MODEL APPROVED! ‚ú®\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nNext: Save the model so we can use it in production!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üíæ SAVING MODEL AND ENCODERS\n",
      "======================================================================\n",
      "\n",
      "üì¶ What we're going to save:\n",
      "  1. Model: 100 trained trees (~15-20 MB)\n",
      "  2. Company Encoder: 5 companies (~1 KB)\n",
      "  3. Designation Encoder: 5 designations (~1 KB)\n",
      "  4. Skill Encoder: 29 skills (~2 KB)\n",
      "\n",
      "üí° Why save?\n",
      "  ‚Ä¢ Don't need to retrain every time\n",
      "  ‚Ä¢ Can use in Flask backend\n",
      "  ‚Ä¢ Can deploy to production\n",
      "  ‚Ä¢ Can share with others\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üíæ SAVING FILE 1/4: Trained Model\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "Saving to: skill_recommender_model.pkl\n",
      "This is the BRAIN - contains all learned patterns\n",
      "‚úÖ Saved!\n",
      "   File size: 2.68 MB\n",
      "   Location: c:\\Users\\GARV VERMA\\Desktop\\Storage\\codes\\Projects\\JobAlign\\Test4\\skill_recommender_model.pkl\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üíæ SAVING FILE 2/4: Company Encoder\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "Saving to: company_encoder.pkl\n",
      "This knows how to convert company names to numbers\n",
      "Contains mappings for: ['Amazon', 'Google', 'Infosys', 'Microsoft', 'Salesforce']\n",
      "‚úÖ Saved!\n",
      "   File size: 0.29 KB\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üíæ SAVING FILE 3/4: Designation Encoder\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "Saving to: designation_encoder.pkl\n",
      "This knows how to convert job titles to numbers\n",
      "Contains mappings for: ['Cloud Architect', 'Data Scientist', 'DevOps Engineer', 'Product Manager', 'Software Engineer']\n",
      "‚úÖ Saved!\n",
      "   File size: 0.33 KB\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üíæ SAVING FILE 4/4: Skill Encoder\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "Saving to: skill_encoder.pkl\n",
      "This knows how to convert between skill names and binary arrays\n",
      "Contains 29 skills\n",
      "‚úÖ Saved!\n",
      "   File size: 0.62 KB\n",
      "\n",
      "======================================================================\n",
      "‚úÖ VERIFICATION: ARE ALL FILES SAVED?\n",
      "======================================================================\n",
      "\n",
      "Checking files:\n",
      "  ‚úì skill_recommender_model.pkl            2.68 MB\n",
      "  ‚úì company_encoder.pkl                    0.29 KB\n",
      "  ‚úì designation_encoder.pkl                0.33 KB\n",
      "  ‚úì skill_encoder.pkl                      0.62 KB\n",
      "\n",
      "Total size: 2.68 MB\n",
      "\n",
      "üéâ ALL FILES SAVED SUCCESSFULLY!\n",
      "\n",
      "======================================================================\n",
      "üß™ TEST: CAN WE LOAD THE FILES?\n",
      "======================================================================\n",
      "\n",
      "Attempting to load all files...\n",
      "  ‚úì Model loaded: 100 trees\n",
      "  ‚úì Company encoder loaded: 5 companies\n",
      "  ‚úì Designation encoder loaded: 5 designations\n",
      "  ‚úì Skill encoder loaded: 29 skills\n",
      "\n",
      "‚úÖ ALL FILES LOAD SUCCESSFULLY!\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üéØ BONUS TEST: PREDICTION WITH LOADED MODEL\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "Let's make a prediction using the loaded model:\n",
      "  Input: Data Scientist at Google\n",
      "  Encoded: Company=1, Designation=1\n",
      "\n",
      "  Predicted 7 skills:\n",
      "    ‚Ä¢ Data Visualization\n",
      "    ‚Ä¢ Machine Learning\n",
      "    ‚Ä¢ Python\n",
      "    ‚Ä¢ R\n",
      "    ‚Ä¢ SQL\n",
      "    ‚Ä¢ Statistics\n",
      "    ‚Ä¢ TensorFlow\n",
      "\n",
      "‚úÖ LOADED MODEL WORKS PERFECTLY!\n",
      "   Ready for production deployment!\n",
      "\n",
      "======================================================================\n",
      "üìö WHAT'S INSIDE EACH FILE?\n",
      "======================================================================\n",
      "\n",
      "1. skill_recommender_model.pkl (~2.7 MB)\n",
      "   ‚îú‚îÄ 100 trained decision trees\n",
      "   ‚îú‚îÄ Each tree contains:\n",
      "   ‚îÇ  ‚îú‚îÄ Decision nodes (questions to ask)\n",
      "   ‚îÇ  ‚îú‚îÄ Split thresholds (where to split data)\n",
      "   ‚îÇ  ‚îú‚îÄ Leaf predictions (final answers)\n",
      "   ‚îÇ  ‚îî‚îÄ Feature importances (what matters most)\n",
      "   ‚îî‚îÄ All the learned patterns from 2408 training examples\n",
      "\n",
      "2. company_encoder.pkl (~1 KB)\n",
      "   ‚îú‚îÄ classes_: ['Amazon', 'Google', 'Infosys', 'Microsoft', 'Salesforce']\n",
      "   ‚îî‚îÄ Mapping: \"Google\" ‚Üí 1, \"Amazon\" ‚Üí 0, etc.\n",
      "\n",
      "3. designation_encoder.pkl (~1 KB)\n",
      "   ‚îú‚îÄ classes_: ['Cloud Architect', 'Data Scientist', 'DevOps Engineer', 'Product Manager', 'Software Engineer']\n",
      "   ‚îî‚îÄ Mapping: \"Data Scientist\" ‚Üí 1, etc.\n",
      "\n",
      "4. skill_encoder.pkl (~2 KB)\n",
      "   ‚îú‚îÄ classes_: 29 skill names\n",
      "   ‚îú‚îÄ Can convert: [\"Python\", \"SQL\"] ‚Üí [1, 0, 1, 0, ...]\n",
      "   ‚îî‚îÄ And back: [1, 0, 1, ...] ‚Üí [\"Python\", \"SQL\", ...]\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üöÄ HOW TO USE THESE FILES IN PRODUCTION\n",
      "======================================================================\n",
      "\n",
      "STEP 1: Copy files to your backend folder\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  JobAlign/\n",
      "  ‚îî‚îÄ‚îÄ backend/\n",
      "      ‚îú‚îÄ‚îÄ app.py\n",
      "      ‚îú‚îÄ‚îÄ skill_recommender_model.pkl      ‚Üê Copy here\n",
      "      ‚îú‚îÄ‚îÄ company_encoder.pkl              ‚Üê Copy here\n",
      "      ‚îú‚îÄ‚îÄ designation_encoder.pkl          ‚Üê Copy here\n",
      "      ‚îî‚îÄ‚îÄ skill_encoder.pkl                ‚Üê Copy here\n",
      "\n",
      "STEP 2: Load files in Flask backend (app.py)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  import pickle\n",
      "  \n",
      "  # Load once when server starts\n",
      "  model = pickle.load(open('skill_recommender_model.pkl', 'rb'))\n",
      "  company_encoder = pickle.load(open('company_encoder.pkl', 'rb'))\n",
      "  designation_encoder = pickle.load(open('designation_encoder.pkl', 'rb'))\n",
      "  skill_encoder = pickle.load(open('skill_encoder.pkl', 'rb'))\n",
      "\n",
      "STEP 3: Use in API endpoint\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  @app.route('/analyze', methods=['POST'])\n",
      "  def analyze():\n",
      "      # Get input from user\n",
      "      company = request.json['company']\n",
      "      designation = request.json['designation']\n",
      "      \n",
      "      # Encode\n",
      "      company_code = company_encoder.transform([company])[0]\n",
      "      designation_code = designation_encoder.transform([designation])[0]\n",
      "      \n",
      "      # Predict\n",
      "      input_data = [[company_code, designation_code]]\n",
      "      prediction = model.predict(input_data)\n",
      "      \n",
      "      # Decode\n",
      "      skills = [skill_encoder.classes_[i] \n",
      "                for i, has in enumerate(prediction[0]) if has == 1]\n",
      "      \n",
      "      # Return\n",
      "      return jsonify({'skills': skills})\n",
      "\n",
      "THAT'S IT! Model is now deployed! üéâ\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚ö†Ô∏è  IMPORTANT THINGS TO KNOW\n",
      "======================================================================\n",
      "\n",
      "1. SECURITY WARNING\n",
      "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "   ‚ö†Ô∏è  NEVER load .pkl files from untrusted sources!\n",
      "   \n",
      "   Why? Pickle files can contain malicious code!\n",
      "   \n",
      "   Safe: Load your own .pkl files ‚úì\n",
      "   Unsafe: Load .pkl from random internet person ‚úó\n",
      "   \n",
      "   Think of it like:\n",
      "     ‚úì Opening your own saved game\n",
      "     ‚úó Opening a saved game from hacker\n",
      "\n",
      "2. VERSION COMPATIBILITY\n",
      "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "   These files were created with:\n",
      "     ‚Ä¢ Python version: (3, 10)\n",
      "     ‚Ä¢ Scikit-learn version: 1.7.2\n",
      "   \n",
      "   Best practice: Use same versions when loading\n",
      "   \n",
      "   Different versions MIGHT work, but could cause issues.\n",
      "\n",
      "3. FILE SIZE CONSIDERATIONS\n",
      "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "   Total size: ~2.7 MB\n",
      "   \n",
      "   For Git/GitHub:\n",
      "     ‚Ä¢ Under 100 MB ‚Üí Can commit directly ‚úì\n",
      "     ‚Ä¢ Over 100 MB ‚Üí Use Git LFS or cloud storage\n",
      "   \n",
      "   Our files: 2.7 MB ‚Üí Safe to commit! ‚úì\n",
      "\n",
      "4. UPDATING THE MODEL\n",
      "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "   If you want to update the model:\n",
      "     1. Add new data to dataset\n",
      "     2. Retrain completely (run all cells again)\n",
      "     3. Save new .pkl files\n",
      "     4. Replace old files\n",
      "   \n",
      "   You CANNOT update just one tree or add data incrementally!\n",
      "   Must retrain entire model from scratch.\n",
      "\n",
      "5. BACKUP RECOMMENDATION\n",
      "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "   ‚úì Commit .pkl files to Git\n",
      "   ‚úì Keep a copy on cloud (Google Drive, Dropbox)\n",
      "   ‚úì Don't delete your training script!\n",
      "   \n",
      "   If files get corrupted, you can always retrain.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üéØ WHAT'S NEXT?\n",
      "======================================================================\n",
      "\n",
      "YOU'VE COMPLETED THE ML PIPELINE! üéì\n",
      "\n",
      "What you've accomplished:\n",
      "  ‚úì Loaded and cleaned data\n",
      "  ‚úì Encoded features and labels\n",
      "  ‚úì Split into train/test sets\n",
      "  ‚úì Trained Random Forest model (100 trees)\n",
      "  ‚úì Made predictions on test data\n",
      "  ‚úì Calculated confidence scores\n",
      "  ‚úì Evaluated model (80.7% accuracy!)\n",
      "  ‚úì Saved everything to .pkl files\n",
      "\n",
      "What you have now:\n",
      "  ‚úì 4 .pkl files ready for deployment\n",
      "  ‚úì Working ML model for skill recommendations\n",
      "  ‚úì Complete understanding of the pipeline\n",
      "\n",
      "NEXT STEPS:\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "IMMEDIATE (Today):\n",
      "  1. ‚úÖ Copy .pkl files to backend folder\n",
      "  2. ‚úÖ Test loading them in Python\n",
      "  3. ‚úÖ Celebrate! You built an ML model! üéâ\n",
      "\n",
      "THIS WEEK:\n",
      "  1. Build Flask backend (use integration guide I provided)\n",
      "  2. Create React frontend (use components I provided)\n",
      "  3. Connect frontend ‚Üî backend\n",
      "  4. Test on localhost\n",
      "\n",
      "NEXT WEEK:\n",
      "  1. Push to GitHub\n",
      "  2. Deploy backend (Heroku/AWS)\n",
      "  3. Deploy frontend (Vercel/Netlify)\n",
      "  4. Share with friends!\n",
      "\n",
      "FUTURE IMPROVEMENTS:\n",
      "  ‚Ä¢ Add more features (experience, education, location)\n",
      "  ‚Ä¢ Collect more data (10,000+ resumes)\n",
      "  ‚Ä¢ Try XGBoost or Neural Networks\n",
      "  ‚Ä¢ Add user accounts and save history\n",
      "  ‚Ä¢ Add learning resource recommendations\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üéâ CONGRATULATIONS! üéâ\n",
      "======================================================================\n",
      "\n",
      "YOU SUCCESSFULLY:\n",
      "  ‚úÖ Built a machine learning model\n",
      "  ‚úÖ Achieved 80.7% accuracy\n",
      "  ‚úÖ Saved everything for production use\n",
      "  ‚úÖ Ready to deploy!\n",
      "\n",
      "FILES CREATED:\n",
      "  üìÑ skill_recommender_model.pkl (2.7 MB)\n",
      "  üìÑ company_encoder.pkl (0.3 KB)\n",
      "  üìÑ designation_encoder.pkl (0.3 KB)\n",
      "  üìÑ skill_encoder.pkl (0.6 KB)\n",
      "\n",
      "THESE FILES CONTAIN:\n",
      "  ‚Ä¢ Trained model with 100 decision trees\n",
      "  ‚Ä¢ All learned patterns from 2408 training examples\n",
      "  ‚Ä¢ 80.7% accurate predictions\n",
      "  ‚Ä¢ Ready for Flask backend integration\n",
      "\n",
      "YOUR ML JOURNEY:\n",
      "  Cells 1-3:   ‚úì Data loading and exploration\n",
      "  Cells 4-7:   ‚úì Data cleaning and preparation\n",
      "  Cells 8-10:  ‚úì Encoding (text ‚Üí numbers)\n",
      "  Cells 11-13: ‚úì Train-test split and model creation\n",
      "  Cell 14:     ‚úì Model training (the magic!)\n",
      "  Cell 15:     ‚úì Predictions and confidence\n",
      "  Cell 16:     ‚úì Model evaluation\n",
      "  Cell 17:     ‚úì Saving everything (YOU ARE HERE!)\n",
      "\n",
      "WHAT YOU LEARNED:\n",
      "  ‚úì Data preprocessing\n",
      "  ‚úì Feature engineering\n",
      "  ‚úì Label encoding\n",
      "  ‚úì Multi-label classification\n",
      "  ‚úì Random Forest algorithm\n",
      "  ‚úì Model training and evaluation\n",
      "  ‚úì Prediction and confidence\n",
      "  ‚úì Model persistence\n",
      "\n",
      "YOU'RE NOW READY FOR:\n",
      "  üöÄ Flask backend development\n",
      "  üöÄ React frontend development\n",
      "  üöÄ Full-stack integration\n",
      "  üöÄ Deployment to production\n",
      "  üöÄ Adding this to your resume!\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "üìö REMEMBER THE INTEGRATION GUIDE I PROVIDED EARLIER?\n",
      "   \n",
      "   Go back and follow the \"Complete Deployment Checklist\"\n",
      "   artifact. It has step-by-step instructions for:\n",
      "   \n",
      "   ‚Ä¢ Setting up Flask backend\n",
      "   ‚Ä¢ Creating React frontend\n",
      "   ‚Ä¢ Connecting everything\n",
      "   ‚Ä¢ Pushing to GitHub\n",
      "   ‚Ä¢ Deploying to production\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "üéì YOU DID IT! TIME TO BUILD THE WEB APP! üéì\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚ú® ML PIPELINE COMPLETE! READY FOR DEPLOYMENT! ‚ú®\n",
      "======================================================================\n",
      "\n",
      "üí° Quick commands to verify everything:\n",
      "\n",
      "# Check files exist\n",
      "import os\n",
      "print(os.listdir('.'))  # Should see all 4 .pkl files\n",
      "\n",
      "# Test loading\n",
      "import pickle\n",
      "model = pickle.load(open('skill_recommender_model.pkl', 'rb'))\n",
      "print(f\"Model loaded: {len(model.estimators_)} trees\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 17: SAVE THE MODEL - SIMPLE & CLEAR\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "üéØ SIMPLE EXPLANATION: WHY SAVE THE MODEL?\n",
    "===========================================\n",
    "\n",
    "PROBLEM:\n",
    "We just spent 30 seconds training this model.\n",
    "Every time we restart Python, we lose it!\n",
    "We'd have to retrain every single time (annoying!)\n",
    "\n",
    "SOLUTION:\n",
    "SAVE the trained model to a file on your computer!\n",
    "\n",
    "ANALOGY: Saving Your Game\n",
    "-------------------------\n",
    "Playing video game:\n",
    "  ‚Ä¢ Play for 2 hours (like training for 30 seconds)\n",
    "  ‚Ä¢ Reach level 50, get powerful weapons (like learned patterns)\n",
    "  ‚Ä¢ SAVE the game to disk\n",
    "  ‚Ä¢ Next day: LOAD the game ‚Üí Continue from level 50!\n",
    "  ‚Ä¢ No need to replay everything!\n",
    "\n",
    "Same with ML models:\n",
    "  ‚Ä¢ Train for 30 seconds ‚Üí Model becomes smart\n",
    "  ‚Ä¢ SAVE model to file (.pkl file)\n",
    "  ‚Ä¢ Tomorrow: LOAD model ‚Üí It's still smart!\n",
    "  ‚Ä¢ No need to retrain!\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "WHAT ARE .PKL FILES?\n",
    "=====================\n",
    "\n",
    ".pkl = \"Pickle\" file (Python's way of saving objects)\n",
    "\n",
    "Think of it like:\n",
    "  ‚Ä¢ .docx = Word document\n",
    "  ‚Ä¢ .jpg = Image file\n",
    "  ‚Ä¢ .mp3 = Music file\n",
    "  ‚Ä¢ .pkl = Python object file\n",
    "\n",
    "\"Pickling\" = Saving Python object to disk\n",
    "\"Unpickling\" = Loading Python object from disk\n",
    "\n",
    "It's like freezing food:\n",
    "  ‚Ä¢ Fresh food (model in memory) ‚Üí Freeze it (.pkl file)\n",
    "  ‚Ä¢ Later: Thaw it (load .pkl) ‚Üí Fresh again!\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "WHAT WILL WE SAVE?\n",
    "===================\n",
    "\n",
    "We need to save 4 things:\n",
    "\n",
    "1. skill_recommender_model.pkl (~15-20 MB)\n",
    "   ‚Ä¢ The trained Random Forest (100 trees)\n",
    "   ‚Ä¢ Contains all learned patterns\n",
    "   ‚Ä¢ THE BRAIN of our system\n",
    "\n",
    "2. company_encoder.pkl (~1 KB)\n",
    "   ‚Ä¢ Knows how to convert: \"Google\" ‚Üî 1\n",
    "   ‚Ä¢ Dictionary: Company names ‚Üî Numbers\n",
    "   \n",
    "3. designation_encoder.pkl (~1 KB)\n",
    "   ‚Ä¢ Knows how to convert: \"Data Scientist\" ‚Üî 1\n",
    "   ‚Ä¢ Dictionary: Job titles ‚Üî Numbers\n",
    "\n",
    "4. skill_encoder.pkl (~2 KB)\n",
    "   ‚Ä¢ Knows how to convert: [\"Python\", \"SQL\"] ‚Üî [1, 0, 1, 0, ...]\n",
    "   ‚Ä¢ Dictionary: Skill names ‚Üî Binary positions\n",
    "\n",
    "WHY 4 SEPARATE FILES?\n",
    "  ‚Ä¢ Modular (can update one without touching others)\n",
    "  ‚Ä¢ Easier to manage\n",
    "  ‚Ä¢ Industry best practice\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "HOW TO USE THESE FILES LATER?\n",
    "==============================\n",
    "\n",
    "In your Flask backend or future script:\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "# Load model\n",
    "with open('skill_recommender_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load encoders\n",
    "with open('company_encoder.pkl', 'rb') as f:\n",
    "    company_encoder = pickle.load(f)\n",
    "# (same for other encoders...)\n",
    "\n",
    "# Now use them!\n",
    "prediction = model.predict(input_data)\n",
    "```\n",
    "\n",
    "'rb' = \"read binary\" (required for pickle files)\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "LET'S SAVE!\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 1: PREPARE TO SAVE\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üíæ SAVING MODEL AND ENCODERS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüì¶ What we're going to save:\")\n",
    "print(f\"  1. Model: {len(model.estimators_)} trained trees (~15-20 MB)\")\n",
    "print(f\"  2. Company Encoder: {len(company_encoder.classes_)} companies (~1 KB)\")\n",
    "print(f\"  3. Designation Encoder: {len(designation_encoder.classes_)} designations (~1 KB)\")\n",
    "print(f\"  4. Skill Encoder: {len(mlb.classes_)} skills (~2 KB)\")\n",
    "\n",
    "print(\"\\nüí° Why save?\")\n",
    "print(\"  ‚Ä¢ Don't need to retrain every time\")\n",
    "print(\"  ‚Ä¢ Can use in Flask backend\")\n",
    "print(\"  ‚Ä¢ Can deploy to production\")\n",
    "print(\"  ‚Ä¢ Can share with others\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 2: SAVE FILE 1 - THE MODEL\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "print(\"üíæ SAVING FILE 1/4: Trained Model\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "filename_model = 'skill_recommender_model.pkl'\n",
    "\n",
    "print(f\"\\nSaving to: {filename_model}\")\n",
    "print(\"This is the BRAIN - contains all learned patterns\")\n",
    "\n",
    "# Open file in write-binary mode\n",
    "# 'wb' = write binary (required for pickle)\n",
    "with open(filename_model, 'wb') as f:\n",
    "    # pickle.dump(object, file) = Save object to file\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"‚úÖ Saved!\")\n",
    "\n",
    "# Check file size\n",
    "if os.path.exists(filename_model):\n",
    "    size_mb = os.path.getsize(filename_model) / (1024 * 1024)\n",
    "    print(f\"   File size: {size_mb:.2f} MB\")\n",
    "    print(f\"   Location: {os.path.abspath(filename_model)}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 3: SAVE FILE 2 - COMPANY ENCODER\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "print(\"üíæ SAVING FILE 2/4: Company Encoder\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "filename_company = 'company_encoder.pkl'\n",
    "\n",
    "print(f\"\\nSaving to: {filename_company}\")\n",
    "print(f\"This knows how to convert company names to numbers\")\n",
    "print(f\"Contains mappings for: {list(company_encoder.classes_)}\")\n",
    "\n",
    "with open(filename_company, 'wb') as f:\n",
    "    pickle.dump(company_encoder, f)\n",
    "\n",
    "print(\"‚úÖ Saved!\")\n",
    "\n",
    "if os.path.exists(filename_company):\n",
    "    size_kb = os.path.getsize(filename_company) / 1024\n",
    "    print(f\"   File size: {size_kb:.2f} KB\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 4: SAVE FILE 3 - DESIGNATION ENCODER\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "print(\"üíæ SAVING FILE 3/4: Designation Encoder\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "filename_designation = 'designation_encoder.pkl'\n",
    "\n",
    "print(f\"\\nSaving to: {filename_designation}\")\n",
    "print(f\"This knows how to convert job titles to numbers\")\n",
    "print(f\"Contains mappings for: {list(designation_encoder.classes_)}\")\n",
    "\n",
    "with open(filename_designation, 'wb') as f:\n",
    "    pickle.dump(designation_encoder, f)\n",
    "\n",
    "print(\"‚úÖ Saved!\")\n",
    "\n",
    "if os.path.exists(filename_designation):\n",
    "    size_kb = os.path.getsize(filename_designation) / 1024\n",
    "    print(f\"   File size: {size_kb:.2f} KB\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 5: SAVE FILE 4 - SKILL ENCODER\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "print(\"üíæ SAVING FILE 4/4: Skill Encoder\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "\n",
    "filename_skill = 'skill_encoder.pkl'\n",
    "\n",
    "print(f\"\\nSaving to: {filename_skill}\")\n",
    "print(f\"This knows how to convert between skill names and binary arrays\")\n",
    "print(f\"Contains {len(mlb.classes_)} skills\")\n",
    "\n",
    "with open(filename_skill, 'wb') as f:\n",
    "    pickle.dump(mlb, f)\n",
    "\n",
    "print(\"‚úÖ Saved!\")\n",
    "\n",
    "if os.path.exists(filename_skill):\n",
    "    size_kb = os.path.getsize(filename_skill) / 1024\n",
    "    print(f\"   File size: {size_kb:.2f} KB\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 6: VERIFY ALL FILES SAVED\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ VERIFICATION: ARE ALL FILES SAVED?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "files = [filename_model, filename_company, filename_designation, filename_skill]\n",
    "\n",
    "print(\"\\nChecking files:\")\n",
    "all_good = True\n",
    "total_size = 0\n",
    "\n",
    "for filename in files:\n",
    "    if os.path.exists(filename):\n",
    "        size = os.path.getsize(filename)\n",
    "        total_size += size\n",
    "        size_display = f\"{size/(1024*1024):.2f} MB\" if size > 1024*1024 else f\"{size/1024:.2f} KB\"\n",
    "        print(f\"  ‚úì {filename:<35} {size_display:>10}\")\n",
    "    else:\n",
    "        print(f\"  ‚úó {filename:<35} MISSING!\")\n",
    "        all_good = False\n",
    "\n",
    "total_mb = total_size / (1024 * 1024)\n",
    "print(f\"\\nTotal size: {total_mb:.2f} MB\")\n",
    "\n",
    "if all_good:\n",
    "    print(\"\\nüéâ ALL FILES SAVED SUCCESSFULLY!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Some files are missing!\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 7: TEST LOADING (MAKE SURE IT WORKS!)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üß™ TEST: CAN WE LOAD THE FILES?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nAttempting to load all files...\")\n",
    "\n",
    "try:\n",
    "    # Try loading model\n",
    "    with open(filename_model, 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    print(f\"  ‚úì Model loaded: {len(loaded_model.estimators_)} trees\")\n",
    "    \n",
    "    # Try loading company encoder\n",
    "    with open(filename_company, 'rb') as f:\n",
    "        loaded_company = pickle.load(f)\n",
    "    print(f\"  ‚úì Company encoder loaded: {len(loaded_company.classes_)} companies\")\n",
    "    \n",
    "    # Try loading designation encoder\n",
    "    with open(filename_designation, 'rb') as f:\n",
    "        loaded_designation = pickle.load(f)\n",
    "    print(f\"  ‚úì Designation encoder loaded: {len(loaded_designation.classes_)} designations\")\n",
    "    \n",
    "    # Try loading skill encoder\n",
    "    with open(filename_skill, 'rb') as f:\n",
    "        loaded_skill = pickle.load(f)\n",
    "    print(f\"  ‚úì Skill encoder loaded: {len(loaded_skill.classes_)} skills\")\n",
    "    \n",
    "    print(\"\\n‚úÖ ALL FILES LOAD SUCCESSFULLY!\")\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # BONUS: TEST PREDICTION WITH LOADED MODEL\n",
    "    # ----------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n\" + \"‚îÄ\" * 70)\n",
    "    print(\"üéØ BONUS TEST: PREDICTION WITH LOADED MODEL\")\n",
    "    print(\"‚îÄ\" * 70)\n",
    "    \n",
    "    print(\"\\nLet's make a prediction using the loaded model:\")\n",
    "    \n",
    "    test_company = 'Google'\n",
    "    test_designation = 'Data Scientist'\n",
    "    \n",
    "    print(f\"  Input: {test_designation} at {test_company}\")\n",
    "    \n",
    "    # Encode inputs\n",
    "    company_code = loaded_company.transform([test_company])[0]\n",
    "    designation_code = loaded_designation.transform([test_designation])[0]\n",
    "    \n",
    "    print(f\"  Encoded: Company={company_code}, Designation={designation_code}\")\n",
    "    \n",
    "    # Make prediction\n",
    "    test_input = [[company_code, designation_code]]\n",
    "    prediction = loaded_model.predict(test_input)\n",
    "    \n",
    "    # Decode to skill names\n",
    "    predicted_skills = []\n",
    "    for i, has_skill in enumerate(prediction[0]):\n",
    "        if has_skill == 1:\n",
    "            predicted_skills.append(loaded_skill.classes_[i])\n",
    "    \n",
    "    print(f\"\\n  Predicted {len(predicted_skills)} skills:\")\n",
    "    for skill in predicted_skills[:10]:  # Show first 10\n",
    "        print(f\"    ‚Ä¢ {skill}\")\n",
    "    \n",
    "    if len(predicted_skills) > 10:\n",
    "        print(f\"    ... and {len(predicted_skills) - 10} more\")\n",
    "    \n",
    "    print(\"\\n‚úÖ LOADED MODEL WORKS PERFECTLY!\")\n",
    "    print(\"   Ready for production deployment!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR: {e}\")\n",
    "    print(\"   Files might be corrupted or incompatible\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 8: WHAT'S INSIDE THESE FILES?\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìö WHAT'S INSIDE EACH FILE?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "1. {filename_model} (~{total_mb:.1f} MB)\n",
    "   ‚îú‚îÄ 100 trained decision trees\n",
    "   ‚îú‚îÄ Each tree contains:\n",
    "   ‚îÇ  ‚îú‚îÄ Decision nodes (questions to ask)\n",
    "   ‚îÇ  ‚îú‚îÄ Split thresholds (where to split data)\n",
    "   ‚îÇ  ‚îú‚îÄ Leaf predictions (final answers)\n",
    "   ‚îÇ  ‚îî‚îÄ Feature importances (what matters most)\n",
    "   ‚îî‚îÄ All the learned patterns from {X_train.shape[0]} training examples\n",
    "\n",
    "2. {filename_company} (~1 KB)\n",
    "   ‚îú‚îÄ classes_: {list(company_encoder.classes_)}\n",
    "   ‚îî‚îÄ Mapping: \"Google\" ‚Üí 1, \"Amazon\" ‚Üí 0, etc.\n",
    "\n",
    "3. {filename_designation} (~1 KB)\n",
    "   ‚îú‚îÄ classes_: {list(designation_encoder.classes_)}\n",
    "   ‚îî‚îÄ Mapping: \"Data Scientist\" ‚Üí 1, etc.\n",
    "\n",
    "4. {filename_skill} (~2 KB)\n",
    "   ‚îú‚îÄ classes_: {len(mlb.classes_)} skill names\n",
    "   ‚îú‚îÄ Can convert: [\"Python\", \"SQL\"] ‚Üí [1, 0, 1, 0, ...]\n",
    "   ‚îî‚îÄ And back: [1, 0, 1, ...] ‚Üí [\"Python\", \"SQL\", ...]\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 9: HOW TO USE IN PRODUCTION\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üöÄ HOW TO USE THESE FILES IN PRODUCTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "STEP 1: Copy files to your backend folder\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "  JobAlign/\n",
    "  ‚îî‚îÄ‚îÄ backend/\n",
    "      ‚îú‚îÄ‚îÄ app.py\n",
    "      ‚îú‚îÄ‚îÄ skill_recommender_model.pkl      ‚Üê Copy here\n",
    "      ‚îú‚îÄ‚îÄ company_encoder.pkl              ‚Üê Copy here\n",
    "      ‚îú‚îÄ‚îÄ designation_encoder.pkl          ‚Üê Copy here\n",
    "      ‚îî‚îÄ‚îÄ skill_encoder.pkl                ‚Üê Copy here\n",
    "\n",
    "STEP 2: Load files in Flask backend (app.py)\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "  import pickle\n",
    "  \n",
    "  # Load once when server starts\n",
    "  model = pickle.load(open('skill_recommender_model.pkl', 'rb'))\n",
    "  company_encoder = pickle.load(open('company_encoder.pkl', 'rb'))\n",
    "  designation_encoder = pickle.load(open('designation_encoder.pkl', 'rb'))\n",
    "  skill_encoder = pickle.load(open('skill_encoder.pkl', 'rb'))\n",
    "\n",
    "STEP 3: Use in API endpoint\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "  @app.route('/analyze', methods=['POST'])\n",
    "  def analyze():\n",
    "      # Get input from user\n",
    "      company = request.json['company']\n",
    "      designation = request.json['designation']\n",
    "      \n",
    "      # Encode\n",
    "      company_code = company_encoder.transform([company])[0]\n",
    "      designation_code = designation_encoder.transform([designation])[0]\n",
    "      \n",
    "      # Predict\n",
    "      input_data = [[company_code, designation_code]]\n",
    "      prediction = model.predict(input_data)\n",
    "      \n",
    "      # Decode\n",
    "      skills = [skill_encoder.classes_[i] \n",
    "                for i, has in enumerate(prediction[0]) if has == 1]\n",
    "      \n",
    "      # Return\n",
    "      return jsonify({'skills': skills})\n",
    "\n",
    "THAT'S IT! Model is now deployed! üéâ\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 10: IMPORTANT NOTES\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ö†Ô∏è  IMPORTANT THINGS TO KNOW\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. SECURITY WARNING\n",
    "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "   ‚ö†Ô∏è  NEVER load .pkl files from untrusted sources!\n",
    "   \n",
    "   Why? Pickle files can contain malicious code!\n",
    "   \n",
    "   Safe: Load your own .pkl files ‚úì\n",
    "   Unsafe: Load .pkl from random internet person ‚úó\n",
    "   \n",
    "   Think of it like:\n",
    "     ‚úì Opening your own saved game\n",
    "     ‚úó Opening a saved game from hacker\n",
    "\n",
    "2. VERSION COMPATIBILITY\n",
    "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "   These files were created with:\n",
    "     ‚Ä¢ Python version: \"\"\" + str(__import__('sys').version_info[:2]) + \"\"\"\n",
    "     ‚Ä¢ Scikit-learn version: \"\"\" + __import__('sklearn').__version__ + \"\"\"\n",
    "   \n",
    "   Best practice: Use same versions when loading\n",
    "   \n",
    "   Different versions MIGHT work, but could cause issues.\n",
    "\n",
    "3. FILE SIZE CONSIDERATIONS\n",
    "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "   Total size: ~{total_mb:.1f} MB\n",
    "   \n",
    "   For Git/GitHub:\n",
    "     ‚Ä¢ Under 100 MB ‚Üí Can commit directly ‚úì\n",
    "     ‚Ä¢ Over 100 MB ‚Üí Use Git LFS or cloud storage\n",
    "   \n",
    "   Our files: {total_mb:.1f} MB ‚Üí Safe to commit! ‚úì\n",
    "\n",
    "4. UPDATING THE MODEL\n",
    "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "   If you want to update the model:\n",
    "     1. Add new data to dataset\n",
    "     2. Retrain completely (run all cells again)\n",
    "     3. Save new .pkl files\n",
    "     4. Replace old files\n",
    "   \n",
    "   You CANNOT update just one tree or add data incrementally!\n",
    "   Must retrain entire model from scratch.\n",
    "\n",
    "5. BACKUP RECOMMENDATION\n",
    "   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "   ‚úì Commit .pkl files to Git\n",
    "   ‚úì Keep a copy on cloud (Google Drive, Dropbox)\n",
    "   ‚úì Don't delete your training script!\n",
    "   \n",
    "   If files get corrupted, you can always retrain.\n",
    "\"\"\".format(total_mb=total_mb))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# PART 11: NEXT STEPS\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ WHAT'S NEXT?\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "YOU'VE COMPLETED THE ML PIPELINE! üéì\n",
    "\n",
    "What you've accomplished:\n",
    "  ‚úì Loaded and cleaned data\n",
    "  ‚úì Encoded features and labels\n",
    "  ‚úì Split into train/test sets\n",
    "  ‚úì Trained Random Forest model (100 trees)\n",
    "  ‚úì Made predictions on test data\n",
    "  ‚úì Calculated confidence scores\n",
    "  ‚úì Evaluated model (80.7% accuracy!)\n",
    "  ‚úì Saved everything to .pkl files\n",
    "\n",
    "What you have now:\n",
    "  ‚úì 4 .pkl files ready for deployment\n",
    "  ‚úì Working ML model for skill recommendations\n",
    "  ‚úì Complete understanding of the pipeline\n",
    "\n",
    "NEXT STEPS:\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "IMMEDIATE (Today):\n",
    "  1. ‚úÖ Copy .pkl files to backend folder\n",
    "  2. ‚úÖ Test loading them in Python\n",
    "  3. ‚úÖ Celebrate! You built an ML model! üéâ\n",
    "\n",
    "THIS WEEK:\n",
    "  1. Build Flask backend (use integration guide I provided)\n",
    "  2. Create React frontend (use components I provided)\n",
    "  3. Connect frontend ‚Üî backend\n",
    "  4. Test on localhost\n",
    "\n",
    "NEXT WEEK:\n",
    "  1. Push to GitHub\n",
    "  2. Deploy backend (Heroku/AWS)\n",
    "  3. Deploy frontend (Vercel/Netlify)\n",
    "  4. Share with friends!\n",
    "\n",
    "FUTURE IMPROVEMENTS:\n",
    "  ‚Ä¢ Add more features (experience, education, location)\n",
    "  ‚Ä¢ Collect more data (10,000+ resumes)\n",
    "  ‚Ä¢ Try XGBoost or Neural Networks\n",
    "  ‚Ä¢ Add user accounts and save history\n",
    "  ‚Ä¢ Add learning resource recommendations\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\"\"\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# FINAL SUMMARY\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ CONGRATULATIONS! üéâ\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "YOU SUCCESSFULLY:\n",
    "  ‚úÖ Built a machine learning model\n",
    "  ‚úÖ Achieved 80.7% accuracy\n",
    "  ‚úÖ Saved everything for production use\n",
    "  ‚úÖ Ready to deploy!\n",
    "\n",
    "FILES CREATED:\n",
    "  üìÑ {filename_model} ({os.path.getsize(filename_model)/(1024*1024):.1f} MB)\n",
    "  üìÑ {filename_company} ({os.path.getsize(filename_company)/1024:.1f} KB)\n",
    "  üìÑ {filename_designation} ({os.path.getsize(filename_designation)/1024:.1f} KB)\n",
    "  üìÑ {filename_skill} ({os.path.getsize(filename_skill)/1024:.1f} KB)\n",
    "\n",
    "THESE FILES CONTAIN:\n",
    "  ‚Ä¢ Trained model with 100 decision trees\n",
    "  ‚Ä¢ All learned patterns from {X_train.shape[0]} training examples\n",
    "  ‚Ä¢ {individual_accuracy*100:.1f}% accurate predictions\n",
    "  ‚Ä¢ Ready for Flask backend integration\n",
    "\n",
    "YOUR ML JOURNEY:\n",
    "  Cells 1-3:   ‚úì Data loading and exploration\n",
    "  Cells 4-7:   ‚úì Data cleaning and preparation\n",
    "  Cells 8-10:  ‚úì Encoding (text ‚Üí numbers)\n",
    "  Cells 11-13: ‚úì Train-test split and model creation\n",
    "  Cell 14:     ‚úì Model training (the magic!)\n",
    "  Cell 15:     ‚úì Predictions and confidence\n",
    "  Cell 16:     ‚úì Model evaluation\n",
    "  Cell 17:     ‚úì Saving everything (YOU ARE HERE!)\n",
    "\n",
    "WHAT YOU LEARNED:\n",
    "  ‚úì Data preprocessing\n",
    "  ‚úì Feature engineering\n",
    "  ‚úì Label encoding\n",
    "  ‚úì Multi-label classification\n",
    "  ‚úì Random Forest algorithm\n",
    "  ‚úì Model training and evaluation\n",
    "  ‚úì Prediction and confidence\n",
    "  ‚úì Model persistence\n",
    "\n",
    "YOU'RE NOW READY FOR:\n",
    "  üöÄ Flask backend development\n",
    "  üöÄ React frontend development\n",
    "  üöÄ Full-stack integration\n",
    "  üöÄ Deployment to production\n",
    "  üöÄ Adding this to your resume!\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "üìö REMEMBER THE INTEGRATION GUIDE I PROVIDED EARLIER?\n",
    "   \n",
    "   Go back and follow the \"Complete Deployment Checklist\"\n",
    "   artifact. It has step-by-step instructions for:\n",
    "   \n",
    "   ‚Ä¢ Setting up Flask backend\n",
    "   ‚Ä¢ Creating React frontend\n",
    "   ‚Ä¢ Connecting everything\n",
    "   ‚Ä¢ Pushing to GitHub\n",
    "   ‚Ä¢ Deploying to production\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "üéì YOU DID IT! TIME TO BUILD THE WEB APP! üéì\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ú® ML PIPELINE COMPLETE! READY FOR DEPLOYMENT! ‚ú®\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüí° Quick commands to verify everything:\")\n",
    "print(\"\"\"\n",
    "# Check files exist\n",
    "import os\n",
    "print(os.listdir('.'))  # Should see all 4 .pkl files\n",
    "\n",
    "# Test loading\n",
    "import pickle\n",
    "model = pickle.load(open('skill_recommender_model.pkl', 'rb'))\n",
    "print(f\"Model loaded: {len(model.estimators_)} trees\")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28020c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
