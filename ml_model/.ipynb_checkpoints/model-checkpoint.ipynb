{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47220a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('resume_dataset_large.csv')\n",
    "# Shape: (5000, 5) - Company, Designation, Skills, Achievements, Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa1c0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove whitespace and quotes\n",
    "df.columns = df.columns.str.strip()\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].str.strip().str.replace('\"', '')\n",
    "\n",
    "# Filter only accepted candidates\n",
    "df = df[df['Status'].str.lower() == 'accepted']  # 5000 ‚Üí 3010 records\n",
    "\n",
    "# Remove missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90770e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Company', 'Designation']].copy()\n",
    "# Shape: (3010, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "455c9865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3010, 5)\n",
      "Columns: Index(['Company', 'Designation', 'Skills', 'Achievements', 'Status'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3010 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Company       3010 non-null   object\n",
      " 1   Designation   3010 non-null   object\n",
      " 2   Skills        3010 non-null   object\n",
      " 3   Achievements  3010 non-null   object\n",
      " 4   Status        3010 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 141.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# See shapes, types, values at every step\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f12ee237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different approaches quickly\n",
    "# Approach 1\n",
    "X = df[['Company', 'Designation']]\n",
    "\n",
    "# Approach 2\n",
    "X = df[['Company', 'Designation', 'Achievements']]\n",
    "\n",
    "# Compare results without rerunning entire script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9182b83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Company', 'Designation', 'Skills', 'Achievements', 'Status'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e25da5c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skill_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# See skill distribution\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mskill_counts\u001b[49m\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()  \u001b[38;5;66;03m# Appears inline!\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skill_counts' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# See skill distribution\n",
    "skill_counts.plot(kind='bar')\n",
    "plt.show()  # Appears inline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b05f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "How many rows? 5000\n",
      "How many columns? 5\n",
      "What are the columns? ['Company', 'Designation', 'Skills', 'Achievements', 'Status']\n",
      "Unique companies: 5\n",
      "Company\n",
      "Microsoft     1019\n",
      "Amazon        1000\n",
      "Salesforce    1000\n",
      "Infosys        997\n",
      "Google         984\n",
      "Name: count, dtype: int64\n",
      "Unique designations: 5\n",
      "Designation\n",
      "DevOps Engineer      1035\n",
      "Data Scientist       1010\n",
      "Software Engineer    1005\n",
      "Product Manager       992\n",
      "Cloud Architect       958\n",
      "Name: count, dtype: int64\n",
      "Status\n",
      "Accepted    3010\n",
      "Rejected    1990\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìã Example Resume:\n",
      "Company: Microsoft\n",
      "Designation: Cloud Architect\n",
      "Skills: Machine Learning, C#, AWS, Scalability, Azure, Terraform, Network Security, Python\n",
      "Status: Accepted\n",
      "Before: ['Company', 'Designation', 'Skills', 'Achievements', 'Status']\n",
      "After: ['Company', 'Designation', 'Skills', 'Achievements', 'Status']\n",
      "\n",
      "‚úÖ Data cleaned!\n",
      "Before filtering: 5000 records\n",
      "After filtering: 3010 records\n",
      "Removed: 1990 rejected candidates\n",
      "Input shape: (3010, 2)\n",
      "This means: 3010 rows (people), 2 columns (features)\n",
      "Original Skills (text):\n",
      "Machine Learning, C#, AWS, Scalability, Azure, Terraform, Network Security, Python\n",
      "\n",
      "Transformed Skills (list):\n",
      "['Machine Learning', 'C#', 'AWS', 'Scalability', 'Azure', 'Terraform', 'Network Security', 'Python']\n",
      "Companies learned:\n",
      "  Amazon ‚Üí 0\n",
      "  Google ‚Üí 1\n",
      "  Infosys ‚Üí 2\n",
      "  Microsoft ‚Üí 3\n",
      "  Salesforce ‚Üí 4\n",
      "\n",
      "üìä Encoding Verification:\n",
      "      Original  Encoded\n",
      "0    Microsoft        3\n",
      "1       Amazon        0\n",
      "5   Salesforce        4\n",
      "6      Infosys        2\n",
      "7    Microsoft        3\n",
      "9      Infosys        2\n",
      "10   Microsoft        3\n",
      "11      Amazon        0\n",
      "12     Infosys        2\n",
      "14      Amazon        0\n",
      "Output shape: (3010, 29)\n",
      "Interpretation: 3010 people, 29 possible skills\n",
      "\n",
      "All possible skills (29):\n",
      "['AWS' 'Agile' 'Algorithms' 'Azure' 'C#' 'CI/CD' 'Communication'\n",
      " 'Data Structures' 'Data Visualization' 'Docker' 'Git' 'Java' 'Jira'\n",
      " 'Kubernetes' 'Leadership' 'Linux' 'Machine Learning' 'Market Analysis'\n",
      " 'Monitoring' 'Network Security' 'Python' 'R' 'Roadmapping' 'SQL'\n",
      " 'Scalability' 'Statistics' 'TensorFlow' 'Terraform' 'UX/UI Principles']\n",
      "\n",
      "üë§ Person 0's skills:\n",
      "Original: ['Machine Learning', 'C#', 'AWS', 'Scalability', 'Azure', 'Terraform', 'Network Security', 'Python']\n",
      "Encoded: [1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0]\n",
      "Interpretation:\n",
      "  ‚úì Has AWS\n",
      "  ‚úì Has Azure\n",
      "  ‚úì Has C#\n",
      "  ‚úì Has Machine Learning\n",
      "  ‚úì Has Network Security\n",
      "  ‚úì Has Python\n",
      "  ‚úì Has Scalability\n",
      "  ‚úì Has Terraform\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Designation_Encoded'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 227\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# CELL 11: PREPARE FINAL INPUTS\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03mCombine encoded features\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m X_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCompany_Encoded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDesignation_Encoded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal input shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_encoded\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal output shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_encoded\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mk:\\Anaconda\\envs\\reco_env\\lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4118\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4119\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4121\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mk:\\Anaconda\\envs\\reco_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6210\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6214\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6216\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mk:\\Anaconda\\envs\\reco_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6263\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Designation_Encoded'] not in index\""
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 1: IMPORTS & SETUP\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "What am I doing: Importing libraries\n",
    "Why: These are tools I need for data processing and ML\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "\n",
    "# ============================================================\n",
    "# CELL 2: LOAD DATA\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "What: Load CSV file into pandas DataFrame\n",
    "Why: Need data to train the model\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('resume_dataset_large.csv')\n",
    "\n",
    "# LEARNING TASK: Answer these questions by running code\n",
    "print(f\"How many rows? {len(df)}\")\n",
    "print(f\"How many columns? {len(df.columns)}\")\n",
    "print(f\"What are the columns? {list(df.columns)}\")\n",
    "\n",
    "# Look at first 5 rows\n",
    "df.head()\n",
    "\n",
    "# ============================================================\n",
    "# CELL 3: EXPLORE THE DATA\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "LEARNING EXERCISE: Explore before processing\n",
    "\"\"\"\n",
    "\n",
    "# Question 1: How many unique companies?\n",
    "print(f\"Unique companies: {df['Company'].nunique()}\")\n",
    "print(df['Company'].value_counts())\n",
    "\n",
    "# Question 2: How many unique designations?\n",
    "print(f\"Unique designations: {df['Designation'].nunique()}\")\n",
    "print(df['Designation'].value_counts())\n",
    "\n",
    "# Question 3: What does the Status column look like?\n",
    "print(df['Status'].value_counts())\n",
    "\n",
    "# Question 4: Look at one row in detail\n",
    "print(\"\\nüìã Example Resume:\")\n",
    "print(f\"Company: {df.loc[0, 'Company']}\")\n",
    "print(f\"Designation: {df.loc[0, 'Designation']}\")\n",
    "print(f\"Skills: {df.loc[0, 'Skills']}\")\n",
    "print(f\"Status: {df.loc[0, 'Status']}\")\n",
    "\n",
    "# ============================================================\n",
    "# CELL 4: DATA CLEANING\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "What: Clean the data\n",
    "Why: Remove extra spaces, quotes, missing values\n",
    "\"\"\"\n",
    "\n",
    "# TASK 1: Clean column names\n",
    "print(\"Before:\", df.columns.tolist())\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"After:\", df.columns.tolist())\n",
    "\n",
    "# TASK 2: Clean text data\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].str.strip().str.replace('\"', '')\n",
    "\n",
    "# Check the result\n",
    "print(\"\\n‚úÖ Data cleaned!\")\n",
    "df.head()\n",
    "\n",
    "# ============================================================\n",
    "# CELL 5: FILTER DATA\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "LEARNING QUESTION: Why filter for 'Accepted' only?\n",
    "ANSWER: [Write your understanding here]\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Before filtering: {len(df)} records\")\n",
    "\n",
    "# Filter for accepted candidates\n",
    "df = df[df['Status'].str.lower() == 'accepted']\n",
    "\n",
    "print(f\"After filtering: {len(df)} records\")\n",
    "print(f\"Removed: {5000 - len(df)} rejected candidates\")\n",
    "\n",
    "# ============================================================\n",
    "# CELL 6: PREPARE INPUT FEATURES (X)\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "CONCEPT: Features = INPUT to the model\n",
    "Features = What we KNOW (Company, Designation)\n",
    "\"\"\"\n",
    "\n",
    "X = df[['Company', 'Designation']].copy()\n",
    "\n",
    "print(f\"Input shape: {X.shape}\")\n",
    "print(f\"This means: {X.shape[0]} rows (people), {X.shape[1]} columns (features)\")\n",
    "\n",
    "# LEARNING TASK: Look at first 10 inputs\n",
    "X.head(10)\n",
    "\n",
    "# ============================================================\n",
    "# CELL 7: PREPARE OUTPUT LABELS (y)\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "CONCEPT: Labels = OUTPUT we want to predict\n",
    "Labels = What we want to LEARN (Skills)\n",
    "\"\"\"\n",
    "\n",
    "# TASK: Split comma-separated skills into lists\n",
    "df['Skills_List'] = df['Skills'].apply(\n",
    "    lambda x: [skill.strip() for skill in str(x).split(',')]\n",
    ")\n",
    "\n",
    "# LEARNING: See the transformation\n",
    "print(\"Original Skills (text):\")\n",
    "print(df.loc[0, 'Skills'])\n",
    "\n",
    "print(\"\\nTransformed Skills (list):\")\n",
    "print(df.loc[0, 'Skills_List'])\n",
    "\n",
    "y = df['Skills_List']\n",
    "\n",
    "# ============================================================\n",
    "# CELL 8: ENCODING - COMPANY\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "CONCEPT: Computers understand numbers, not text\n",
    "'Google' ‚Üí 1, 'Amazon' ‚Üí 0, etc.\n",
    "\n",
    "LEARNING TASK: Understand LabelEncoder\n",
    "\"\"\"\n",
    "\n",
    "company_encoder = LabelEncoder()\n",
    "\n",
    "# Fit: Learn all unique companies\n",
    "company_encoder.fit(X['Company'])\n",
    "\n",
    "# What did it learn?\n",
    "print(\"Companies learned:\")\n",
    "for i, company in enumerate(company_encoder.classes_):\n",
    "    print(f\"  {company} ‚Üí {i}\")\n",
    "\n",
    "# Transform: Convert text to numbers\n",
    "X['Company_Encoded'] = company_encoder.transform(X['Company'])\n",
    "\n",
    "# VERIFY: Check the transformation\n",
    "comparison = pd.DataFrame({\n",
    "    'Original': X['Company'].head(10),\n",
    "    'Encoded': X['Company_Encoded'].head(10)\n",
    "})\n",
    "print(\"\\nüìä Encoding Verification:\")\n",
    "print(comparison)\n",
    "\n",
    "# ============================================================\n",
    "# CELL 9: ENCODING - DESIGNATION\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "TASK: Do the same for Designation\n",
    "TRY YOURSELF: Complete this cell\n",
    "\"\"\"\n",
    "\n",
    "designation_encoder = LabelEncoder()\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# 1. Fit the encoder\n",
    "# 2. Print the classes\n",
    "# 3. Transform and add to X\n",
    "# 4. Verify the transformation\n",
    "\n",
    "# ============================================================\n",
    "# CELL 10: ENCODING - SKILLS (Multi-Label)\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "CONCEPT: MultiLabelBinarizer\n",
    "Input: [\"Python\", \"SQL\", \"AWS\"]\n",
    "Output: [0, 0, 1, 0, 1, 0, 1, 0, ...]\n",
    "         ^     ^        ^     ^\n",
    "         |     |        |     |\n",
    "      Not    Not     Has    Has\n",
    "      skill1 skill2  Python  SQL\n",
    "\"\"\"\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_encoded = mlb.fit_transform(y)\n",
    "\n",
    "# LEARNING: Understand the output\n",
    "print(f\"Output shape: {y_encoded.shape}\")\n",
    "print(f\"Interpretation: {y_encoded.shape[0]} people, {y_encoded.shape[1]} possible skills\")\n",
    "\n",
    "print(f\"\\nAll possible skills ({len(mlb.classes_)}):\")\n",
    "print(mlb.classes_)\n",
    "\n",
    "# VISUAL: See one person's encoding\n",
    "person_idx = 0\n",
    "print(f\"\\nüë§ Person 0's skills:\")\n",
    "print(f\"Original: {y.iloc[person_idx]}\")\n",
    "print(f\"Encoded: {y_encoded[person_idx]}\")\n",
    "print(f\"Interpretation:\")\n",
    "for i, skill in enumerate(mlb.classes_):\n",
    "    if y_encoded[person_idx][i] == 1:\n",
    "        print(f\"  ‚úì Has {skill}\")\n",
    "\n",
    "# ============================================================\n",
    "# CELL 11: PREPARE FINAL INPUTS\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Combine encoded features\n",
    "\"\"\"\n",
    "\n",
    "X_encoded = X[['Company_Encoded', 'Designation_Encoded']]\n",
    "\n",
    "print(f\"Final input shape: {X_encoded.shape}\")\n",
    "print(f\"Final output shape: {y_encoded.shape}\")\n",
    "\n",
    "# SANITY CHECK\n",
    "assert X_encoded.shape[0] == y_encoded.shape[0], \"Rows must match!\"\n",
    "print(\"‚úÖ Input and output sizes match!\")\n",
    "\n",
    "# ============================================================\n",
    "# CELL 12: TRAIN-TEST SPLIT\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "CONCEPT: Split data into training (80%) and testing (20%)\n",
    "Why? To test if model learned or just memorized\n",
    "\"\"\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, \n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# LEARNING: What percentage is testing?\n",
    "test_percentage = (len(X_test) / len(X_encoded)) * 100\n",
    "print(f\"Test percentage: {test_percentage:.1f}%\")\n",
    "\n",
    "# ============================================================\n",
    "# CELL 13: CREATE MODEL\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "CONCEPT: Random Forest = 100 decision trees voting\n",
    "\"\"\"\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,      # 100 trees\n",
    "    random_state=42,       # For reproducibility\n",
    "    n_jobs=-1,             # Use all CPU cores\n",
    "    max_depth=20,          # How deep each tree\n",
    "    min_samples_split=5    # Minimum samples to split\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model created (not trained yet)\")\n",
    "print(f\"Model has {model.n_estimators} trees\")\n",
    "\n",
    "# ============================================================\n",
    "# CELL 14: TRAIN MODEL\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "This is where LEARNING happens!\n",
    "Model looks at X_train and y_train\n",
    "Finds patterns: \"When Company=1 and Designation=2, usually skills=[1,0,1,...]\"\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"üéì Training started...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"‚úÖ Training completed in {elapsed:.2f} seconds\")\n",
    "\n",
    "# ============================================================\n",
    "# CELL 15: MAKE PREDICTIONS\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Test the model on data it has NEVER seen\n",
    "\"\"\"\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Predictions shape: {y_pred.shape}\")\n",
    "print(f\"Made predictions for {len(y_pred)} people\")\n",
    "\n",
    "# LEARNING: Look at one prediction\n",
    "person_idx = 0\n",
    "print(f\"\\nüìä Example Prediction:\")\n",
    "print(f\"Actual skills: {y_test[person_idx]}\")\n",
    "print(f\"Predicted skills: {y_pred[person_idx]}\")\n",
    "\n",
    "# Count how many matched\n",
    "matches = (y_test[person_idx] == y_pred[person_idx]).sum()\n",
    "total = len(y_test[person_idx])\n",
    "print(f\"Matched: {matches}/{total} skills\")\n",
    "\n",
    "# ============================================================\n",
    "# CELL 16: EVALUATE MODEL\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "CONCEPT: How good is the model?\n",
    "\"\"\"\n",
    "\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "individual_accuracy = 1 - hamming\n",
    "\n",
    "print(f\"Hamming Loss: {hamming:.4f}\")\n",
    "print(f\"Individual Accuracy: {individual_accuracy:.4f} = {individual_accuracy*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  Out of 100 skill predictions, {int(individual_accuracy*100)} are correct\")\n",
    "print(f\"  Out of 100 skill predictions, {int(hamming*100)} are wrong\")\n",
    "\n",
    "# ============================================================\n",
    "# CELL 17: TEST WITH REAL EXAMPLE\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Let's test: What skills for Google Data Scientist?\n",
    "\"\"\"\n",
    "\n",
    "# Input\n",
    "company = \"Google\"\n",
    "designation = \"Data Scientist\"\n",
    "\n",
    "# Encode\n",
    "company_encoded = company_encoder.transform([company])[0]\n",
    "designation_encoded = designation_encoder.transform([designation])[0]\n",
    "\n",
    "print(f\"{company} ‚Üí {company_encoded}\")\n",
    "print(f\"{designation} ‚Üí {designation_encoded}\")\n",
    "\n",
    "# Create input array\n",
    "input_data = np.array([[company_encoded, designation_encoded]])\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(input_data)[0]\n",
    "\n",
    "# Decode back to skill names\n",
    "predicted_skills = []\n",
    "for i, has_skill in enumerate(prediction):\n",
    "    if has_skill == 1:\n",
    "        predicted_skills.append(mlb.classes_[i])\n",
    "\n",
    "print(f\"\\nüéØ Predicted skills for {designation} at {company}:\")\n",
    "for skill in predicted_skills:\n",
    "    print(f\"  ‚úì {skill}\")\n",
    "\n",
    "# ============================================================\n",
    "# CELL 18: CALCULATE CONFIDENCE\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "ADVANCED: Get confidence scores from all trees\n",
    "\"\"\"\n",
    "\n",
    "# Get predictions from all 100 trees\n",
    "all_tree_predictions = np.array([\n",
    "    tree.predict(input_data)[0] \n",
    "    for tree in model.estimators_\n",
    "])\n",
    "\n",
    "# Calculate confidence (% of trees that voted yes)\n",
    "confidence = all_tree_predictions.mean(axis=0)\n",
    "\n",
    "# Get top 10 skills by confidence\n",
    "top_indices = np.argsort(confidence)[::-1][:10]\n",
    "\n",
    "print(f\"üèÜ Top 10 Skills with Confidence:\")\n",
    "for i, idx in enumerate(top_indices, 1):\n",
    "    skill = mlb.classes_[idx]\n",
    "    conf = confidence[idx]\n",
    "    print(f\"  {i}. {skill}: {conf*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec0c66",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '‚îú' (U+251C) (2665236516.py, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[30], line 32\u001b[1;36m\u001b[0m\n\u001b[1;33m    ‚îú‚îÄ‚îÄ Day 1: Cells 1-7 (Data loading, cleaning, preparation)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '‚îú' (U+251C)\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE 1: After Cell 3\n",
    "\"\"\"\n",
    "TASK: Answer these questions by writing code:\n",
    "1. Which company appears most in the dataset?\n",
    "2. What percentage of total are \"Accepted\"?\n",
    "3. How many skills does the average person have?\n",
    "\n",
    "WRITE YOUR CODE BELOW:\n",
    "\"\"\"\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "# EXERCISE 2: After Cell 8\n",
    "\"\"\"\n",
    "TASK: \n",
    "1. What number is \"Microsoft\" encoded as?\n",
    "2. Create a function that converts company names to numbers\n",
    "3. What happens if you try to encode a company not in training data?\n",
    "\n",
    "WRITE YOUR CODE BELOW:\n",
    "\"\"\"\n",
    "\n",
    "# Your code here\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **My Recommended Workflow**\n",
    "```\n",
    "Week 1: Jupyter Learning\n",
    "‚îú‚îÄ‚îÄ Day 1: Cells 1-7 (Data loading, cleaning, preparation)\n",
    "‚îú‚îÄ‚îÄ Day 2: Cells 8-11 (Encoding)\n",
    "‚îú‚îÄ‚îÄ Day 3: Cells 12-16 (Training, evaluation)\n",
    "‚îî‚îÄ‚îÄ Day 4: Cells 17-18 (Prediction, confidence)\n",
    "\n",
    "Week 2: Deeper Understanding\n",
    "‚îú‚îÄ‚îÄ Day 5: Experiments (change parameters, compare results)\n",
    "‚îú‚îÄ‚îÄ Day 6: Add visualizations (plot skill distributions, confusion matrix)\n",
    "‚îî‚îÄ‚îÄ Day 7: Document your learnings\n",
    "\n",
    "Week 3: Production\n",
    "‚îú‚îÄ‚îÄ Day 8-9: Convert to VS Code .py script\n",
    "‚îî‚îÄ‚îÄ Day 10: Integrate with Flask backend\n",
    "`````````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae0e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
